{"meta":{"title":"个人网页","subtitle":null,"description":"学习笔记","author":"郑伟","url":"https://zhengw-tech.com"},"pages":[{"title":"categories","date":"2019-06-04T17:23:55.000Z","updated":"2021-04-17T14:50:06.970Z","comments":true,"path":"categories/index.html","permalink":"https://zhengw-tech.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-06-04T17:24:03.000Z","updated":"2021-04-17T14:50:06.988Z","comments":true,"path":"tags/index.html","permalink":"https://zhengw-tech.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"让GPT开发Word模版功能","slug":"word-template","date":"2023-06-10T12:02:06.000Z","updated":"2023-06-11T14:21:14.732Z","comments":true,"path":"2023/06/10/word-template/","link":"","permalink":"https://zhengw-tech.com/2023/06/10/word-template/","excerpt":"类GPT对于程序员来说比较大的用途之一就是可以用来生成代码，这次我们使用chatGpt来实现一个word的模版功能，也就是先使用一个word模版，然后使用对应的语法来将需要替换的地方使用占位符进行占位，在渲染的时候根据入参的数据进行替换，生成最终需要的word文件 预期需要支持一下几种模版语法功能： 简单字符串的替换 数字类型的小数截取功能，要支持位数不足时是否需要补0 需要支持日期的格式化 需要支持图片占位符的替换 需要支持使用对象集合，渲染word中表格多行的数据部分(暂未实现) 运行效果先来看一下最终呈现的效果 word模版内容 模版使用数据 12345678Map&lt;String, Object&gt; placeholderMap = new HashMap&lt;&gt;();placeholderMap.put(\"name\", \"张三\");placeholderMap.put(\"profession\", \"里斯\");placeholderMap.put(\"ssname\", \"John Doe\");placeholderMap.put(\"price\", String.valueOf(123.45));placeholderMap.put(\"date\", new Date());placeholderMap.put(\"image1\", \"https://zhengw-tech.com/images/netty-server.png\");placeholderMap.put(\"image2\", \"https://zhengw-tech.com/images/jvm-class.png\"); 最终word内容","text":"类GPT对于程序员来说比较大的用途之一就是可以用来生成代码，这次我们使用chatGpt来实现一个word的模版功能，也就是先使用一个word模版，然后使用对应的语法来将需要替换的地方使用占位符进行占位，在渲染的时候根据入参的数据进行替换，生成最终需要的word文件 预期需要支持一下几种模版语法功能： 简单字符串的替换 数字类型的小数截取功能，要支持位数不足时是否需要补0 需要支持日期的格式化 需要支持图片占位符的替换 需要支持使用对象集合，渲染word中表格多行的数据部分(暂未实现) 运行效果先来看一下最终呈现的效果 word模版内容 模版使用数据 12345678Map&lt;String, Object&gt; placeholderMap = new HashMap&lt;&gt;();placeholderMap.put(\"name\", \"张三\");placeholderMap.put(\"profession\", \"里斯\");placeholderMap.put(\"ssname\", \"John Doe\");placeholderMap.put(\"price\", String.valueOf(123.45));placeholderMap.put(\"date\", new Date());placeholderMap.put(\"image1\", \"https://zhengw-tech.com/images/netty-server.png\");placeholderMap.put(\"image2\", \"https://zhengw-tech.com/images/jvm-class.png\"); 最终word内容 下面我面来看一下这个对话过程 开始的时候准备让gpt直接一次实现全部的功能，但是发现在功能比较多的时候，它很容易遗忘前面的功能，导致反复修改，后来改为让它来分析需求，确定步骤之后，一步一步分模块和它沟通让它来实现 需求分析12345678910// ME请你作为一名Java开发功能师，帮我开发一个word模版的功能首先需要设计一个模版的语法，需要支持如下功能1. 简单字符串或者数字的替换2. 数字类型的小数截取功能，要支持位数不足时是否需要补03. 需要支持日期的格式化4. 需要支持图片占位符的替换5. 需要支持使用对象集合，渲染word中表格多行的数据部分，可以根据具体数据数量展示表格行数其次需要使用Java语言，使用apache poi来完成上述模版语法的支持功能实现请先分析实现这个功能需要的关键步骤，在我让你给出代码之前，请不要给我任何代码。 12345678910111213// GPT当开发一个基于 Apache POI 的 Word 模板功能时，下面是一般的关键步骤和思路：设计模板语法：根据需求，设计一套模板语法，以标识需要替换的字符串、数字、日期、图片占位符以及表格部分。解析模板：创建一个模板解析器，负责解析模板文件，并识别和提取出模板中的占位符信息。准备数据：根据模板的占位符信息，准备需要填充到模板中的数据。这可以包括字符串、数字、日期、图片和表格数据等。创建 Word 文档：使用 Apache POI 创建一个空白的 Word 文档。替换字符串和数字：根据占位符的位置，使用 Apache POI 将字符串和数字数据填充到相应的位置。处理小数位数：如果有需要，对数字类型进行小数截取，并根据需求决定是否补齐位数。公式化日期：根据占位符的位置，将日期数据转换为合适的格式，并使用 Apache POI 的公式功能进行日期的计算和公式化展示。替换图片：根据占位符的位置，将指定的图片文件插入到 Word 文档中。填充表格数据：对于表格部分，根据模板中的表格结构和占位符的位置，根据对象集合中的数据动态创建和填充表格行。输出文档：将填充好数据的 Word 文档保存到指定的位置，并进行必要的格式化和调整。以上是一个大致的实现步骤和思路。你可以根据这些步骤来逐步实现你的 Word 模板功能。当然，在实际的开发过程中，你可能还需要考虑异常处理、模板校验、优化性能等方面的问题。 模版语法设计12ME好的，那么我们按照顺序来实现，现在设计一下模版语法 12345678910111213141516GPT针对你提出的功能需求，可以设计以下模板语法：简单字符串或者数字的替换：字符串替换：使用占位符 &#123;placeholder&#125; 表示需要替换的字符串。数字替换：使用占位符 &#123;placeholder&#125; 表示需要替换的数字。数字类型的小数截取功能：小数截取：使用占位符 &#123;placeholder:digit&#125; 表示需要截取小数位的数字，其中 digit 表示保留的小数位数。小数补零：使用占位符 &#123;placeholder:digit:padding&#125; 表示需要截取小数位的数字，并在小数位数不足时补零，其中 digit 表示保留的小数位数，padding 表示是否补零，可取值为 true 或 false。日期的格式化：日期格式化：使用占位符 &#123;placeholder:format&#125; 表示需要公式化的日期，其中 format 表示日期的格式。图片占位符的替换：图片替换：使用占位符 &#123;placeholder&#125; 表示需要替换的图片占位符。使用对象集合渲染表格多行的数据部分：表格渲染：使用占位符 &#123;table&#125; 表示表格的起始位置，在该位置之后的内容将会根据对象集合进行动态的表格行渲染。请注意，上述占位符格式仅为示例，你可以根据具体需求进行适当调整。在实际解析模板时，可以使用正则表达式或其他方式来提取占位符及其参数。这样设计的模板语法可以覆盖到你的需求，并且易于解析和使用。在实现过程中，我们将根据这些模板语法来解析模板并进行相应的数据填充。 12ME这个占位符需要能区分出来类型，不然后面无法分别处理进行解析替换 12345678910111213141516GPT你提出的观点是正确的，确实需要一种方式来区分不同类型的占位符，以便后续进行正确的解析和替换操作。在设计模板语法时，可以使用特定的标识符或符号来表示不同类型的占位符。以下是一个修改后的模板语法设计，包含了对不同类型占位符的区分：简单字符串或者数字的替换：字符串替换：使用占位符 $&#123;str:placeholder&#125; 表示需要替换的字符串。数字替换：使用占位符 $&#123;num:placeholder&#125; 表示需要替换的数字。数字类型的小数截取功能：小数截取：使用占位符 $&#123;num:placeholder:digit&#125; 表示需要截取小数位的数字，其中 digit 表示保留的小数位数。小数补零：使用占位符 $&#123;num:placeholder:digit:padding&#125; 表示需要截取小数位的数字，并在小数位数不足时补零，其中 digit 表示保留的小数位数，padding 表示是否补零，可取值为 true 或 false。日期的公式化：日期格式化：使用占位符 $&#123;date:placeholder:format&#125; 表示需要公式化的日期，其中 format 表示日期的格式。图片占位符的替换：图片替换：使用占位符 $&#123;img:placeholder&#125; 表示需要替换的图片占位符。使用对象集合渲染表格多行的数据部分：表格渲染：使用占位符 $&#123;table:placeholder&#125; 表示表格的起始位置，在该位置之后的内容将会根据对象集合进行动态的表格行渲染。通过在占位符中添加类型前缀，例如 $&#123;str:placeholder&#125; 或 $&#123;num:placeholder&#125;，可以准确地区分不同类型的占位符，并在解析模板时进行相应的处理。这样设计的模板语法可以更好地满足你的需求，并能够正确地解析和替换不同类型的占位符。 这部分感觉表格部分设计的有点问题，和它再次确认了一下 12ME表格的这个语法可以具体解释一下如何使用吗？ 123456789GPT当使用对象集合渲染表格多行的数据部分时，可以使用以下的表格语法：表格语法：$&#123;table:placeholder&#125;$&#123;table:placeholder&#125;：该占位符表示表格的起始位置。在模板中使用这个占位符来标识表格的开始位置。在模板中，你可以将表格的起始位置用 $&#123;table:placeholder&#125; 进行标记，示例如下：这是一个示例表格：$&#123;table:start&#125;$&#123;table:end&#125;...&lt;这里篇幅所限，先省略了&gt; 这里和我预期的不符合，继续和它确认修改了几轮，之后为了确认我们达成了一致，让它重新输出一下结果 12ME可以举一个例子来说明，word中表格模版，如何使用模版语法来填充数据吗？可以用markdown格式来表示这个表格 123456789GPT当使用模板语法填充 Word 表格时，你可以将模板中的占位符与实际数据进行映射和替换。以下是一个示例，演示了如何使用模板语法来填充一个简单的 Word 表格。模板示例（Markdown 格式）：| 姓名 | 年龄 | 邮箱 || ----------- | ------ | ------------------- || $&#123;name1&#125; | $&#123;age1&#125; | $&#123;email1&#125; || $&#123;name2&#125; | $&#123;age2&#125; | $&#123;email2&#125; || $&#123;name3&#125; | $&#123;age3&#125; | $&#123;email3&#125; |在这个示例中，我们有一个包含三行数据的表格模板，每行数据包括姓名、年龄和邮箱。$&#123;name1&#125;、$&#123;age1&#125;、$&#123;email1&#125; 是占位符，将在填充数据时被实际的值替换。 这里看出来还是不对，每一行的对应字段变量名要是一致的，不然支持不了多行，继续沟通 12ME这个占位符需要支持的是一个集合类型的数据，不会为每一行都单独定义一个字段名，需要支持循环结构，这个模版例子需要怎么修改下 123456789GPT如果你需要在表格中填充一个集合类型的数据，并使用循环结构进行填充，可以对模板语法进行适当修改。以下是修改后的示例：模板示例（Markdown 格式）：| 姓名 | 年龄 | 邮箱 || ----------- | ------ | ------------------- |&#123;&#123;#data&#125;&#125;| $&#123;name&#125; | $&#123;age&#125; | $&#123;email&#125; |&#123;&#123;/data&#125;&#125;在这个示例中，我们使用 &#123;&#123;#data&#125;&#125; 和 &#123;&#123;/data&#125;&#125; 来定义循环结构。在循环结构内部，我们使用占位符 $&#123;name&#125;、$&#123;age&#125; 和 $&#123;email&#125; 来表示集合中每个对象的属性。 好的，到这里基本可以认为已经完成了模版语法的设计，让它再汇总一下，确保它没有忘记之前说的～ 12ME好的，现在把我们支持的语法汇总一下 123456789101112131415GPT当您使用 Apache POI 在 Word 文档中创建模板时，我们可以支持以下模板语法：字符串或数字的替换：使用 $&#123;placeholder&#125; 表示占位符，其中 placeholder 是要替换的字段名称。数字类型的小数截取功能：使用 $&#123;placeholder.format(precision, zeroPadding)&#125; 表示占位符，其中 placeholder 是要替换的字段名称，precision 是小数精度，zeroPadding 是位数不足时是否补0的标志（true 表示补0，false 表示不补0）。日期的公式化：使用 $&#123;placeholder.format(dateFormat)&#125; 表示占位符，其中 placeholder 是要替换的字段名称，dateFormat 是日期的格式化字符串，例如：&quot;yyyy-MM-dd&quot;。图片占位符的替换：使用 $&#123;placeholder&#125; 表示占位符，其中 placeholder 是要替换的字段名称，可以将占位符替换为图片的路径或二进制数据。表格数据的填充：使用 &#123;&#123;#data&#125;&#125; 和 &#123;&#123;/data&#125;&#125; 定义循环结构，用于填充表格中的多行数据。在循环结构内部，使用占位符 $&#123;fieldName&#125; 表示表格中每个单元格的数据，其中 fieldName 是数据集合中对象的属性名称。这些模板语法可以根据您的需求进行进一步调整和扩展。请注意，模板中的占位符和数据集合中的属性名称需要保持一致。希望这个汇总可以帮助您更好地理解并使用模板语法在 Word 文档中进行数据填充。如有其他问题，请随时提问。 果然忘记了之前说的占位符类型… 12ME这个不同的占位符需要有类型来区分吧 123456789101112131415GPT您是正确的，为了区分不同类型的占位符，我们可以在模板语法中添加类型标识。以下是汇总的模板语法，包括类型标识来区分不同类型的占位符：字符串或数字的替换：使用 $&#123;string:placeholder&#125; 表示字符串类型的占位符，其中 placeholder 是要替换的字段名称。数字类型的小数截取功能：使用 $&#123;number:placeholder.format(precision, zeroPadding)&#125; 表示数字类型的占位符，其中 placeholder 是要替换的字段名称，precision 是小数精度，zeroPadding 是位数不足时是否补0的标志（true 表示补0，false 表示不补0）。日期的公式化：使用 $&#123;date:placeholder.format(dateFormat)&#125; 表示日期类型的占位符，其中 placeholder 是要替换的字段名称，dateFormat 是日期的格式化字符串，例如：&quot;yyyy-MM-dd&quot;。图片占位符的替换：使用 $&#123;image:placeholder&#125; 表示图片类型的占位符，其中 placeholder 是要替换的字段名称，可以将占位符替换为图片的路径或二进制数据。表格数据的填充：使用 &#123;&#123;#data&#125;&#125; 和 &#123;&#123;/data&#125;&#125; 定义循环结构，用于填充表格中的多行数据。在循环结构内部，使用占位符 $&#123;fieldName&#125; 表示表格中每个单元格的数据，其中 fieldName 是数据集合中对象的属性名称。通过在占位符中添加类型标识，我们可以清晰地区分不同类型的占位符，并在模板解析过程中采取相应的处理逻辑。非常抱歉之前的疏忽，希望这次的回答更符合您的需求。如果还有其他问题，请随时提问。 好了，模版语法部分到这里可以先结束了 功能实现普通字符串替换12ME好的，模版语法设计完成，我们现在开始代码实现，我们先来实现word模版中的简单字符串替换，即：$&#123;string:placeholder&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071GPT好的，我们可以使用 Apache POI 来实现 Word 模板中的简单字符串替换功能。下面是一个示例代码，展示如何使用 Apache POI 替换 Word 模板中的简单字符串占位符：import org.apache.poi.xwpf.usermodel.*;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.util.HashMap;import java.util.Map;public class WordTemplateReplacement &#123; public static void main(String[] args) &#123; String templatePath = \"path/to/template.docx\"; String outputPath = \"path/to/output.docx\"; Map&lt;String, String&gt; placeholderMap = new HashMap&lt;&gt;(); placeholderMap.put(\"placeholder1\", \"Replacement 1\"); placeholderMap.put(\"placeholder2\", \"Replacement 2\"); try &#123; FileInputStream inputStream = new FileInputStream(templatePath); XWPFDocument document = new XWPFDocument(inputStream); // 遍历文档中的所有段落 for (XWPFParagraph paragraph : document.getParagraphs()) &#123; replaceParagraphPlaceholders(paragraph, placeholderMap); &#125; // 遍历文档中的所有表格 for (XWPFTable table : document.getTables()) &#123; for (XWPFTableRow row : table.getRows()) &#123; for (XWPFTableCell cell : row.getTableCells()) &#123; for (XWPFParagraph paragraph : cell.getParagraphs()) &#123; replaceParagraphPlaceholders(paragraph, placeholderMap); &#125; &#125; &#125; &#125; FileOutputStream outputStream = new FileOutputStream(outputPath); document.write(outputStream); outputStream.close(); System.out.println(\"Word template replaced successfully!\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static void replaceParagraphPlaceholders(XWPFParagraph paragraph, Map&lt;String, String&gt; placeholderMap) &#123; List&lt;XWPFRun&gt; runs = paragraph.getRuns(); for (XWPFRun run : runs) &#123; String text = run.getText(0); if (text != null) &#123; for (Map.Entry&lt;String, String&gt; entry : placeholderMap.entrySet()) &#123; String placeholder = \"$&#123;string:\" + entry.getKey() + \"&#125;\"; if (text.contains(placeholder)) &#123; text = text.replace(placeholder, entry.getValue()); run.setText(text, 0); &#125; &#125; &#125; &#125; &#125;&#125;在上述代码中，我们首先指定 Word 模板文件的路径和输出文件的路径。然后，我们创建一个包含占位符替换数据的 placeholderMap，其中键是占位符的名称，值是要替换的字符串。代码中的 replaceParagraphPlaceholders 方法用于替换段落中的占位符。我们遍历段落中的每个运行元素，检查运行元素中的文本是否包含占位符，并进行替换。最后，我们使用 XWPFDocument 将修改后的文档写入输出文件中。请注意，以上示例代码假设使用的是 .docx 格式的 Word 模板文件，并且需要包含 Apache POI 的相关依赖。您需要根据您的具体环境和需求进行相应的调整。如果您有其他问题或需要进一步帮助，请随时提问。 让GPT帮我们写几个测试的文件内容来验证一下，功能基本能实现 （其实这里有一个问题，就是如果占位符分布在不同的XWPFRun中时，会替换失败，这个沟通了好半天还是不行，放弃了.. 不过这个也有个解决办法就是在外部把占位符编写好，直接复制到word中即可解决） 数值格式化这里为了防止它忘记了之前沟通的内容，我先确认了一下 12ME之前我们设计的支持数字类型的小数截取功能，要支持位数不足时是否需要补0的word模版语法你还记得吗 123456789GPT当然，我还记得。我们设计的支持数字类型的小数截取功能，可以通过以下模版语法来表示：$&#123;number:placeholder:decimalPlaces:zeroPadding&#125;其中，number 表示数据的字段名或变量名，placeholder 表示占位符，decimalPlaces 表示要截取的小数位数，zeroPadding 表示是否需要补零，取值为 true 或 false。下面是一个示例，展示如何使用该模版语法进行小数截取和补零：原始数据： $&#123;number:data:2:true&#125;在上述示例中，$&#123;number:data:2:true&#125; 表示要将字段名为 data 的数据进行小数截取，保留两位小数，并补零。你可以将其嵌入到 Word 模版中的相应位置。当应用程序解析并替换模版时，会将 $&#123;number:data:2:true&#125; 替换为相应的数值，并根据指定的小数位数和补零规则进行格式化。例如，如果 data 的值为 3.5，则替换后的结果为 3.50。请注意，这只是一个示例模版语法，你可以根据实际需求进行调整和扩展。在代码实现时，需要解析模版语法并应用相应的逻辑来处理小数截取和补零的要求。 果然忘记了，不过也给了另一种方案，就这样吧。。 12ME这个提供一下java使用apache poi实现的代码呢 1234567891011121314151617181920212223242526GPT当然，下面是使用 Apache POI 实现数字类型的小数截取和补零的 Java 代码示例：import org.apache.poi.xwpf.usermodel.XWPFDocument;import org.apache.poi.xwpf.usermodel.XWPFParagraph;import org.apache.poi.xwpf.usermodel.XWPFRun;public class NumberFormattingUtil &#123; public static void replaceNumberPlaceholder(XWPFDocument doc, String placeholder, double value, int decimalPlaces, boolean zeroPadding) &#123; for (XWPFParagraph paragraph : doc.getParagraphs()) &#123; for (XWPFRun run : paragraph.getRuns()) &#123; String text = run.getText(0); if (text != null &amp;&amp; text.contains(placeholder)) &#123; String formattedValue = formatNumber(value, decimalPlaces, zeroPadding); text = text.replace(placeholder, formattedValue); run.setText(text, 0); &#125; &#125; &#125; &#125; private static String formatNumber(double value, int decimalPlaces, boolean zeroPadding) &#123; String format = zeroPadding ? \"%.\" + decimalPlaces + \"f\" : \"%.0\" + decimalPlaces + \"f\"; return String.format(format, value); &#125;&#125; 这说的实现和它的设计也对不上啊，一看就有问题，继续沟通一波，中间几波代码手动合并了一下，修改了一点小问题后（实在不想沟通让它改了），最终内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class NumberProcessor &#123; private static final String NUMBER_PLACEHOLDER_REGEX = \"\\\\$\\\\&#123;number:(\\\\w+)(?:,(\\\\d+)(\\\\+?))?&#125;\"; static Pattern pattern = Pattern.compile(NUMBER_PLACEHOLDER_REGEX); public static void processParagraph(XWPFParagraph paragraph, Map&lt;String, Object&gt; data) &#123; for (XWPFRun run : paragraph.getRuns()) &#123; String text = run.getText(0); if (text != null) &#123; Matcher matcher = pattern.matcher(text); while (matcher.find()) &#123; String placeholder = matcher.group(0); String fieldName = matcher.group(1); String decimalPlacesStr = matcher.group(2); String plusZeroFlag = matcher.group(3); if (data.containsKey(fieldName)) &#123; double value = Double.parseDouble(data.get(fieldName).toString()); String formattedValue = formatNumber(value, decimalPlacesStr, plusZeroFlag); text = text.replace(placeholder, formattedValue); &#125; &#125; run.setText(text, 0); &#125; &#125; &#125; private static String formatNumber(double value, String decimalPlacesStr, String plusZeroFlag) &#123; int decimalPlaces = 2; // 默认保留两位小数 if (decimalPlacesStr != null) &#123; decimalPlaces = Integer.parseInt(decimalPlacesStr); &#125; String pattern = \"#\"; if (decimalPlaces &gt; 0) &#123; pattern += \".\"; for (int i = 0; i &lt; decimalPlaces; i++) &#123; pattern += \"#\"; &#125; &#125; if (plusZeroFlag != null &amp;&amp; plusZeroFlag.equals(\"+\")) &#123; pattern = pattern.replace(\"#\", \"0\"); &#125; DecimalFormat decimalFormat = new DecimalFormat(pattern); return decimalFormat.format(value); &#125;&#125; 试了一下，基本功能可以实现了 日期格式化这次不难为它了，我们直接说需求 12ME现在实现word模版中日期格式化的功能，日期模版的语法格式为：$&#123;date:placeholder:format&#125; 表示需要公式化的日期，其中 format 表示日期的格式，placeholder为对应的变量，使用Java语言和apache poi实现一下这个功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081GPT下面是使用 Java 和 Apache POI 实现日期格式化功能的示例代码：import org.apache.poi.xwpf.usermodel.*;import java.io.FileOutputStream;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;public class WordTemplateExample &#123; public static void main(String[] args) throws IOException &#123; // 加载模板文件 XWPFDocument template = new XWPFDocument(WordTemplateExample.class.getResourceAsStream(\"template.docx\")); // 填充数据 fillData(template); // 保存生成的文档 FileOutputStream outputStream = new FileOutputStream(\"generated.docx\"); template.write(outputStream); outputStream.close(); System.out.println(\"生成的文档已保存\"); &#125; private static void fillData(XWPFDocument template) &#123; // 获取所有段落 for (XWPFParagraph paragraph : template.getParagraphs()) &#123; // 替换段落中的日期占位符 replaceDatePlaceholder(paragraph); &#125; &#125; private static void replaceDatePlaceholder(XWPFParagraph paragraph) &#123; String text = paragraph.getText(); // 判断是否包含日期占位符 if (text.contains(\"$&#123;date:\")) &#123; for (XWPFRun run : paragraph.getRuns()) &#123; String runText = run.getText(0); if (runText != null) &#123; // 查找并替换日期占位符 int startIndex = runText.indexOf(\"$&#123;date:\"); while (startIndex != -1) &#123; int endIndex = runText.indexOf(\"&#125;\", startIndex + 1); if (endIndex != -1) &#123; String placeholder = runText.substring(startIndex + 7, endIndex); String format = getDateFormat(runText.substring(startIndex, endIndex + 1)); String replacement = formatDate(format); // 替换日期占位符 runText = runText.replace(\"$&#123;date:\" + placeholder + \":\" + format + \"&#125;\", replacement); &#125; startIndex = runText.indexOf(\"$&#123;date:\", endIndex + 1); &#125; // 更新段落中的文本 run.setText(runText, 0); &#125; &#125; &#125; &#125; private static String getDateFormat(String placeholder) &#123; // 从占位符中解析出日期格式 int colonIndex = placeholder.indexOf(\":\"); return placeholder.substring(colonIndex + 1, placeholder.length() - 1); &#125; private static String formatDate(String format) &#123; // 使用指定格式格式化当前日期 SimpleDateFormat dateFormat = new SimpleDateFormat(format); return dateFormat.format(new Date()); &#125;&#125;在上述代码中，我们遍历模板中的所有段落，查找并替换日期占位符。日期占位符的格式为 $&#123;date:placeholder:format&#125;，其中 placeholder 是占位符对应的变量名，format 是日期的格式。我们通过解析占位符获取日期格式，并使用 SimpleDateFormat 格式化当前日期。请确保在代码中设置正确的模板文件路径和保存生成的文档路径。模板文件中需要包含日期占位符 $&#123;date:placeholder:format&#125;，并确保格式正确。运行代码后，生成的文档将包含替换了日期占位符的日期值。在上述代码中，我们遍历模板中的所有段落，查找并替换日期占位符。日期占位符的格式为 $&#123;date:placeholder:format&#125;，其中 placeholder 是占位符对应的变量名，format 是日期的格式。我们通过解析占位符获取日期格式，并使用 SimpleDateFormat 格式化当前日期。请确保在代码中设置正确的模板文件路径和保存生成的文档路径。模板文件中需要包含日期占位符 $&#123;date:placeholder:format&#125;，并确保格式正确。运行代码后，生成的文档将包含替换了日期占位符的日期值。 不出所料，生成的代码依然是有问题的 12MEplaceholder和format解析的结果不对，它们中间应该以:分割，现在各自取的内容多了 修改后使用了split(&quot;:&quot;)方法，依然有问题 12ME日期格式化中可能也包含符号:，所以不能直接split(&quot;:&quot;) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172GPT非常抱歉，对于日期格式化中可能包含符号 \":\"，确实不能直接使用 split(\":\") 方法进行分割。为了解决这个问题，我们可以使用正则表达式来匹配日期格式占位符。以下是修正后的代码示例：import org.apache.poi.xwpf.usermodel.*;import java.io.FileOutputStream;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.regex.Matcher;import java.util.regex.Pattern;public class WordTemplateExample &#123; public static void main(String[] args) throws IOException &#123; // 加载模板文件 XWPFDocument template = new XWPFDocument(WordTemplateExample.class.getResourceAsStream(\"template.docx\")); // 填充数据 fillData(template); // 保存生成的文档 FileOutputStream outputStream = new FileOutputStream(\"generated.docx\"); template.write(outputStream); outputStream.close(); System.out.println(\"生成的文档已保存\"); &#125; private static void fillData(XWPFDocument template) &#123; // 获取所有段落 for (XWPFParagraph paragraph : template.getParagraphs()) &#123; // 替换段落中的日期占位符 replaceDatePlaceholder(paragraph); &#125; &#125; private static void replaceDatePlaceholder(XWPFParagraph paragraph) &#123; String text = paragraph.getText(); // 判断是否包含日期占位符 if (text.contains(\"$&#123;date:\")) &#123; for (XWPFRun run : paragraph.getRuns()) &#123; String runText = run.getText(0); if (runText != null) &#123; // 使用正则表达式匹配日期占位符 Pattern pattern = Pattern.compile(\"\\\\$\\\\&#123;date:(.*?):(.*?)\\\\&#125;\"); Matcher matcher = pattern.matcher(runText); StringBuffer buffer = new StringBuffer(); while (matcher.find()) &#123; String placeholder = matcher.group(1); String format = matcher.group(2); String replacement = formatDate(format); // 替换日期占位符 matcher.appendReplacement(buffer, replacement); &#125; matcher.appendTail(buffer); // 更新段落中的文本 run.setText(buffer.toString(), 0); &#125; &#125; &#125; &#125; private static String formatDate(String format) &#123; // 使用指定格式格式化当前日期 SimpleDateFormat dateFormat = new SimpleDateFormat(format); return dateFormat.format(new Date()); &#125;&#125;在修正后的代码中，我们使用了正则表达式 \\\\$\\\\&#123;date:(.*?):(.*?)\\\\&#125; 来匹配日期占位符，保证了即使日期格式中包含 \":\" 符号，也能正确解析占位符的内容。 这次试了下是可以了，但是日期没有从外部参数中获取，这个就自己调整了一下，功能完成 图片占位符替换12ME使用apache poi实现java模版中的图片占位符替换，将占位符替换为传入的图片地址，占位符格式如下：$&#123;img:placeholder&#125; 表示需要替换的图片占位符，placeholder为传入参数map中的图片地址对应的key 123GPT要实现Java模板中的图片占位符替换功能，你可以使用 Apache POI 中的 XWPFRun 类来插入图片，并通过占位符和传入参数的映射来确定要替换的图片地址。以下是一个示例代码：要实现Java模板中的图片占位符替换功能，你可以使用 Apache POI 中的 XWPFRun 类来插入图片，并通过占位符和传入参数的映射来确定要替换的图片地址。以下是一个示例代码：&lt;这部分只能支持本地图片，就不贴代码了&gt; 12ME本地图片和远程图片都需要支持 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899GPT若要同时支持本地图片和远程图片，你可以在代码中进行一些修改。以下是修改后的代码示例：import org.apache.poi.util.IOUtils;import org.apache.poi.xwpf.usermodel.*;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.net.URL;import java.util.HashMap;import java.util.Map;public class WordTemplateExample &#123; public static void main(String[] args) throws IOException &#123; // 加载模板文件 XWPFDocument template = new XWPFDocument(new FileInputStream(\"template.docx\")); // 准备图片映射数据 Map&lt;String, String&gt; imageMap = new HashMap&lt;&gt;(); imageMap.put(\"placeholder1\", \"path/to/local/image.png\"); imageMap.put(\"placeholder2\", \"https://example.com/remote/image.png\"); // 填充数据 fillData(template, imageMap); // 保存生成的文档 FileOutputStream outputStream = new FileOutputStream(\"generated.docx\"); template.write(outputStream); outputStream.close(); System.out.println(\"生成的文档已保存\"); &#125; private static void fillData(XWPFDocument template, Map&lt;String, String&gt; imageMap) throws IOException &#123; for (XWPFParagraph paragraph : template.getParagraphs()) &#123; replaceImagePlaceholder(paragraph, imageMap); &#125; &#125; private static void replaceImagePlaceholder(XWPFParagraph paragraph, Map&lt;String, String&gt; imageMap) throws IOException &#123; for (XWPFRun run : paragraph.getRuns()) &#123; String text = run.getText(0); if (text != null) &#123; String regex = \"\\\\$\\\\&#123;img:(.*?)\\\\&#125;\"; if (text.matches(regex)) &#123; String placeholder = text.replaceAll(regex, \"$1\"); if (imageMap.containsKey(placeholder)) &#123; String imagePath = imageMap.get(placeholder); InputStream imageStream; if (isRemoteImage(imagePath)) &#123; // 远程图片 imageStream = new URL(imagePath).openStream(); &#125; else &#123; // 本地图片 imageStream = new FileInputStream(imagePath); &#125; // 下载图片数据 byte[] imageData = IOUtils.toByteArray(imageStream); imageStream.close(); // 插入图片 int pictureType = getImageType(imagePath); int width = 100; int height = 100; run.addPicture(imageData, pictureType, \"\", Units.toEMU(width), Units.toEMU(height)); // 删除原始文本块 paragraph.removeRun(paragraph.getRuns().indexOf(run)); &#125; &#125; &#125; &#125; &#125; private static boolean isRemoteImage(String imagePath) &#123; return imagePath.startsWith(\"http://\") || imagePath.startsWith(\"https://\"); &#125; private static int getImageType(String imagePath) &#123; if (imagePath.endsWith(\".png\")) &#123; return XWPFDocument.PICTURE_TYPE_PNG; &#125; else if (imagePath.endsWith(\".jpeg\") || imagePath.endsWith(\".jpg\")) &#123; return XWPFDocument.PICTURE_TYPE_JPEG; &#125; else if (imagePath.endsWith(\".gif\")) &#123; return XWPFDocument.PICTURE_TYPE_GIF; &#125; else &#123; // 默认返回 PNG 类型，可根据需要进行调整 return XWPFDocument.PICTURE_TYPE_PNG; &#125; &#125;&#125;在此示例中，我们添加了一个 isRemoteImage 方法来判断图片路径是否为远程图片，如果是远程图片，则使用 java.net.URL 下载图片数据。否则，我们认为它是本地图片，并使用 FileInputStream 读取图片数据。另外，我们还添加了一个 getImageType 方法来根据图片路径获取图片类型。这里我们简单地根据文件后缀名判断图片类型，但你可以根据实际情况进行调整和扩展。请确保根据你的具体需求进行适当的异常处理和错误处理，并根据 Word 文档中的图片格式要求进行调整。 这里也是有几个小问题，有点累了，自己改了下，这种的让GPT来改也是可以的，大概有如下几点 addPicture方法入参需要把byte[]改为 InputStream 异常抛出 迭代中执行removeRun会报错并发异常 改了之后验证功能没有问题 表格占位符替换这个试了下，实现的一直有问题，后续有时间再看吧～～ 总结整体使用下来感受总结一下 需求要尽量描述情况，不明确时可能让GPT举例来确认，确保理解一致 GPT的记忆能力有限，需要拆解需求，让它按小模块来实现功能 需要有耐心，基本很难一次成功，需要反复调试沟通 效率确实是会有提供的，尤其是API不太熟悉的情况下，目前个人觉得一个比较合适的使用方式 最好是自己负责设计，不清晰的地方可以和GPT探讨沟通，由我们自己确定最终的方案 可以由GPT按模块功能实现大部分的样板代码，然后我们来调试调试，改改BUG，组装代码完成功能实现 相关的代码简单整理到了Github，大家有兴趣可以自行查看","categories":[],"tags":[{"name":"word","slug":"word","permalink":"https://zhengw-tech.com/tags/word/"},{"name":"template","slug":"template","permalink":"https://zhengw-tech.com/tags/template/"},{"name":"gpt","slug":"gpt","permalink":"https://zhengw-tech.com/tags/gpt/"}]},{"title":"JavaAgent使用及原理","slug":"java-agent","date":"2023-05-27T07:36:50.000Z","updated":"2023-06-04T14:26:13.673Z","comments":true,"path":"2023/05/27/java-agent/","link":"","permalink":"https://zhengw-tech.com/2023/05/27/java-agent/","excerpt":"在介绍Java agent之前，我们先来介绍一下一个比较关键的概念 - 字节码，这个如果大家已经比较熟悉了，可以直接跳到 java agent部分 字节码我们知道Java编写的程序是可以不做任何修改的在不同的操作系统上面运行，也就是跨平台的，但是要想实现跨平台，就是需要能屏蔽掉不同操作系统之间api等的差异 比如说常见的创建线程，linux和window系统提供的接口就不一样 1234567891011121314// 不同操作系统下，使用c语言创建线程的API// linuxint pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void*), void *arg);// windowsHANDLE CreateThread( LPSECURITY_ATTRIBUTES lpThreadAttributes, SIZE_T dwStackSize, LPTHREAD_START_ROUTINE lpStartAddress, LPVOID lpParameter, DWORD dwCreationFlags, LPDWORD lpThreadId); 除了创建线程，其实还有很多的差异，比如说如果用C语言来实现既能在windows下运行，又能在linux下指定的代码，那么就需要针对有差异的地方，根据不同的操作系统来编写不同的代码，然后在编译的时候根据需要编译成对应系统下的二进制指令，这无疑是很痛苦和低效的方式 而Java下编译并不会生成目标平台的二进制文件，而是生成一个与平台无关的字节码文件，由不同平台下Java虚拟机负责加载执行，操作系统的差异就需要由虚拟机来进行屏蔽，对开发人员是无感知的 我们只需要将源代码编译成字节码（而不是操作系统下的二进制格式），剩下的就可以交给虚拟机来识别执行了 其实这样还有一个额外的好处，那就是在Java虚拟机上，不仅仅只能支持Java语言，理论上只要是符合规范的字节码文件，它都能执行，至于这个字节码文件是Java语言编译过来的，还是其他语言（如kotlin, groovy）编译过来的并不重要，甚至我们都可以手写字节码来执行～","text":"在介绍Java agent之前，我们先来介绍一下一个比较关键的概念 - 字节码，这个如果大家已经比较熟悉了，可以直接跳到 java agent部分 字节码我们知道Java编写的程序是可以不做任何修改的在不同的操作系统上面运行，也就是跨平台的，但是要想实现跨平台，就是需要能屏蔽掉不同操作系统之间api等的差异 比如说常见的创建线程，linux和window系统提供的接口就不一样 1234567891011121314// 不同操作系统下，使用c语言创建线程的API// linuxint pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void*), void *arg);// windowsHANDLE CreateThread( LPSECURITY_ATTRIBUTES lpThreadAttributes, SIZE_T dwStackSize, LPTHREAD_START_ROUTINE lpStartAddress, LPVOID lpParameter, DWORD dwCreationFlags, LPDWORD lpThreadId); 除了创建线程，其实还有很多的差异，比如说如果用C语言来实现既能在windows下运行，又能在linux下指定的代码，那么就需要针对有差异的地方，根据不同的操作系统来编写不同的代码，然后在编译的时候根据需要编译成对应系统下的二进制指令，这无疑是很痛苦和低效的方式 而Java下编译并不会生成目标平台的二进制文件，而是生成一个与平台无关的字节码文件，由不同平台下Java虚拟机负责加载执行，操作系统的差异就需要由虚拟机来进行屏蔽，对开发人员是无感知的 我们只需要将源代码编译成字节码（而不是操作系统下的二进制格式），剩下的就可以交给虚拟机来识别执行了 其实这样还有一个额外的好处，那就是在Java虚拟机上，不仅仅只能支持Java语言，理论上只要是符合规范的字节码文件，它都能执行，至于这个字节码文件是Java语言编译过来的，还是其他语言（如kotlin, groovy）编译过来的并不重要，甚至我们都可以手写字节码来执行～ 上面的概念说完了，下面我们来具体编写代码来感受一下字节码 1234567891011121314// 先来编写一个类，主要有一个 incr方法，对参数进行加一返回package com.zavier.agent;public class Test &#123; public static void main(String[] args) &#123; final Test test = new Test(); final int incr = test.incr(5); // 很明显会输出 6 System.out.println(incr); &#125; public int incr(int i) &#123; return i + 1; &#125;&#125; 那么对应的字节码如何查看呢，就是看它编译后的文件以.class结尾的文件Test.class，而这个文件怎么查看呢，一种就是直接以二进制的方式打开，当然，这个人根本是无法阅读的，我贴出来一部分大家感受一下 12345678910➜ hexdump -C Test.class00000000 ca fe ba be 00 00 00 34 00 28 0a 00 07 00 1a 07 |.......4.(......|00000010 00 1b 0a 00 02 00 1a 0a 00 02 00 1c 09 00 1d 00 |................|00000020 1e 0a 00 1f 00 20 07 00 21 01 00 06 3c 69 6e 69 |..... ..!...&lt;ini|00000030 74 3e 01 00 03 28 29 56 01 00 04 43 6f 64 65 01 |t&gt;...()V...Code.|00000040 00 0f 4c 69 6e 65 4e 75 6d 62 65 72 54 61 62 6c |..LineNumberTabl|00000050 65 01 00 12 4c 6f 63 61 6c 56 61 72 69 61 62 6c |e...LocalVariabl|00000060 65 54 61 62 6c 65 01 00 04 74 68 69 73 01 00 17 |eTable...this...|00000070 4c 63 6f 6d 2f 7a 61 76 69 65 72 2f 61 67 65 6e |Lcom/zavier/agen|00000080 74 2f 54 65 73 74 3b 01 00 04 6d 61 69 6e 01 00 |t/Test;...main..| 还有一种方式就是使用 JDK提供的反编译字节码的工具 javap，我们来执行一下看看，由于反编译后的内容比较多，这里我贴一下 incr 方法对应的字节码大家看一下 123456789101112131415161718192021➜ javap -v Test # 忽略其他部分，大家有兴趣可以自己试一下public int incr(int); descriptor: (I)I flags: ACC_PUBLIC # code部分是对应方法的内容 Code: # 操作数栈有2个元素位，局部变量表有2个元素位，参数有2个（其中一个参数是 this ） stack=2, locals=2, args_size=2 0: iload_1 # 将第一个int类型的本地变量推送到操作数栈顶 1: iconst_1 # 将 int类型数字 1 推送到操作数栈顶 2: iadd # 弹出栈顶两个int类型的数值，相加后将结果压入栈顶 3: ireturn # 从当前方法返回 int LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 4 0 this Lcom/zavier/agent/Test; 0 4 1 i ISourceFile: \"Test.java\" 以上方法的字节码还是比较好理解的，这时候想一下，如果我们将 iconst_1改成iconst_2，那么在运行这个文件，是不是就会变成了加二的操作呢？我们可以来试一下 字节码文件是有它自己的规范的，我们随便改可能会导致加载异常，而且手动找到对应命令进行修改也确实是一个很麻烦的事情，这时候就需要使用工具来完成了，可选的有很多，如asm, cglib, javassist, bytebuddy等等 这里使用asm9来实现一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Transformer &#123; // 遍历查找类的 static class MyClassVisitor extends ClassVisitor &#123; public MyClassVisitor(int i, ClassWriter cw) &#123; super(i, cw); &#125; @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) &#123; MethodVisitor mv = super.visitMethod(access, name, desc, signature, exceptions); // 查找方法，名称为 incr， (I)I 表示参数类型为一个int,返回类型也为int if (name.equals(\"incr\") &amp;&amp; desc.equals(\"(I)I\")) &#123; return new MyMethodVisitor(Opcodes.ASM9, mv); &#125; else &#123; return mv; &#125; &#125; &#125; // 遍历查找方法的 static class MyMethodVisitor extends MethodVisitor &#123; public MyMethodVisitor(int api, MethodVisitor methodVisitor) &#123; super(api, methodVisitor); &#125; @Override public void visitInsn(int opcode) &#123; if (opcode == Opcodes.ICONST_1) &#123; // 如果指定是ICONST_1，则修改为 ICONST_2 super.visitInsn(Opcodes.ICONST_2); &#125; else &#123; super.visitInsn(opcode); &#125; &#125; &#125; // 使用main方法来执行修改 public static void main(String[] args) throws IOException &#123; // 读取字节码文件，进行转换 ClassReader cr = new ClassReader(new FileInputStream(\"/path/Test.class\")); ClassWriter cw = new ClassWriter(cr, 0); ClassVisitor cv = new MyClassVisitor(Opcodes.ASM9, cw); cr.accept(cv, 0); byte[] bytes = cw.toByteArray(); // 修改后的字节码 // 将转换后的结果输出到文件中 final FileOutputStream fileOutputStream = new FileOutputStream(\"/path/Test.class\"); fileOutputStream.write(bytes); fileOutputStream.close(); &#125;&#125; 这时候我们再使用javap看一下替换后的字节码内容，可以发现已经替换成功了 123456789101112131415public int incr(int); descriptor: (I)I flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: iload_1 1: iconst_2 # 这里已经替换成了 iconst_2 2: iadd 3: ireturn LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 4 0 this Lcom/zavier/agent/Test; 0 4 1 i I 我们再运行一下代码看一看 123➜ java com.zavier.agent.Test# 可以看到main方法运行的结果已经由6变成了77 到这里字节码部分就介绍完了，大家主要记住 字节码是JVM运行的关键就可以了，其中基本包含了我们在源代码中编写的全部内容，我们通过修改字节码甚至可以实现源代码中没有的功能 JavaAgent现在我们开始介绍一下java-agent技术，那么java-agent是做什么的呢？简单理解就是jvm提供的可以在运行时修改字节码的能力，利用这种能力可以做很多事情，如用来记录请求链路（skywalking等）或者录制流量等 方法声明javaagent使用有两种方式，一种是在jvm启动的时候直接指定agent，即需要在对应项目jvm启动时即指定jar包： java -javaagent:xxx/agent.jar -jar server.jar 还有一种是在运行时动态挂载agent，这种需要通过java代码来实现动态的挂载 12VirtualMachine jvm = VirtualMachine.attach(\"&lt;要挂载agent到哪个jvm进程的ID&gt;\");jvm.loadAgent(\"/path/agent.java\"); // agent jar包的路径 先看一下启动时指定代理包的写法，它需要声明实现如下的方法 1public static void premain(String args, Instrumentation instrumentation) 如果是动态挂载的方式，则需要声明实现另一个方法 1public static void agentmain(String agentArgs, Instrumentation inst) 方法实现两种方式使用起来大同小异，我们看一下大致用法实现 123456789101112131415161718192021222324public class Agent &#123; // 定义 premain 方法并实现 public static void premain(String args, Instrumentation instrumentation) &#123; // 调用 Instrumentation#addTransformer(java.lang.instrument.ClassFileTransformer) // 添加对应的字节码文件转换器，用来对字节码进行转换 instrumentation.addTransformer(new LogClassFileTransformer()); &#125; // 定义 agentmain 方法并实现 public static void agentmain(String agentArgs, Instrumentation instrumentation) &#123; // 同 premain 方法实现 instrumentation.addTransformer(new LogClassFileTransformer()); &#125; // 自定义的字节码文件转换器 static class LogClassFileTransformer implements ClassFileTransformer &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; // 字节码转换的实现逻辑，通过解析原始字节码，进行替换后返回更新后的字节码，达到修改实现的目的 &#125; &#125;&#125; 打包配置不管使用哪种方式，都需要增加一下如下打包的配置 打包时需要将依赖一起打包 打的包中的 META-INF目录下的MANIFEST.MF文件中增加如下配置： 123456789# MANIFEST.MF文件# 动态挂载时使用的agent的入口类方法，也就是实现agentmain方法的类Agent-Class: com.zavier.agent.Agent# 是否允许重新定义类Can-Redefine-Classes: true# 是否允许转换类Can-Retransform-Classes: true# 启动时使用的agent的入口类方法，也就是实现premain方法的类Premain-Class: com.zavier.agent.Agent 这里我们使用maven的assembly插件来完成上述配置实现，这样在打包时maven自动帮我们完成了全部配置功能 123456789101112131415161718192021222324252627282930&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;!-- 生成包含依赖的jar包 --&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;-full&lt;/finalName&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;archive&gt; &lt;manifestEntries&gt; &lt;!-- 这里的配置和上面的是一一对应的 --&gt; &lt;Premain-Class&gt;com.zavier.agent.Agent&lt;/Premain-Class&gt; &lt;Agent-Class&gt;com.zavier.agent.Agent&lt;/Agent-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;assemble-all&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 实现例子这次我们用byte-buddy对java-agent的支持，来实现一个记录请求日志的功能 首先我们新建一个spring boot的项目，随便写下controller, service，然后正常启动项目 1234567891011121314151617@RestControllerpublic class DemoController &#123; @GetMapping(value = \"/sayHello\") public User sayHello(String name) &#123; final User user = demoService.sayHello(name); return user; &#125;&#125;@Servicepublic class DemoService &#123; public User sayHello(String name) &#123; final User user = new User(); user.setName(name); return user; &#125;&#125; 这时候在浏览器访问 http://localhost:8080/sayHello?name=zhangsan，可以看到系统无日志，同时会返回 1&#123;\"name\": \"zhangsan\"&#125; 在新建一个agent项目，实现记录所有调用DemoService#sayHello方法的参数和返回值 这次我们借助bytebuddy的支持来实现我们的功能 123456&lt;!-- 引入 byte-buddy依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt; &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt; &lt;version&gt;1.12.12&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940// 先创建一个记录日志的Adviceimport net.bytebuddy.asm.Advice;import net.bytebuddy.implementation.bytecode.assign.Assigner;import java.lang.reflect.Method;import java.lang.reflect.Parameter;import java.util.HashMap;import java.util.Map;public class LoggingAdvice &#123; // 方法进行时获取对应的参数信息 @Advice.OnMethodEnter(suppress = Exception.class) public static String before( @Advice.AllArguments Object[] allArguments, @Advice.Origin Method method) &#123; if (allArguments == null) &#123; return null; &#125; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); final Parameter[] parameters = method.getParameters(); for (int i = 0; i &lt; parameters.length; i++) &#123; map.put(parameters[i].getName(), allArguments[i]); &#125; return map.toString(); &#125; // 方法退出时获取结果信息，并打印最终结果 @Advice.OnMethodExit public static void after( @Advice.Enter String params, @Advice.Origin Method method, @Advice.Return(typing = Assigner.Typing.DYNAMIC) Object returnValue) &#123; // 打印结果日志 System.out.println(\"method:\" + method.getName() + \",param:\" + params + \",result:\" + returnValue); &#125;&#125; 实现Agent类对应的agentmain方法 12345678910111213141516// Agent.javapublic static void agentmain(String agentArgs, Instrumentation inst) &#123; new AgentBuilder.Default().disableClassFormatChanges() .with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION) // 匹配以 com.zavier.bootdemo.web 开头的类 .type(ElementMatchers.nameStartsWith(\"com.zavier.bootdemo.web\")) .transform(new AgentBuilder.Transformer() &#123; @Override public DynamicType.Builder&lt;?&gt; transform(DynamicType.Builder&lt;?&gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) &#123; // 将方法名称是 sayHello 交给 LoggingAdvice 处理 return builder.visit(Advice.to(LoggingAdvice.class).on( namedOneOf(\"sayHello\"))); &#125; &#125;).installOn(inst);&#125; 补充好配置文件后，整体进行打成一个jar包 动态挂载，实现打印日志功能 1234# 首先查找对当前spring boot项目对应的进程ID，可以看到对应的ID是 63932➜ jps -l 66387 sun.tools.jps.Jps63932 com.zavier.bootdemo.BootDemoApplication 实现attach的java代码 1234public static void main(String[] args) throws Exception &#123; VirtualMachine jvm = VirtualMachine.attach(\"63932\"); // springboot项目进程ID jvm.loadAgent(\"/path/agent-study-1.0-SNAPSHOT-full.jar\");&#125; 这时候再通过浏览器访问http://localhost:8080/sayHello?name=zhangsan就可以在springboot项目中看到如下输出 1method:sayHello,param:&#123;arg0=zhangsan&#125;,result:User(name=zhangsan) 这样我们就实现了在不修改代码的情况下添加日志的功能，当然这只是一个小的例子，实际使用的时候要考虑很多场景，如类的隔离、修改类的卸载回退等等 以上就是这次的全部内容，很多地方没有使用精确的定义，基本是作者个人的理解表述，如有错误欢迎指正","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"agent","slug":"agent","permalink":"https://zhengw-tech.com/tags/agent/"}]},{"title":"Java异常重试-GuavaRetrying","slug":"guava-retry","date":"2023-04-11T23:48:29.000Z","updated":"2023-04-14T00:27:47.495Z","comments":true,"path":"2023/04/12/guava-retry/","link":"","permalink":"https://zhengw-tech.com/2023/04/12/guava-retry/","excerpt":"重试在项目中还是比较常见的一个场景，比如调用外部服务因为网络等原因的异常，重试一次可能就成功了，而不需要立即给用户反馈错误，提高体验 假设我们自己来写一个最简单异常重试的话，可能代码是这样子的 123456789int retryTime = 3;for (int i = 0; i &lt; retryTime; i++) &#123; try &#123; // 方法调用 return service.query(); &#125; catch (Throwable e) &#123; log.info(\"调用异常，进行重试\"); &#125;&#125; 这里可能有几个问题需要考虑 不仅仅是异常需要重试，有时接口返回的特定错误码也是需要重试的 不是所有的异常都可以重试，需要根据情况判断异常原因才能重试 有时失败不能立即重试，需要等待一小段时间，比如短时网络波动 重试停止不一定只需要次数，有时也需要判断整体用的时间等因素 这么一看，需要考虑的地方还挺多，而重试功能又是一个非常通用的功能，所以完全可以包装一下做成通用的能力 而这个目前已经有一些现成的工具供我们使用，这次我们就先看下 guava-retrying","text":"重试在项目中还是比较常见的一个场景，比如调用外部服务因为网络等原因的异常，重试一次可能就成功了，而不需要立即给用户反馈错误，提高体验 假设我们自己来写一个最简单异常重试的话，可能代码是这样子的 123456789int retryTime = 3;for (int i = 0; i &lt; retryTime; i++) &#123; try &#123; // 方法调用 return service.query(); &#125; catch (Throwable e) &#123; log.info(\"调用异常，进行重试\"); &#125;&#125; 这里可能有几个问题需要考虑 不仅仅是异常需要重试，有时接口返回的特定错误码也是需要重试的 不是所有的异常都可以重试，需要根据情况判断异常原因才能重试 有时失败不能立即重试，需要等待一小段时间，比如短时网络波动 重试停止不一定只需要次数，有时也需要判断整体用的时间等因素 这么一看，需要考虑的地方还挺多，而重试功能又是一个非常通用的功能，所以完全可以包装一下做成通用的能力 而这个目前已经有一些现成的工具供我们使用，这次我们就先看下 guava-retrying 快速使用首先需要引入依赖包 12345&lt;dependency&gt; &lt;groupId&gt;com.github.rholder&lt;/groupId&gt; &lt;artifactId&gt;guava-retrying&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 然后就可以使用了 1234567891011121314151617181920212223242526272829// 1. 将方法调用包装成一个 callableCallable&lt;Boolean&gt; callable = new Callable&lt;Boolean&gt;() &#123; public Boolean call() throws Exception &#123; return true; // do something useful here &#125;&#125;;// 2. 配置重试相关策略（根据具体使用进行调整配置）Retryer&lt;Boolean&gt; retryer = RetryerBuilder.&lt;Boolean&gt;newBuilder() // 结果是null进行重试 .retryIfResult(Predicates.&lt;Boolean&gt;isNull()) // IO异常进行重试 .retryIfExceptionOfType(IOException.class) // 运行时异常进行重试 .retryIfRuntimeException() // 单次执行超时时间配置，超时则异常 .withAttemptTimeLimiter(AttemptTimeLimiters.fixedTimeLimit(200, TimeUnit.MILLISECONDS)) // 固定间隔等待(也可以设置其他等待策略) .withWaitStrategy(WaitStrategies.fixedWait(100, TimeUnit.MILLISECONDS)) // 3次重试后停止 .withStopStrategy(StopStrategies.stopAfterAttempt(3)) .build();try &#123; retryer.call(callable);&#125; catch (RetryException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125; 实现分析可以看到整体源码比较简单清晰 我们直接通过调用方法的代码来看一下各个类的用途 12345678910111213141516171819202122232425262728293031323334353637383940414243// com.github.rholder.retry.Retryerpublic V call(Callable&lt;V&gt; callable) throws ExecutionException, RetryException &#123; long startTime = System.nanoTime(); for (int attemptNumber = 1; ; attemptNumber++) &#123; Attempt&lt;V&gt; attempt; try &#123; // 1. 执行实际方法调用(如有超时配置，达到超时时间后会抛出异常，再次进行重试) V result = attemptTimeLimiter.call(callable); // 2. 成功后则包装成功结果 attempt = new ResultAttempt&lt;V&gt;(result, attemptNumber, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)); &#125; catch (Throwable t) &#123; // 3. 假如执行异常时也先包装异常的结果，不抛出异常 attempt = new ExceptionAttempt&lt;V&gt;(t, attemptNumber, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)); &#125; // 4. 异常监听器通知处理 for (RetryListener listener : listeners) &#123; listener.onRetry(attempt); &#125; // 5. 这里就是我们之前配置的需要重试的条件汇总，如retryIfRuntimeException等 // 如果全部都没有匹配上，则说明不需要重试，此时会直接返回结果或抛出异常 if (!rejectionPredicate.apply(attempt)) &#123; return attempt.get(); &#125; // 6. 如果前面的重试条件匹配上了，则会进入这里，进行是否停止重试的判断(一般不可能允许无限重试) // 比如配置了最多重试三次，或者从第一次尝试到现在已经达到了多少时间等等 // 如果需要停止，则也不会再次进行重试，直接抛出异常 if (stopStrategy.shouldStop(attempt)) &#123; throw new RetryException(attemptNumber, attempt); &#125; else &#123; // 7. 计算重试的间隔时间 long sleepTime = waitStrategy.computeSleepTime(attempt); try &#123; // 8. 阻塞达到间隔时间结束 blockStrategy.block(sleepTime); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); throw new RetryException(attemptNumber, attempt); &#125; &#125; &#125;&#125; 这样我们就比较好理解下面的类的作用了 123456789101112131415161718192021222324252627282930313233.├── Attempt // 执行的结果包装(可能成功或失败) 【接口】├── AttemptTimeLimiter // 执行时间限制接口(实际方法由它执行)【接口】├── AttemptTimeLimiters // 执行时间限制接口实现工厂类【类】├───── FixedAttemptTimeLimit // 固定限制执行时间【类】├───── NoAttemptTimeLimit // 不限制执行时间【类】├── BlockStrategy // 执行阻塞策略接口【接口】├── BlockStrategies // 执行阻塞策略工厂类【类】├───── ThreadSleepStrategy // 通过Thread.sleep进行阻塞的实现【类】├── RetryException // 重试异常类【类】├── RetryListener // 重试监听器接口【接口】├── Retryer // 实际执行重试器【类】├───── ExceptionAttempt // 执行异常的结果包装【类】├───── ResultAttempt // 执行成功的结果包装【类】├───── RetryerCallable // 没有使用..【类】├── RetryerBuilder // 重试构造器【类】├───── ExceptionClassPredicate // 用于异常类型判断是否需要重试断言【类】├───── ExceptionPredicate // 根据异常进行判断是否需要重试断言【类】├───── ResultPredicate // 根据执行结果判断是否需要重试断言【类】├── StopStrategy // 终止策略【接口】├── StopStrategies // 终止策略实现工厂类【类】├───── NeverStopStrategy // 永不终止【类】├───── StopAfterAttemptStrategy // 限制最多重试次数进行终止【类】├───── StopAfterDelayStrategy // 限制总执行时间进行终止【类】├── WaitStrategy // 等待时间计算策略【接口】├── WaitStrategies // 等待时间计算策略实现工厂【类】├───── CompositeWaitStrategy // 复合等待时间计算类（聚合其他实现类）【类】├───── ExceptionWaitStrategy // 根据特定类型异常计算等待时间【类】├───── ExponentialWaitStrategy // 每次等待时间进行指数增长【类】├───── FibonacciWaitStrategy // 每次等待时间进行fibonacci方式增长【类】├───── FixedWaitStrategy // 每次都是固定的等待时间【类】├───── IncrementingWaitStrategy // 根据初始值和指定值，每次重试增加指定值时间【类】└───── RandomWaitStrategy // 指定一个时间范围，每次在其中进行随机取值【类】 其中提供了很多可以直接使用的策略类，当不满足我们需求的时候，也可以自己实现对应的接口来扩展","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"异常重试","slug":"异常重试","permalink":"https://zhengw-tech.com/tags/异常重试/"},{"name":"guava-retrying","slug":"guava-retrying","permalink":"https://zhengw-tech.com/tags/guava-retrying/"}]},{"title":"Java项目中使用Groovy的几种方式","slug":"groovy-script","date":"2023-03-25T09:23:17.000Z","updated":"2023-05-27T13:21:12.913Z","comments":true,"path":"2023/03/25/groovy-script/","link":"","permalink":"https://zhengw-tech.com/2023/03/25/groovy-script/","excerpt":"Groovy本身是一门完整的编程语言，同时也可以作为脚本集成到我们的应用中，为静态语言提供一些动态的能力，比如将 groovy 的脚本放到一些动态配置中或者数据库中进行管理，实现一些动态的规则计算等，在规则新增或变更的时候可以实时更新而无需开发代码上线，这次主要介绍一下Java中如何使用Groovy脚本 关于在应用中集成Groovy，官方文档已经提供了相关的资料，本次基于此文档进行一下说明 首先需要引入相应的包，这里基于的版本是3.0.16 12345&lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;3.0.16&lt;/version&gt;&lt;/dependency&gt;","text":"Groovy本身是一门完整的编程语言，同时也可以作为脚本集成到我们的应用中，为静态语言提供一些动态的能力，比如将 groovy 的脚本放到一些动态配置中或者数据库中进行管理，实现一些动态的规则计算等，在规则新增或变更的时候可以实时更新而无需开发代码上线，这次主要介绍一下Java中如何使用Groovy脚本 关于在应用中集成Groovy，官方文档已经提供了相关的资料，本次基于此文档进行一下说明 首先需要引入相应的包，这里基于的版本是3.0.16 12345&lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;3.0.16&lt;/version&gt;&lt;/dependency&gt; EvalEval是最简单的一种用法 12345678910111213141516171819import groovy.util.Eval;// 1.执行没有参数的表达式，其中可以调用方法Eval.me(\"33*3\"); // 99Eval.me(\"'foo'.toUpperCase()\"); // FOO// 2. 执行有一个参数的表达式// x赋值为4，执行表达值（变量名固定为x）Eval.x(4, \"2 * x\"); // 8// k赋值为4，，执行表达值（自定义变量名，并在脚本中使用）Eval.me(\"k\", 4, \"2 * k\"); // 8// 3. 执行有两个参数的表达式// x赋值为4， y赋值为6，执行表达值（变量名固定依次为x、y）Eval.xy(4, 5, \"x * y\"); // 20// 3. 执行有三个参数的表达式// x赋值为4， y赋值为6，z赋值为6，执行表达值（变量名固定依次为x、y、z）Eval.xyz(4, 5, 6, \"x * y + z\"); // 26 表达式中可以调用自定义类的方法，如 123456789101112131415@Data@AllArgsConstructorstatic class Goods &#123; private String goodsName; private BigDecimal price; private Integer num; public BigDecimal totalPrice() &#123; return price.multiply(new BigDecimal(num)); &#125;&#125;Goods goods = new Goods(\"goods1\", new BigDecimal(\"100.54\"), 5);Object result = Eval.me(\"goods\", goods, \"goods.totalPrice()\");// result == 502.70 同时，表达式中也支持多行 123456Object result = Eval.me(\"def i = 5; def j = 6; i + j\");// result == 11// 甚至可以定义函数并执行(定义函数之后，需要手动调用函数才能执行)Object result = Eval.me(\"def run1() &#123;def i = 5;def j = 's'; j + i&#125;; run1()\");// result == s5 但是使用Eval需要注意，它是不支持缓存的，每次执行都会创建类（会占用永久代/元空间），虽然占用的空间在GC的时候会被回收，不过表达式需要频繁执行的话，还是尽量不要使用 GroovyShellGroovyShell可以认为是Eval的升级版，主要有如下几个方面的改进 支持多种脚本来源，而不仅仅只能通过字符串传递脚本 12URI uri = new URL(\"https://example.test/script.groovy\").toURI();Object evaluate = groovyShell.evaluate(uri); 支持设置和返回更多的参数 123456789101112131415// 通过bindng传递参数给ShellBinding sharedData = new Binding();GroovyShell shell = new GroovyShell(sharedData);sharedData.setProperty(\"text\", \"I am shared data\");sharedData.setProperty(\"num\", 10);Object result = shell.evaluate(\"text + ': ' + num\");// I am shared data: 10Binding sharedData = new Binding();GroovyShell shell = new GroovyShell(sharedData);// 脚本中的变量如果前面有def或者int等声明，则无法通过Binding获取Object result = shell.evaluate(\"i = 10; i + 1\");// result == 11Object i = sharedData.getProperty(\"i\");// i == 10 可以先解析脚本，延迟执行 123456789101112// 解析脚本，生成ScriptGroovyShell shell = new GroovyShell();Script script = shell.parse(\"4 * num\");// 给Script绑定变量Binding binding = new Binding();binding.setProperty(\"num\", 7);script.setBinding(binding);// 执行脚本Object run = script.run();// run == 28 GroovyShell每次执行时也是会创建新的类，解析创建的Script实例是可以进行缓存的，避免每次都加载新的类和创建对应实例，但是因为涉及到外部绑定的变量，所以如果变量有变更，在并发的情况下会有问题，不能在并发情况下使用 GroovyClassLoader之前说过的不管是 Eval 还是 GroovyShell ，它们最终都是使用 GroovyClassLoader进行脚本的解析、创建并加载类来执行的 12345678910111213141516171819202122GroovyClassLoader classLoader = new GroovyClassLoader();Class aClass = classLoader.parseClass(\"class Foo &#123;String doIt() &#123;return \\\"ok\\\"&#125;&#125;\");Object object = aClass.newInstance();Method method = object.getClass().getDeclaredMethod(\"doIt\");Object invoke = method.invoke(object);// invoke == \"ok\"// 解析类的脚本，也不一定非要使用class来定义，如下定义方式也是可以使用的（默认解析为Script类，会有run方法）GroovyClassLoader classLoader = new GroovyClassLoader();Class aClass = classLoader.parseClass(\"def doIt(i) &#123;return \\\"ok \\\" + i&#125;\");Object object = aClass.newInstance();Method method = object.getClass().getDeclaredMethod(\"doIt\", Object.class);Object invoke = method.invoke(object, 6);// invoke == \"ok 6\"// 对于没有参数的场景，甚至可以这样写（默认解析为Script类，会有run方法）GroovyClassLoader classLoader = new GroovyClassLoader();Class aClass = classLoader.parseClass(\"3 + 5\");Script object = (Script) aClass.newInstance();Object result = object.run();// result == 8 使用这种方式的时候，我们可以缓存创建的实例和对应的方法，之后就可以根据这两个信息进行方法的调用了，同时如果脚本类写的没有问题时，也不会有并发的问题 以上就是在 Java 项目中使用 Groovy脚本的几种主要方式，大家可以根据具体的使用场景进行选择，尽量缓存创建的实例","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"groovy","slug":"groovy","permalink":"https://zhengw-tech.com/tags/groovy/"}]},{"title":"Gson原理分析-JsonReader","slug":"gson","date":"2023-01-20T03:08:24.000Z","updated":"2023-01-25T01:44:28.133Z","comments":true,"path":"2023/01/20/gson/","link":"","permalink":"https://zhengw-tech.com/2023/01/20/gson/","excerpt":"java语言下，进行json处理的工具类jackson, fastjson, gson等，使用起来比较简单，就不介绍了，这次我们就来探索一下其中gson的具体实现，其核心处理类为JsonReader和JsonWriter进行json格式数据的读取和写入，上层TypeAdapter使用其进行json和具体数据类型的转换，而Gson调用时会根据类型获取到具体的TypeAdapter进行使用","text":"java语言下，进行json处理的工具类jackson, fastjson, gson等，使用起来比较简单，就不介绍了，这次我们就来探索一下其中gson的具体实现，其核心处理类为JsonReader和JsonWriter进行json格式数据的读取和写入，上层TypeAdapter使用其进行json和具体数据类型的转换，而Gson调用时会根据类型获取到具体的TypeAdapter进行使用 在将json字符串转换成Java对象时，首先需要有定义Java的类，这里我们先不定义，而是使用一种更通用的，将json字符串转换成JsonElement的方法(com.google.gson.JsonParser#parseString)实现 123456789101112131415161718192021222324252627282930313233343536373839// JsonParser.javapublic static JsonElement parseReader(JsonReader reader) throws JsonIOException, JsonSyntaxException &#123; boolean lenient = reader.isLenient(); reader.setLenient(true); try &#123; // 1. 调用Streams的方法 return Streams.parse(reader); &#125; catch (StackOverflowError e) &#123; throw new JsonParseException(\"Failed parsing JSON source: \" + reader + \" to Json\", e); &#125; catch (OutOfMemoryError e) &#123; throw new JsonParseException(\"Failed parsing JSON source: \" + reader + \" to Json\", e); &#125; finally &#123; reader.setLenient(lenient); &#125;&#125;// Streams.javapublic static JsonElement parse(JsonReader reader) throws JsonParseException &#123; boolean isEmpty = true; try &#123; reader.peek(); isEmpty = false; // 2. 使用 TypeAdapters.JSON_ELEMENT 进行读取 return TypeAdapters.JSON_ELEMENT.read(reader); &#125; catch (EOFException e) &#123; if (isEmpty) &#123; return JsonNull.INSTANCE; &#125; // The stream ended prematurely so it is likely a syntax error. throw new JsonSyntaxException(e); &#125; catch (MalformedJsonException e) &#123; throw new JsonSyntaxException(e); &#125; catch (IOException e) &#123; throw new JsonIOException(e); &#125; catch (NumberFormatException e) &#123; throw new JsonSyntaxException(e); &#125;&#125; 最终调用如下Adapter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111// TypeAdapters.javapublic static final TypeAdapter&lt;JsonElement&gt; JSON_ELEMENT = new TypeAdapter&lt;JsonElement&gt;() &#123; /** * 读取对象或者数组 */ private JsonElement tryBeginNesting(JsonReader in, JsonToken peeked) throws IOException &#123; switch (peeked) &#123; case BEGIN_ARRAY: in.beginArray(); return new JsonArray(); case BEGIN_OBJECT: in.beginObject(); return new JsonObject(); default: return null; &#125; &#125; /** 读取基础类型和null */ private JsonElement readTerminal(JsonReader in, JsonToken peeked) throws IOException &#123; switch (peeked) &#123; case STRING: return new JsonPrimitive(in.nextString()); case NUMBER: String number = in.nextString(); return new JsonPrimitive(new LazilyParsedNumber(number)); case BOOLEAN: return new JsonPrimitive(in.nextBoolean()); case NULL: in.nextNull(); return JsonNull.INSTANCE; default: throw new IllegalStateException(\"Unexpected token: \" + peeked); &#125; &#125; // 3. 进行json数据读取 // 总结一下就是使用peek，后根据peek的结果来调用对应的方法进行读取使用 @Override public JsonElement read(JsonReader in) throws IOException &#123; if (in instanceof JsonTreeReader) &#123; return ((JsonTreeReader) in).nextJsonElement(); &#125; // JsonArray 或者 JsonObject JsonElement current; JsonToken peeked = in.peek(); // 根据peeked结果，判断类型后创建JsonObject或者JsonArray current = tryBeginNesting(in, peeked); if (current == null) &#123; // 如果是基础类型，则直接读取后返回 return readTerminal(in, peeked); &#125; // 这部分之前低版本是使用递归来实现的，这里是使用栈来实现 // 之前的递归代码阅读起来比较容易，这里调整可能是为了防止堆栈溢出? Deque&lt;JsonElement&gt; stack = new ArrayDeque&lt;&gt;(); while (true) &#123; while (in.hasNext()) &#123; String name = null; // 之前读取的是类型是对象时，接着获取对象的key if (current instanceof JsonObject) &#123; name = in.nextName(); &#125; // 查看一下key对应的value值(此时没有真正读取值)，判断一下值结构 peeked = in.peek(); JsonElement value = tryBeginNesting(in, peeked); // value是对象或者数组时，则认为是嵌套结构 boolean isNesting = value != null; // key对应的value不是对象或者数组结构，则认为是基础类型进行读取 if (value == null) &#123; value = readTerminal(in, peeked); &#125; // 根据结构(对象或者数组)，进行数据的添加 if (current instanceof JsonArray) &#123; ((JsonArray) current).add(value); &#125; else &#123; ((JsonObject) current).add(name, value); &#125; if (isNesting) &#123; // value是对象或者数组，则将此次结果记录到队列中，下个循环开始解析value中的信息 stack.addLast(current); current = value; &#125; &#125; // 最后根据结构调用关闭读取方法 if (current instanceof JsonArray) &#123; in.endArray(); &#125; else &#123; in.endObject(); &#125; if (stack.isEmpty()) &#123; return current; &#125; else &#123; // 之前的while循环中，嵌套结构(深度优先)已经处理完成，这里依次再进行出栈后解析(广度) current = stack.removeLast(); &#125; &#125; &#125; @Override public void write(JsonWriter out, JsonElement value) throws IOException &#123; // TODO write部分这次先不进行查看分析 &#125;&#125;;","categories":[],"tags":[{"name":"json","slug":"json","permalink":"https://zhengw-tech.com/tags/json/"},{"name":"gson","slug":"gson","permalink":"https://zhengw-tech.com/tags/gson/"}]},{"title":"MyBatis插件开发使用","slug":"mybatis-plugin","date":"2022-12-24T02:25:13.000Z","updated":"2022-12-24T03:57:57.952Z","comments":true,"path":"2022/12/24/mybatis-plugin/","link":"","permalink":"https://zhengw-tech.com/2022/12/24/mybatis-plugin/","excerpt":"MyBatis允许我们在其执行过程中对特定的一些方法进行拦截代理，实现一些特定的通用功能，如分页插件或者租户插件，允许进行拦截的类及对应方法基本如下 Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query)","text":"MyBatis允许我们在其执行过程中对特定的一些方法进行拦截代理，实现一些特定的通用功能，如分页插件或者租户插件，允许进行拦截的类及对应方法基本如下 Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 这部分可以在源码中找到 12345678910111213141516171819202122232425262728293031323334353637383940// Configuration.javapublic ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); // 对类进行代理拦截 parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler;&#125;public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); // 对类进行代理拦截 resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler;&#125;public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); // 对类进行代理拦截 statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125;public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; // 对类进行代理拦截 executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 要想更好的使用MyBatis的插件功能，首先需要对拦截到的类和方法进行了解，以一次查询为例我们看一下相关流程 Executor: Executor是SqlSession中执行功能使用到的类，如查询时，首先从Configuration或获取MappedStatement（可以认为是对应的mapper.xml中的 SELECT节点信息），之后和具体的参数值一起传递给Executor的query方法使用 12// Executor.java&lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException; StatementHandler: Executor具体执行时，默认会使用StatementHandler的prepare对要执行的SQL创建预编译的Statement，之后使用parameterize设置参数 12345678910111213141516171819202122// SimpleExecutor.javapublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125;private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection = getConnection(statementLog); // 预编译 stmt = handler.prepare(connection, transaction.getTimeout()); // 设置参数 handler.parameterize(stmt); return stmt;&#125; 在StatementHandler执行parameterize，默认会使用ParameterHandler#setParameters来对预编译结果继续进行参数设置 之后再调用StatementHandler#query方法来进行查询，最后使用ResultSetHandler#handleResultSets对查询结果进行处理 分析了流程之后，我们就可以根据自己的需求在指定方法上面进行拦截处理，如我们想要统一在数据库层面设置某一个字段值(如创建人信息)，那么就可以拦截Executor#update方法，对其中的参数进行修改赋值 这里我们以一个最简单的分页插件功能为例，看一下如何实现使用一个插件 一般分页我们可以拦截Executor相关的方法，但是这里为了简单，我们就处理StatementHandler#prepare方法，在进行预编译sql前，将sql进行修改，这样执行的就是分页后的sql了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 需要添加拦截器注解@Intercepts(&#123; // 这里需要声明拦截的类，方法名称、参数信息 @Signature(type = StatementHandler.class, method = \"prepare\", args = &#123;Connection.class, Integer.class&#125;)&#125;)public class DemoInterceptor implements Interceptor &#123; private static ThreadLocal&lt;Page&gt; pageThreadLocal = new ThreadLocal&lt;&gt;(); public static void page(Integer page, Integer size) &#123; final Page p = new Page(); p.setPage(page); p.setSize(size); pageThreadLocal.set(p); &#125; @Override public Object intercept(Invocation invocation) throws Throwable &#123; final Page page = pageThreadLocal.get(); if (page == null) &#123; return invocation.proceed(); &#125; try &#123; final int offset = (page.getPage() - 1) * page.getSize(); final StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); final BoundSql boundSql = statementHandler.getBoundSql(); final String sql = boundSql.getSql(); // 修改SQL数据后重新赋值回去 String newSql = sql + \" limit \" + page.getSize() + \" offset \" + offset; final MetaObject metaObject = SystemMetaObject.forObject(boundSql); metaObject.setValue(\"sql\", newSql); &#125; finally &#123; pageThreadLocal.remove(); &#125; return invocation.proceed(); &#125; static class Page &#123; private Integer page; private Integer size; public Integer getPage() &#123; return page; &#125; public void setPage(Integer page) &#123; this.page = page; &#125; public Integer getSize() &#123; return size; &#125; public void setSize(Integer size) &#123; this.size = size; &#125; &#125;&#125; 之后在mybatis的配置文件中配置上此插件 123&lt;plugins&gt; &lt;plugin interceptor=\"com.zavier.demo.interceptor.DemoInterceptor\" /&gt;&lt;/plugins&gt; 再执行查询前，如果设置了分页信息则最终SQL会有相关的分页信息","categories":[],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://zhengw-tech.com/tags/mybatis/"}]},{"title":"Hive解析json数据","slug":"hive-json","date":"2022-11-11T14:49:55.000Z","updated":"2023-03-28T13:09:05.703Z","comments":true,"path":"2022/11/11/hive-json/","link":"","permalink":"https://zhengw-tech.com/2022/11/11/hive-json/","excerpt":"我们平时在使用关系数据库存储数据时，在某种情况下可能会有使用字符串类的字段来存储json格式的数据，然后在代码里面进行解析处理等，这样比较方便扩展，但是在使用数据进行分析等场景下就会很不方便，这时候就需要对json进行一些解析的操作，这次主要看下如何使用Hive来解析json格式的数据","text":"我们平时在使用关系数据库存储数据时，在某种情况下可能会有使用字符串类的字段来存储json格式的数据，然后在代码里面进行解析处理等，这样比较方便扩展，但是在使用数据进行分析等场景下就会很不方便，这时候就需要对json进行一些解析的操作，这次主要看下如何使用Hive来解析json格式的数据 get_json_objectHive为我们提供了get_json_object函数，可以指定路径来获取json字符串中的属性值，如 12345678910111213-- 处理对象select get_json_object('&#123;\"name\":\"zhangsan\", \"age\":10&#125;', '$.name')-- 输出: zhangsan-- 如果需要获取对象中的多个数据，可以使用json_tupleselect json_tuple('&#123;\"name\":\"zhangsan\", \"age\":10&#125;', 'name', 'age')-- 输出: zhangsan 10-- 处理数组select get_json_object('[\"ab\", \"cd\"]', '$.[0]')-- 输出: ab-- 处理对象数组select get_json_object('[&#123;\"name\":\"zhangsan\", \"age\":10&#125;,&#123;\"name\":\"lisi\", \"age\":15&#125;]', '$.[1].name')-- 输出: lisi 以上这种方式基本就能满足获取指定位置数据的需求了 explode在实际使用时，我们可能需要将json拆开解析成一张宽表，方便后面的分析使用，这时候我们需要遍历json字符串中的全部数据，然后与其他字段值做笛卡尔积，下面我们看下这种的实现方式 这里先介绍一下 explode这个函数，这个函数的作用是什么呢？它可以将array类型的数据转换成每个元素占用一行，对于map类型的数据可以将其每个键值对转换成一行（注意：这里说的array和map不是说的字符串类型的json数据，而是指hive自己的字段类型），我们执行看一下效果 先创建对应的表结构，并插入数据 1234567create table page_view (userid int, friends array&lt;int&gt;, properties map&lt;string, string&gt;);insert into table page_view values (1, array(1,2,3), map('a', 'b', 'c', 'd')), (10, array(10,20,30), map('af', 'bf', 'cg', 'dg'));select * from page_view;/* 输出 *1 [1,2,3] &#123;\"a\":\"b\",\"c\":\"d\"&#125;10 [10,20,30] &#123;\"af\":\"bf\",\"cg\":\"dg\"&#125;*/ 这里我们用 explode 来处理一下 friends 和 properties列看一下 12345678910111213141516171819-- 处理list数据，转成单列多行select explode(friends) as f from page_view;/** 输出 **123102030*/-- 处理map数据，转成两列(k-v)多行数据select explode(properties) as (m, n) from page_view;/** 输出 **a bc daf bfcg dg*/ 这个函数只能处理对应的map和array结构，我们可以通过split函数将字符串处理后，转换成array类型；通过str_to_map将字符串转换为map类型 1234567-- 使用split将字符串变成list结构select split('1,2,3,4', ',');-- 输出：[\"1\", \"2\", \"3\", \"4\"]-- 使用str_to_map将字符串变成map结构select str_to_map('a:b,c:d');-- 输出：&#123;\"a\":\"b\",\"c\":\"d\"&#125; 对于json格式的字符串与此函数支持的数据格式不同的地方，可以使用regexp_replace等字符串函数处理后使用 1234select replace(replace('[12,45,67]', '[', ''), ']', '');-- 输出：12,45,67select substr('[12,45,67]', 2, length('[12,45,67]')-2);-- 输出：12,45,67 lateral viewexplode还有一个问题就是无法与表中的其他字段同时获取，即查询到的结果只能是explode涉及到的字段，如之前的page_view表，使用explode后就无法同时获取到userid字段的值 这时候就需要 lateral view，它结合 explode结合使用，可以帮我们把数据进行组合 格式：lateral view explode(&lt;map/array&gt;) &lt;tableAlias&gt; as &lt;col&gt; 12345select userid, m, n from page_view lateral view explode(properties) t as m, n where userid = 10;/* 输出 *10 af bf10 cg dg*/ 总结一下 简单的场景，可以直接通过get_json_object配置jsonPath来获取到对应的值 复杂的场景 先通过字符串处理函数将字符串数据转换成map或list 再使用explode将list/map转成多行数据 结合 lateral view 与 explode 将多行数据与其他字段进行组合，获取最终结果","categories":[],"tags":[{"name":"json","slug":"json","permalink":"https://zhengw-tech.com/tags/json/"},{"name":"hive","slug":"hive","permalink":"https://zhengw-tech.com/tags/hive/"},{"name":"jsonpath","slug":"jsonpath","permalink":"https://zhengw-tech.com/tags/jsonpath/"}]},{"title":"Java对象比对实现","slug":"java-bean-diff","date":"2022-09-17T06:53:53.000Z","updated":"2022-09-18T05:55:34.610Z","comments":true,"path":"2022/09/17/java-bean-diff/","link":"","permalink":"https://zhengw-tech.com/2022/09/17/java-bean-diff/","excerpt":"有时候我们需要对于同一个类的两个实例对象进行一下数据内容的比对，找出他们的差异，比如用来做单测或者同一份数据多版本的内容比对，这里主要介绍使用apache的commons-lang3的工具类来进行功能实现","text":"有时候我们需要对于同一个类的两个实例对象进行一下数据内容的比对，找出他们的差异，比如用来做单测或者同一份数据多版本的内容比对，这里主要介绍使用apache的commons-lang3的工具类来进行功能实现 首先需要引入如下包依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.12.0&lt;/version&gt;&lt;/dependency&gt; 使用时需要实现Diffable接口，并使用DiffBuilder来构建比对结果 1234567891011121314public class Person implements Diffable&lt;Person&gt; &#123; String name; int age; boolean smoker; public DiffResult diff(Person obj) &#123; // obj可能为null，这里可以自行判断处理 return new DiffBuilder(this, obj, ToStringStyle.JSON_STYLE) .append(\"name\", this.name, obj.name) .append(\"age\", this.age, obj.age) .append(\"smoker\", this.smoker, obj.smoker) .build(); &#125;&#125; 运行测试一下 1234567final Person aa = new Person(\"aa\", 12, true);final Person bb = new Person(\"bb\", 12, false);final DiffResult diff = aa.diff(bb);System.out.println(diff);// 结果输出如下// &#123;\"name\":\"aa\",\"smoker\":true&#125; differs from &#123;\"name\":\"bb\",\"smoker\":false&#125; 这种对于简单的属性是OK的，对于嵌套的可比较类可以使用如下方式 1234567891011121314151617181920212223242526272829303132// 使用 DiffBuilder#append(String, DiffResult&lt;T&gt;)public class Person implements Diffable&lt;Person&gt; &#123; String name; int age; boolean smoker; // Address是一个可比较的类 Address address; public DiffResult diff(Person obj) &#123; // obj可能为null，这里可以自行判断处理 return new DiffBuilder(this, obj, ToStringStyle.JSON_STYLE) .append(\"name\", this.name, obj.name) .append(\"age\", this.age, obj.age) .append(\"smoker\", this.smoker, obj.smoker) // 这里可以直接设置比对结果到address中 .append(\"address\", this.address.diff(obj.getAddress())) .build(); &#125;&#125;@Datapublic class Address implements Diffable&lt;Address&gt; &#123; private String province; private String city; @Override public DiffResult diff(Address obj) &#123; return new DiffBuilder(this, obj, ToStringStyle.MULTI_LINE_STYLE) .append(\"province\", this.getProvince(), obj.getProvince()) .append(\"city\", this.getCity(), obj.getCity()) .build(); &#125;&#125; 结果样例如下 1&#123;\"age\":13,\"address.city\":\"c1\"&#125; differs from &#123;\"age\":14,\"address.city\":\"c2\"&#125; 整体功能到这里基本就实现了，但是对于其中的diff方法中的很多append手写起来比较麻烦，我们可以写一个工具类来简化代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DiffUtils&lt;T&gt; &#123; public static &lt;T&gt; DiffResult&lt;T&gt; buildResult(T baseObj, T compareObj, String... excludeFields) &#123; try &#123; final DiffBuilder&lt;T&gt; diffBuilder = new DiffBuilder&lt;&gt;(baseObj, compareObj, ToStringStyle.JSON_STYLE); // 这里使用的JavaBean相关的工具类，所以要去比对对象需要符合JavaBean的规范 // 也可以替换成使用反射相关方法，来支持非JavaBean的比较 final BeanInfo beanInfo = Introspector.getBeanInfo(baseObj.getClass()); final PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) &#123; if (isExcludeField(propertyDescriptor.getName(), excludeFields)) &#123; continue; &#125; final Method readMethod = propertyDescriptor.getReadMethod(); final Object obj1 = readMethod.invoke(baseObj); final Object obj2 = readMethod.invoke(compareObj); if (obj1 instanceof Diffable) &#123; Diffable diffable1 = (Diffable) obj1; Diffable diffable2 = (Diffable) obj2; diffBuilder.append(propertyDescriptor.getName(), diffable1.diff(diffable2)); &#125; else &#123; diffBuilder.append(propertyDescriptor.getName(), obj1, obj2); &#125; &#125; return diffBuilder.build(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; private static boolean isExcludeField(String fieldName, String... excludeFields) &#123; if (excludeFields == null || excludeFields.length == 0) &#123; return false; &#125; for (String excludeField : excludeFields) &#123; if (excludeField.equalsIgnoreCase(fieldName)) &#123; return true; &#125; &#125; return false; &#125;&#125; 这样实现的代码就可以简化为 12345678910public class Person implements Diffable&lt;Person&gt; &#123; String name; int age; boolean smoker; public DiffResult diff(Person obj) &#123; // 使用工具类来构建 return DiffUtils.buildResult(this, obj); &#125;&#125; 目前还有一个问题，就是其中属性如果是对象的集合，那么比较起来会有点问题，效果大致是这样的 1&#123;\"addressList\":[\"Address(province=aa, city=bb)\",\"Address(province=bb, city=cc)\"],\"name\":\"aa\",\"smoker\":true&#125; differs from &#123;\"addressList\":[\"Address(province=aa, city=bb)\",\"Address(province=bb, city=dd)\"],\"name\":\"bb\",\"smoker\":false&#125; 这种可能就需要我们根据实际的需求，进行相关的功能改造来进行支持，或者将commons-lang3中的相关代码复制出来进行改造","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"diff","slug":"diff","permalink":"https://zhengw-tech.com/tags/diff/"}]},{"title":"JSONPath简介","slug":"json-path","date":"2022-09-11T14:43:19.000Z","updated":"2023-03-28T14:17:04.891Z","comments":true,"path":"2022/09/11/json-path/","link":"","permalink":"https://zhengw-tech.com/2022/09/11/json-path/","excerpt":"JSON目前是使用的比较多的一种数据格式，前后端的交互就是都是使用JSON格式，后端存储的时候就算使用MySQL，有时候也会存在使用字符串等类型字段存储JSON数据（现在MySQL也支持了JSON类型字段并提供相关的语法） JSONPath比较适合使用在一些结构不确定，或者比较灵活的场景下，从json中获取想要的数据 有一些变更频繁的扩展类的非核心数据，可以直接当做一个json字符串进行存储，在获取的数据可以通过配置的JsonPath来从其中进行取值使用 在做类似网关等场景下，可以通过配置JsonPath完成数据的转换，当然如果转换逻辑特别复杂时可能还是模版引擎更合适一些","text":"JSON目前是使用的比较多的一种数据格式，前后端的交互就是都是使用JSON格式，后端存储的时候就算使用MySQL，有时候也会存在使用字符串等类型字段存储JSON数据（现在MySQL也支持了JSON类型字段并提供相关的语法） JSONPath比较适合使用在一些结构不确定，或者比较灵活的场景下，从json中获取想要的数据 有一些变更频繁的扩展类的非核心数据，可以直接当做一个json字符串进行存储，在获取的数据可以通过配置的JsonPath来从其中进行取值使用 在做类似网关等场景下，可以通过配置JsonPath完成数据的转换，当然如果转换逻辑特别复杂时可能还是模版引擎更合适一些 使用我们先看下JSONPath的使用，这里使用的是https://github.com/json-path/JsonPath，其README中已经提供了相关的介绍和使用示例，这里再简单介绍下，我们这里直接使用其中的示例数据 12345678910111213141516171819202122232425262728293031323334353637&#123; \"store\": &#123; \"book\": [ &#123; \"category\": \"reference\", \"author\": \"Nigel Rees\", \"title\": \"Sayings of the Century\", \"price\": 8.95 &#125;, &#123; \"category\": \"fiction\", \"author\": \"Evelyn Waugh\", \"title\": \"Sword of Honour\", \"price\": 12.99 &#125;, &#123; \"category\": \"fiction\", \"author\": \"Herman Melville\", \"title\": \"Moby Dick\", \"isbn\": \"0-553-21311-3\", \"price\": 8.99 &#125;, &#123; \"category\": \"fiction\", \"author\": \"J. R. R. Tolkien\", \"title\": \"The Lord of the Rings\", \"isbn\": \"0-395-19395-8\", \"price\": 22.99 &#125; ], \"bicycle\": &#123; \"color\": \"red\", \"price\": 19.95 &#125; &#125;, \"expensive\": 10&#125; JSONPath的表达式都是以 $ 开始，表示根节点 属性值获取：子节点可以使用 .&lt;name&gt; 来进行表示，如: $.store.bicycle.color 或者 $[&#39;store&#39;][&#39;bicycle&#39;][&#39;color&#39;]可以获取其中的color值 获取多个属性值：JSONPath表达式最后一级子节点可以同时获取多个值，如 $[&#39;store&#39;][&#39;bicycle&#39;][&#39;color&#39;, &#39;price&#39;] 数组数据获取：可以根据索引获取指定位置元素，如： $.store.book[0,1] 或者 $.store.book[:2] 或者 $.store.book[-1] 可以使用通配符*进行匹配，如：$.store.book[*] 或者 $.store.bicycle.* 深度查找可以使用..&lt;name&gt;来对属性进行查找，而不管它的具体位置，如：$..price 属性/数组过滤可以使用[?(&lt;expression&gt;)]，其中的表达式需要能解析为boolean值，如：$.store.bicycle[?(@.color==&#39;red&#39;)] 或者 $.store.book[?(@.price &lt; 10)] 函数使用：可以使用lengh()等函数，如：$.store.book.length() 、$.numbers.sum() 相关API用法如下： 12345678910final JsonPath compile = JsonPath.compile(\"$.store.book[0].author\");String json = \"...\";final String author = compile.read(json);// 或者如果不重复使用的话，可以直接写成一步List&lt;String&gt; authors = JsonPath.read(json, \"$.store.book[*].author\");// 函数使用（需要注意函数能作用的数据类型，如 min(), max(), sum()等只能作用于数值数组）String json = \"&#123;\\\"numbers\\\":[1,3,4,7,-1]&#125;\";final Object read = JsonPath.read(json, \"$.numbers.sum()\"); // 输出：14.0 除此之外，JsonPath还提供了一些额外的配置项，以仓库中的json为例子 123456789[ &#123; \"name\" : \"john\", \"gender\" : \"male\" &#125;, &#123; \"name\" : \"ben\" &#125;] DEFAULT_PATH_LEAF_TO_NULL 叶子节点找不到时默认为null： 正常情况下通过Path找不到数据值，JsonPath会抛出异常（使用了通配符如[*]等除外，这种找不到路径是会返回空集合），增加此配置后在叶子结点找不到数据时会返回null 而不是异常（仅限叶子结点，中间节点不存在时仍然会抛出异常） 123Configuration configuration = Configuration.builder().options(Option.DEFAULT_PATH_LEAF_TO_NULL).build();Object data = JsonPath.using(configuration).parse(json).read(\"$[1]['gender']\");// data == null ALWAYS_RETURN_LIST 不管JsonPath获取的结果是单个值还是集合，都会包装成集合返回 123Configuration configuration = Configuration.builder().options(Option.DEFAULT_PATH_LEAF_TO_NULL, Option.ALWAYS_RETURN_LIST).build();Object data = JsonPath.using(configuration).parse(json).read(\"$[*]['gender']\");// data == [\"male\",null] SUPPRESS_EXCEPTIONS 当处理发生异常时，如果配置了 ALWAYS_RETURN_LIST，则返回空集合，否则返回null 123Configuration configuration = Configuration.builder().options(Option.ALWAYS_RETURN_LIST, Option.SUPPRESS_EXCEPTIONS).build();Object data = JsonPath.using(configuration).parse(json).read(\"$[0]['abc']['def']\");// data = [] REQUIRE_PROPERTIES 路径中属性不存在时，会抛出异常，因为本身路径不存在就会抛出异常，所以这个配置主要体现在配置通配符的场景下，且如果同时配置了 SUPPRESS_EXCEPTIONS， 则 SUPPRESS_EXCEPTIONS 优先（不会抛出异常） 123Configuration configuration = Configuration.builder().options(Option.ALWAYS_RETURN_LIST).build();Object data = JsonPath.using(configuration).parse(json).read(\"$[*]['gender']\");// 抛出异常 以上主要是读取的操作，同时它还支持对数据进行修改，调用对应的set方法即可 1String newJson = JsonPath.parse(json).set(\"$['store']['book'][0]['author']\", \"Paul\").jsonString(); 实现简介使用方法基本如下，下面大概说一下它的实现 先将JSONPath表达式进行编译解析为一系列的token，并按顺序使用链表连接起来 解析json时，依次调用每个token的解析方法，将自己所在层解析出来后，将解析结果交给之后的token继续进行处理，像剥洋葱一样层层解析 解析过程中使用配置的json工具类来对数据进行查询操纵 到最后一个节点后，使用 EvaluationContent对结果进行收集结束 其中包含的token有如下几类 RootPathToken，根节点，支持表达式：$ PropertyPathToken，支持表达式: .&lt;name&gt; 或 [&#39;&lt;name1&gt;&#39; (,&#39;&lt;name2&gt;&#39;)] ArrayIndexToken，支持表达式：[&lt;number&gt; (, &lt;number&gt;)] ArraySliceToken，支持表达式：[start:end] WildcardPathToken，支持表达式： * 或者 [*] PredicatePathToken，支持表达式：[?(&lt;expresion&gt;)] ScanPathToken，支持表达式：..&lt;name&gt; FunctionPathToken，用于支持内置的函数 这样就可以将对应的表达式映射成一系列的token，然后依次解析 123456789101112131415161718192021222324252627// PathCompiler.javaprivate boolean readNextToken(PathTokenAppender appender) &#123; char c = path.currentChar(); switch (c) &#123; case OPEN_SQUARE_BRACKET: if (!readBracketPropertyToken(appender) &amp;&amp; !readArrayToken(appender) &amp;&amp; !readWildCardToken(appender) &amp;&amp; !readFilterToken(appender) &amp;&amp; !readPlaceholderToken(appender)) &#123; fail(\"Could not parse token starting at position \" + path.position() + \". Expected ?, ', 0-9, * \"); &#125; return true; case PERIOD: if (!readDotToken(appender)) &#123; fail(\"Could not parse token starting at position \" + path.position()); &#125; return true; case WILDCARD: if (!readWildCardToken(appender)) &#123; fail(\"Could not parse token starting at position \" + path.position()); &#125; return true; default: if (!readPropertyOrFunctionToken(appender)) &#123; fail(\"Could not parse token starting at position \" + path.position()); &#125; return true; &#125;&#125; 我们以获取属性使用的PropertyPathToken来看下解析过程 1234567891011121314151617181920212223242526272829class PropertyPathToken extends PathToken &#123; // 这里是解析JSONPath处理的属性名称 private final List&lt;String&gt; properties; // 这里是解析JSONPath处理的属性包含符号，单引号或者双引号 private final String stringDelimiter; public void evaluate(String currentPath, PathRef parent, Object model, EvaluationContextImpl ctx) &#123; // 使用提供的json工具类判断json是否能转换成一个map if (!ctx.jsonProvider().isMap(model)) &#123; // 不能转成map则跳过或者抛出异常 // 为了看起来简洁一点，这里代码进行了删除，正常json对象解析都是map &#125; // 一般会进入到这里，解析一个或多个属性 if (singlePropertyCase() || multiPropertyMergeCase()) &#123; // 这里调用PathToken中提供的方法 handleObjectProperty(currentPath, model, ctx, properties); return; &#125; assert multiPropertyIterationCase(); final List&lt;String&gt; currentlyHandledProperty = new ArrayList&lt;String&gt;(1); currentlyHandledProperty.add(null); for (final String property : properties) &#123; currentlyHandledProperty.set(0, property); handleObjectProperty(currentPath, model, ctx, currentlyHandledProperty); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536public abstract class PathToken &#123; void handleObjectProperty(String currentPath, Object model, EvaluationContextImpl ctx, List&lt;String&gt; properties) &#123; // 单个属性处理 if(properties.size() == 1) &#123; String property = properties.get(0); String evalPath = Utils.concat(currentPath, \"['\", property, \"']\"); // 调用提供的json工具获取对应的属性值 Object propertyVal = readObjectProperty(property, model, ctx); // 读取结果为空 if(propertyVal == JsonProvider.UNDEFINED)&#123; // 跳过或者抛出异常 // 这里代码我们先忽略 &#125; PathRef pathRef = ctx.forUpdate() ? PathRef.create(model, property) : PathRef.NO_OP; // 如果是最后一个节点(叶子节点)，则收集结果结束 if (isLeaf()) &#123; String idx = \"[\" + String.valueOf(upstreamArrayIndex) + \"]\"; if(idx.equals(\"[-1]\") || ctx.getRoot().getTail().prev().getPathFragment().equals(idx))&#123; ctx.addResult(evalPath, pathRef, propertyVal); &#125; &#125; else &#123; // 否则使用下一个token处理当前解析到的属性值 next().evaluate(evalPath, pathRef, propertyVal, ctx); &#125; &#125; else &#123; // 这里是多个属性的处理逻辑，先忽略，大家有兴趣可以自行看下相关源码 &#125; &#125; // 使用提供的json工具获取对应的属性值 private static Object readObjectProperty(String property, Object model, EvaluationContextImpl ctx) &#123; return ctx.jsonProvider().getMapValue(model, property); &#125;&#125; 以上就是全部内容，整体比较简略，大致介绍了下使用和大概实现，希望抛砖引玉吧 其中如有错误，欢迎指正，感谢～","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"json","slug":"json","permalink":"https://zhengw-tech.com/tags/json/"},{"name":"jsonpath","slug":"jsonpath","permalink":"https://zhengw-tech.com/tags/jsonpath/"}]},{"title":"MyBatis使用原理及配置简化实现","slug":"mybatis-config","date":"2022-06-23T02:06:24.000Z","updated":"2022-06-25T13:28:35.989Z","comments":true,"path":"2022/06/23/mybatis-config/","link":"","permalink":"https://zhengw-tech.com/2022/06/23/mybatis-config/","excerpt":"之前写过一篇mybatis-spring配置及使用的文章，但是其中主要是偏使用的一些内容，这次我们就从根上来分析一下 mybatis配置及核心流程的功能实现，以及后续对它配置的一些优化、简化功能 mybatis为基于3.5.10版本的代码","text":"之前写过一篇mybatis-spring配置及使用的文章，但是其中主要是偏使用的一些内容，这次我们就从根上来分析一下 mybatis配置及核心流程的功能实现，以及后续对它配置的一些优化、简化功能 mybatis为基于3.5.10版本的代码 最简核心配置配置使用首先需要进行mybatis的xml配置 mybatis-config.xml 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/test\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 指定mapper配置文件 --&gt; &lt;mappers&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 接下来进行mapper的配置，这里我们就随意举一个例子吧 12345678// 对应实体类public class UserDO &#123; private Integer id; private String userName; private Integer userAge; // 省略 getter, setter 方法&#125; 123456789101112131415161718&lt;mapper namespace=\"com.zavier.demo.mapper.UserMapper\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.zavier.demo.entity.UserDO\"&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\" /&gt; &lt;result column=\"user_name\" jdbcType=\"VARCHAR\" property=\"userName\" /&gt; &lt;result column=\"user_age\" jdbcType=\"INTEGER\" property=\"userAge\" /&gt; &lt;/resultMap&gt; &lt;insert id=\"save\" parameterType=\"com.zavier.demo.entity.UserDO\"&gt; INSERT INTO t_user (user_name, user_age) VALUES (#&#123;userName&#125;, #&#123;userAge&#125;) &lt;/insert&gt; &lt;select id=\"findById\" parameterType=\"java.lang.Integer\" resultMap=\"BaseResultMap\"&gt; SELECT id, user_name, user_age FROM t_user WHERE id = #&#123;userId&#125; &lt;/select&gt;&lt;/mapper&gt; 配置完成后就可以直接使用了 123456789// 读取MyBatis配置文件InputStream inputStream = Resources.getResourceAsStream(\"mybatis-config.xml\");// 从配置文件中构建 SqlSessionFactory (全局只有一个，用于构建 SqlSession)SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 使用 SqlSessionFactory 创建 SqlSession(请求作用域，用后销毁)SqlSession session = sessionFactory.openSession(true);// 这里可以看出，Mapper接口不是必须的，只要拼接好mapper.xml中的namespace+id，就可以直接进行查询了UserDO user = session.selectOne(\"com.zavier.demo.mapper.UserMapper.findById\", 1); 原理分析创建SqlSessionFactory接下来看一下上面这一段代码都做了什么事情，其中第一步就是构建SqlSessionFactory实例，这个跟进源码可以发现是使用的 XMLConfigBuilder 对 mybatis-config.xml 进行的解析，得到Configuration 12XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);Configuration configuration = parser.parse(); 这个Configuration可以认为包含了mybatis的一切配置信息，包括其中的mapper.xml中的相关信息，在解析创建Configuration的过程中会使用XMLMapperBuilder对mapper.xml文件进行解析，并借助MapperBuilderAssistant 将每个 select|insert|update|delete 节点转换成 MappedStatement，并注册到 Configuration中 12XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());mapperParser.parse(); 123// Configuration.javaprotected final Map&lt;String, MappedStatement&gt; mappedStatements = // 忽略;// 其中的key 就是mapper.xml中的 namespace+id 组成 这样在创建完 SqlSessionFactory 实例后，我们就可以得到一个包含全部配置的Configuration类，同时将数据库操作的节点注册到了其中的 mappedStatements，后续我们进行数据库操作就要依赖这些 mappedStatements 创建Session创建session的代码如下 123456789101112131415161718192021// DefaultSqlSessionFactory.javaprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; // 这里其实可以和mybatis-config.xml中的配置信息映射上 // 通过这几部操作，可以得到 JdbcTransaction, 其中持有数据源 Datasource final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 这里构造核心的执行器，其中持有上一步骤创建的 Transaction final Executor executor = configuration.newExecutor(tx, execType); // 最终再有SqlSession将他们聚合到一起 return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 这几个类间的关系大致如下图 SqlSession查询查询逻辑会进入到如下流程中 1234567891011121314// DefaultSqlSession.javaprivate &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler) &#123; try &#123; // statement为对应的 namespace+id, 如: com.zavier.demo.mapper.UserMapper.findById // 通过Configuration获取到 查询节点对应之前注册的 MappedStatement MappedStatement ms = configuration.getMappedStatement(statement); // 将 mappedStatement及参数等信息传给Executor执行 return executor.query(ms, wrapCollection(parameter), rowBounds, handler); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 接着进入Executor的执行流程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// BaseExecutor.javapublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; // 获取MappedStatement中的sql，绑定参数信息 BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); // 执行查询 return query(ms, parameter, rowBounds, resultHandler, key, boundSql);&#125;// 最终会调用到 SimpleExecutor.java 中的如下方法public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 根据MappedStatement、参数、SQL等信息创建StatementHandler // 默认实现为 PreparedStatementHandler StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); // 这里调用 PreparedStatementHandler的query方法 // 进行SQL执行及结果处理 return handler.query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125;/** * 对于PreparedStatementHandler来说 * 这里相当于进行了获取数据库连接，预编译语句以及设置参数三个步骤 */private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; // 从 Transaction中获取数据库的连接 Connection connection = getConnection(statementLog); // 这里最终会调用到 PreparedStatementHandler中的 instantiateStatement方法 // 其中会执行：connection.prepareStatement(sql) stmt = handler.prepare(connection, transaction.getTimeout()); // 这里会调用 DefaultParameterHandler#setParameters方法 // 最终调用 TypeHandler#setParameter方法进行参数赋值 handler.parameterize(stmt); return stmt;&#125;// 从 Transaction中获取数据库的连接protected Connection getConnection(Log statementLog) throws SQLException &#123; Connection connection = transaction.getConnection(); if (statementLog.isDebugEnabled()) &#123; return ConnectionLogger.newInstance(connection, statementLog, queryStack); &#125; else &#123; return connection; &#125;&#125; 12345678// PreparedStatementHandler.javapublic &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; // 执行 ps.execute(); // 使用 ResultSetHandler进行结果处理转换 return resultSetHandler.handleResultSets(ps);&#125; 这样一次查询请求就执行完成了，整体路径如下 SqlSession 【传递MappedStatement和参数】 Executor【创建并使用StatementHandler查询并转换结果返回】 StatementHandler【使用TypeHandler及ResultSetHandler 处理参数及结果】 Mapper接口支持之前我们的流程里面没有涉及到平时开发中最常用的Mapper接口，其实这个也确实不是必须的，但是如果使用 1UserDO user = session.selectOne(\"com.zavier.demo.mapper.UserMapper.findById\", 1); 这种方式进行查询还是不太方便，所以一般会使用单独的Mapper接口，调用对于的方法即可 配置使用首先需要增加上对应的Mapper接口，注意类的全路径名称要和mapper.xml中的namespace相同，同时方法名称要和其中的具体功能的ID相同，如 12345package com.zavier.demo.mapper;public interface UserMapper &#123; UserDO findById(Integer userId); int save(UserDO userDO);&#125; 之后就可以通过之前的sqlSession来获取mapper执行查询逻辑 1234// 获取对应 MapperUserMapper mapper = session.getMapper(UserMapper.class);// 执行查询UserDO user = mapper.findById(1); 原理分析之前我们说过，mapper.xml文件是由XMLMapperBuilder来进行解析处理的，这里面其实就包含了mapper接口的处理，解析时如果有对应的接口，会进行注册到MapperRegistry中，现在看一下代码 1234567891011121314151617181920212223242526272829303132// XMLMapperBuilder.javapublic void parse() &#123; if (!configuration.isResourceLoaded(resource)) &#123; configurationElement(parser.evalNode(\"/mapper\")); configuration.addLoadedResource(resource); // 这里进行了mapper接口的处理 bindMapperForNamespace(); &#125; parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements();&#125;private void bindMapperForNamespace() &#123; // mapper接口类的全路径名称 String namespace = builderAssistant.getCurrentNamespace(); if (namespace != null) &#123; Class&lt;?&gt; boundType = null; try &#123; // 加载mapper接口，不存在则忽略 boundType = Resources.classForName(namespace); &#125; catch (ClassNotFoundException e) &#123; // ignore, bound type is not required &#125; if (boundType != null &amp;&amp; !configuration.hasMapper(boundType)) &#123; configuration.addLoadedResource(\"namespace:\" + namespace); // 存在mapper接口类则添加到Configuration中 configuration.addMapper(boundType); &#125; &#125;&#125; 1234567public class Configuration &#123; protected final MapperRegistry mapperRegistry = new MapperRegistry(this); public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; // 调用MapperRegistry， 添加Mapper接口 mapperRegistry.addMapper(type); &#125;&#125; 12345678910111213141516171819202122public class MapperRegistry &#123; private final Configuration config; private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;&gt;(); public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; boolean loadCompleted = false; try &#123; // 添加到map中，同时为接口创建了一个代理工厂 knownMappers.put(type, new MapperProxyFactory&lt;&gt;(type)); // 这些是处理Mapper接口方法上的sql注解等，此次先不进行分析，有兴趣大家可以自行看下 MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125; &#125;&#125; 解析流程之后，我们看下获取使用流程 12345678910UserMapper mapper = session.getMapper(UserMapper.class);// 依次会调用 DefaultSqlSession.javapublic &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return configuration.getMapper(type, this);&#125;// 调用 Configuration.javapublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; // 最终从MapperRegistry中获取Mapper接口实现 return mapperRegistry.getMapper(type, sqlSession);&#125; 1234567891011public class MapperRegistry &#123; public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); try &#123; // 获取Mapper代理工厂类，创建代理实例 return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125; &#125;&#125; 123456789101112131415161718public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperProxy.MapperMethodInvoker&gt; methodCache = new ConcurrentHashMap&lt;&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; // 使用JDK动态代理 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125; 在调用Mapper接口的方法执行查询时，会调用到MapperProxy#invoke方法中，最终调用到MapperMethod#execute方法，对于当前的例子来说，会执行到 1234567// MapperMethod.java 截取了部分代码public Object execute(SqlSession sqlSession, Object[] args) &#123; // 参数转换 Object param = method.convertArgsToSqlCommandParam(args); // 调用 sqlSession来进行执行 return sqlSession.selectOne(command.getName(), param);&#125; 小结一下这部分，就是在解析mapper.xml的时候，如果有对应的接口会注册到MapperRegistry中，在使用时，会创建对应的代理类，最终还是调用sqlSession来执行 Spring支持配置使用平时我们开发几乎都是使用Spring，所以我们希望将MyBatis相关的类都由Spring来管理，在需要的时候可是进行依赖注入，我们可以使用 mybatis-spring 这个包 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.7&lt;/version&gt;&lt;/dependency&gt; 如果使用xml的话配置大致如下 1234567891011121314151617181920&lt;!-- 这里可以替换为成熟的数据库连接池，如druid等 --&gt;&lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"driverClassName\" value=\"$&#123;jdbc.driverClassName&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt;&lt;/bean&gt;&lt;!-- 声明 SqlSessionFactoryBean --&gt;&lt;bean id=\"sqlSessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 指定数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;!-- 指定Mapper文件所在的路径 --&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\" /&gt;&lt;/bean&gt;&lt;!-- 声明扫描的包，创建对应的 MapperFactoryBean --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.zavier.demo.mapper\" /&gt;&lt;/bean&gt; 进行如下配置后，即可自动注入Mapper来使用 原理分析SqlSessionFactoryBean为创建SqlSession这个Bean的工厂，我们先看下这部分实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123; // 初始化方法 public void afterPropertiesSet() throws Exception &#123; this.sqlSessionFactory = buildSqlSessionFactory(); &#125; // 这个方法代码较多，对了便于阅读只保留了部分代码并进行了调整 protected SqlSessionFactory buildSqlSessionFactory() throws Exception &#123; final Configuration targetConfiguration; XMLConfigBuilder xmlConfigBuilder = null; // 使用指定了mybatis配置文件，那么使用XMLConfigBuilder进行解析生成Configuration if (this.configLocation != null) &#123; xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties); targetConfiguration = xmlConfigBuilder.getConfiguration(); &#125; else &#123; // 都没有指定则创建一个默认的Configuration targetConfiguration = new Configuration(); &#125; // 插件注册处理 if (!isEmpty(this.plugins)) &#123; Stream.of(this.plugins).forEach(plugin -&gt; &#123; targetConfiguration.addInterceptor(plugin); LOGGER.debug(() -&gt; \"Registered plugin: '\" + plugin + \"'\"); &#125;); &#125; // TypeHanlder注册处理 if (!isEmpty(this.typeHandlers)) &#123; Stream.of(this.typeHandlers).forEach(typeHandler -&gt; &#123; targetConfiguration.getTypeHandlerRegistry().register(typeHandler); LOGGER.debug(() -&gt; \"Registered type handler: '\" + typeHandler + \"'\"); &#125;); &#125; // 默认设置Spring的事务管理器，事务功能交由Spring统一管理 targetConfiguration.setEnvironment(new Environment(this.environment, this.transactionFactory == null ? new SpringManagedTransactionFactory() : this.transactionFactory, this.dataSource)); // mapper配置文件解析处理 if (this.mapperLocations != null) &#123; for (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; // 使用XMLMapperBuilder进行解析 XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), targetConfiguration, mapperLocation.toString(), targetConfiguration.getSqlFragments()); xmlMapperBuilder.parse(); &#125; catch (Exception e) &#123; // 先忽略异常代码 &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; &#125; return this.sqlSessionFactoryBuilder.build(targetConfiguration); &#125;&#125; 可以看到这个SqlSessionFactoryBean也是基于MyBatis的配置进行了一下封装，需要注意的就是这个里面把事务管理器进行了替换 接下来看一下 MapperScannerConfigurer这个Bean的实现，其中会使用ClassPathMapperScanner来扫描包下面的所有接口，依次创建对应的MapperFactoryBean，其中的getObject方法会最终调用sqlSession.getMapper方法返回对应的代理类，这个地方就和之前是一样的了 1234// MapperFactoryBean.javapublic T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface);&#125; MyBatis-Plus大部分情况下，mapper.xml的文件中的一些基本查询都是必须的，每次手动写xml费事费力，这时候可以使用MyBatis-Generator来生成，但是如果我们想把这一步骤也省略的话，就可以直接使用MyBatis-Plus 配置使用这里使用的都是针对普通的SpringMVC项目的配置，首先需要引入对应的包 12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt; 配置和mybatis-spring的配置基本相同，唯一的区别就是需要替换一个sqlSessionFactory为MybatisPlus中的类，同时如果类中的字段名称与数据库字段没有一致，可以在对应字段上面添加注解使用，详细内容参考官方文档 123&lt;bean id=\"sqlSessionFactory\" class=\"com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt; 之后自定义的Mapper只需要继承BaseMapper即可拥有父类中的方法，不需要再手写xml文件 原理分析既然只是替换了sqlSessionFactory，那么我们就看一下新类中做了啥 首先其替换了原来的Configuration为自己的MybatisConfiguration，其继承自Configuration 替换 SqlSessionFactoryBuilder也替换为自己的 MybatisSqlSessionFactoryBuilder 替换 MapperAnnotationBuilder 为自己的 MybatisMapperAnnotationBuilder （关键） 之前解析mapper接口的部分说到过，MapperAnnotationBuilder 是用来解析接口上面的注解用的，如 1234public interface BlogMapper &#123; @Select(\"SELECT * FROM blog WHERE id = #&#123;id&#125;\") Blog selectBlog(int id);&#125; 将对应的信息解析为MappedStatement 并注册到Configuration 在替换为自己的方法后，可以在这一步进行一些MyBatis-Plus接口方法的解析，生成MappedStatement 后注册 123456789101112131415161718192021222324public class MybatisMapperAnnotationBuilder extends MapperAnnotationBuilder &#123; public void parse() &#123; String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) &#123; // 这部分代码暂时忽略，基本同MapperAnnotationBuilder，下面的是plus新增的部分 // 注入 CURD 动态 SQL , 放在在最后, because 可能会有人会用注解重写sql try &#123; if (GlobalConfigUtils.isSupperMapperChildren(configuration, type)) &#123; parserInjector(); &#125; &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteMethod(new InjectorResolver(this)); &#125; &#125; parsePendingMethods(); &#125; void parserInjector() &#123; // 这里获取到的SqlInjector为默认的 DefaultSqlInjector // 依次会调用 new Insert() GlobalConfigUtils.getSqlInjector(configuration).inspectInject(assistant, type); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DefaultSqlInjector extends AbstractSqlInjector &#123; // AbstractSqlInjector中的方法，为了方便阅读挪到了这里展示 public void inspectInject(MapperBuilderAssistant builderAssistant, Class&lt;?&gt; mapperClass) &#123; Class&lt;?&gt; modelClass = ReflectionKit.getSuperClassGenericType(mapperClass, Mapper.class, 0); if (modelClass != null) &#123; String className = mapperClass.toString(); Set&lt;String&gt; mapperRegistryCache = GlobalConfigUtils.getMapperRegistryCache(builderAssistant.getConfiguration()); if (!mapperRegistryCache.contains(className)) &#123; TableInfo tableInfo = TableInfoHelper.initTableInfo(builderAssistant, modelClass); List&lt;AbstractMethod&gt; methodList = this.getMethodList(mapperClass, tableInfo); if (CollectionUtils.isNotEmpty(methodList)) &#123; // 循环注入自定义方法 methodList.forEach(m -&gt; m.inject(builderAssistant, mapperClass, modelClass, tableInfo)); &#125; else &#123; logger.debug(mapperClass.toString() + \", No effective injection method was found.\"); &#125; mapperRegistryCache.add(className); &#125; &#125; &#125; @Override public List&lt;AbstractMethod&gt; getMethodList(Class&lt;?&gt; mapperClass, TableInfo tableInfo) &#123; Stream.Builder&lt;AbstractMethod&gt; builder = Stream.&lt;AbstractMethod&gt;builder() .add(new Insert()) .add(new Delete()) .add(new DeleteByMap()) .add(new Update()) .add(new SelectByMap()) .add(new SelectCount()) .add(new SelectMaps()) .add(new SelectMapsPage()) .add(new SelectObjs()) .add(new SelectList()) .add(new SelectPage()); if (tableInfo.havePK()) &#123; builder.add(new DeleteById()) .add(new DeleteBatchByIds()) .add(new UpdateById()) .add(new SelectById()) .add(new SelectBatchByIds()); &#125; else &#123; // 忽略代码 &#125; return builder.build().collect(toList()); &#125;&#125; 我们就以SelectList 为例看一下是如何构造MappedStatement并注册到Configuration中的 1234567891011121314151617public class SelectList extends AbstractMethod &#123; public SelectList() &#123; super(SqlMethod.SELECT_LIST.getMethod()); &#125; @Override public MappedStatement injectMappedStatement(Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo tableInfo) &#123; // 拼装SQL SqlMethod sqlMethod = SqlMethod.SELECT_LIST; String sql = String.format(sqlMethod.getSql(), sqlFirst(), sqlSelectColumns(tableInfo, true), tableInfo.getTableName(), sqlWhereEntityWrapper(true, tableInfo), sqlOrderBy(tableInfo), sqlComment()); SqlSource sqlSource = languageDriver.createSqlSource(configuration, sql, modelClass); // 构造MappedStatement并添加到Configuration中 return this.addSelectMappedStatementForTable(mapperClass, getMethod(sqlMethod), sqlSource, tableInfo); &#125;&#125; 小结一下，就是利用自定义的MybatisMapperAnnotationBuilder ，将固定一些方法的信息构造MappedStatement并添加到Configuration中，这样后续就可以直接从Configuration中获取使用 不过这种方式替换了太多MyBatis的类，其中还有很多复制的代码然后进行修改，有种魔改的感觉～～ 当然，MyBatis-Plus也不仅仅只有这一个功能，其他还有包括逻辑删除、自动填充、Sql注入器等功能，具体可以查看对应的文档 MyBatis-Mapper除了MyBatis-Plus这种方式，还有一个包也可以实现类似的功能-MyBatis-Mapper，这种方式无需任何额外的配置，使用的MyBatis本身的扩展功能，不过只能支持MyBatis 3.5.1及以上版本 123456&lt;!-- mybatis-mapper包 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-mapper&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt; 配置使用1234567891011// 首先需要添加类里面对应的表名和字段名注解@Table(\"t_user\")@Datapublic class UserDO &#123; @Column(value = \"id\", id = true) private Integer id; @Column(\"user_name\") private String userName; @Column(\"user_age\") private Integer userAge;&#125; 其次Mapper需要继承mybatis-mapper中的Mapper接口，这样就可以直接使用父接口中的方法了 12public interface UserMapper extends Mapper&lt;UserDO, Integer&gt; &#123;&#125; 使用代码如下 1Optional&lt;UserDO&gt; userDO = userMapper.selectByPrimaryKey(1); 原理分析我们先看下mybatis-mapper中的Mapper接口 12345// EntityMapper.java@Lang(Caching.class)// 使用 EntityProvider 中的 selectByPrimaryKey 方法生成SQL@SelectProvider(type = EntityProvider.class, method = \"selectByPrimaryKey\")Optional&lt;T&gt; selectByPrimaryKey(I id); 1234567891011// EntityProvider.javapublic static String selectByPrimaryKey(ProviderContext providerContext) &#123; return SqlScript.caching(providerContext, new SqlScript() &#123; @Override public String getSql(EntityTable entity) &#123; return \"SELECT \" + entity.baseColumnAsPropertyList() + \" FROM \" + entity.table() + where(() -&gt; entity.idColumns().stream().map(EntityColumn::columnEqualsProperty).collect(Collectors.joining(\" AND \"))); &#125; &#125;);&#125; 这部分的处理解析部分在 MapperAnnotationBuilder（处理Mapper接口中的注解信息） 中，其中会根据对应注解中的方法动态生成sql，创建MappedStatement并注册到Configuration中 1234567public class MapperAnnotationBuilder &#123; // 创建SQL语句的部分 private SqlSource buildSqlSource(Annotation annotation, Class&lt;?&gt; parameterType, LanguageDriver languageDriver, Method method) &#123; // 忽略其他部分代码，SelectProvider等会使用下面代码生成sql return new ProviderSqlSource(assistant.getConfiguration(), annotation, type, method); &#125;&#125; 1234567891011121314151617181920212223public class ProviderSqlSource implements SqlSource &#123; public BoundSql getBoundSql(Object parameterObject) &#123; SqlSource sqlSource = createSqlSource(parameterObject); return sqlSource.getBoundSql(parameterObject); &#125; private SqlSource createSqlSource(Object parameterObject) &#123; // 省略了大多数代码 String sql = invokeProviderMethod(parameterObject); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); return languageDriver.createSqlSource(configuration, sql, parameterType); &#125; private String invokeProviderMethod(Object... args) throws Exception &#123; Object targetObject = null; if (!Modifier.isStatic(providerMethod.getModifiers())) &#123; targetObject = providerType.getDeclaredConstructor().newInstance(); &#125; // 反射调用的 EntityProvider 中的对应方法生成SQL CharSequence sql = (CharSequence) providerMethod.invoke(targetObject, args); return sql != null ? sql.toString() : null; &#125;&#125; 知道了原理之后，我们也可以自定义Mapper，并且自己实现注解中的类和方法来动态生成SQL 总之，如果只是追求不写xml文件或者全自动，可以考虑下直接使用 JPA 以上内容没有包含Spring-Boot-Starter系列用法，原理基本都是一样的，只是对应starter包帮我们把手动配置的部分，自动进行了配置而已","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://zhengw-tech.com/tags/mybatis/"}]},{"title":"分布式任务调度核心流程(xxl-job)","slug":"xxl-job","date":"2022-04-30T09:48:06.000Z","updated":"2022-04-30T13:24:46.400Z","comments":true,"path":"2022/04/30/xxl-job/","link":"","permalink":"https://zhengw-tech.com/2022/04/30/xxl-job/","excerpt":"之前简单分析过定时任务的几种实现，但是都是单机本地的实现，现在看一下分布式的任务调度，开源的xxl-job的实现，因为其中的内容较多，这次我们就只看一下其中的任务调度部分，没有关注其中的一些分支逻辑，虽然也很重要","text":"之前简单分析过定时任务的几种实现，但是都是单机本地的实现，现在看一下分布式的任务调度，开源的xxl-job的实现，因为其中的内容较多，这次我们就只看一下其中的任务调度部分，没有关注其中的一些分支逻辑，虽然也很重要 xxl-job的整体执行流程如下图所示 其中主要分为调度器和执行器，调度器用来根据配置信息，在特定的条件下调用执行器中的对应任务进行任务的执行 执行器配置可以看一下xxl-job提供的spring boot为例的执行器，其中需要配置执行器的名称等信息 123456789# 设置调度中心的地址（执行时会有一些接口相关的调用交互）xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin### 执行器的名称 AppNamexxl.job.executor.appname=xxl-job-executor-sample### 可选，默认是自己当前的地址xxl.job.executor.address=### 执行器使用的IP和端口xxl.job.executor.ip=xxl.job.executor.port=9999 配置好执行器后，则需要进行其中的任务开发，例子代码如下 1234567891011@Componentpublic class SampleXxlJob &#123; /** * 表示这是一个可以被调度的任务，任务名称为 demoJobHandler * */ @XxlJob(\"demoJobHandler\") public void demoJobHandler() throws Exception &#123; // TODO: 任务执行 &#125;&#125; 执行器注册 在执行器启动时，执行器会根据配置的调用中心地址，调用对应的接口了实现执行器的注册（以便后续调用器进行调度），注册后每隔30S还会进行一次心跳，证明自己还活着，在关闭时也会调用接口将自己摘除 xxl-job整体没有使用zookeeper之类的注册中心，在接收到执行器的注册请求后，会新增（更新）执行器的信息到对应的MySQL表（xxl_job_registry）中，同时在接收到心跳请求时更新其中的update_time字段 调用中心内部有一个检测线程，每隔30S检测一次，当发现有执行器3次都没有心跳（当前时间 - 最后一次更新时间 &gt; 30S）时，认为这个执行器已下线，此时删除对应的记录（同时也会更新执行器记录中的执行器地址信息） 说完了执行器注册相关的功能，下面我们来看一下调度逻辑的实现 调度中心调度 注册及调度主要流程基本如下，省略了特别多的细节，如有错误之处辛苦指正，感谢","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"定时任务","slug":"定时任务","permalink":"https://zhengw-tech.com/tags/定时任务/"}]},{"title":"Clojure学习文档","slug":"clojure-basic","date":"2022-01-21T13:40:25.000Z","updated":"2022-01-21T17:46:27.864Z","comments":true,"path":"2022/01/21/clojure-basic/","link":"","permalink":"https://zhengw-tech.com/2022/01/21/clojure-basic/","excerpt":"本文主要对Clojure官网中的基础教程部分进行一下整理，对应地址https://clojure.org/guides/learn/syntax","text":"本文主要对Clojure官网中的基础教程部分进行一下整理，对应地址https://clojure.org/guides/learn/syntax 函数创建函数定义一个函数，名称为 greet, 参数为name 1234(defn greet [name] (str \"Hello, \" name));; 或者使用如下方式(def greet (fn [name] (str \"Hello, \" name))) 使用 12user=&gt; (greet \"students\")\"Hello, students\" 函数重载12345678910(defn messenger ([]) (messanger \"Hello world!\") ([msg] (println msg)));; 使用user=&gt; (messenger)Hello world!user =&gt; (messenger \"Hello class!\")Hello class! 可变参数函数12(defn hello [greeting &amp; who] (println greeting who)) 其中除第一个参数外，其余参数都会被放入 who 参数中，类型为list 12user=&gt; (hello \"Hello\" \"world\" \"class\")Hello (world class) 匿名函数123456;; 定义匿名函数(fn [message] (println message));; 定义的同时调用((fn [message] (println message)) \"Hello world!\");; Hello world! 匿名函数可以使用更加简洁的写法 12345678;; 相当于 (fn [x] (+ 6 x))#(+ 6 %);; 相当于 (fn [x y] (+ x y))#(+ %1 %2);; 相当于 (fn [x y &amp; zs] (println x y zs))#(println %1 %2 %&amp;) 应用函数apply函数可以使用0个或多个参数调用函数 1234(apply f '(1 2 3 4)) ;; 等于 (f 1 2 3 4)(apply f 1 '(2 3 4)) ;; 等于 (f 1 2 3 4)(apply f 1 2 '(3 4)) ;; 等于 (f 1 2 3 4)(apply f 1 2 3 '(4)) ;; 等于 (f 1 2 3 4) 当入参是一个集合的时候，但是函数参数需要为单个参数时，apply很有用，如 123;; 假定有一个求和函数，但是参数不定;; 如果我们写成 (defn add [&amp; z] (+ z)) ，因为z是list类型，这样会异常，可以写成(defn add [&amp; z] (apply + z)) 局部量1234;; 定义局部量 x=1, y=2(let [x 1 y 2] (+ x y)) 闭包12345678;; 定义一个函数，其结果会返回一个函数(defn messenger-builder [greeting] (fn [who] (println greeting who)));; 使用(def hello-er (messenger-builder \"Hello\"))(hello-er \"world!\");; Hello world 集合vectorvector是一个有序的集合序列，使用 []格式，如[1 2 3] 123456789101112131415;; 根据索引获取元素,如果索引值无效时会返回niluser=&gt; (get [\"abc\" false 99] 0)\"abc\";; 计数元素数量user=&gt; (count [1 2 3 \"a\"])4;; 构造集合user=&gt; (vector 1 2 3)[1 2 3];; 添加元素，使用conj将元素添加到末尾user=&gt; (conj [1 2 3] 4 5 6)[1 2 3 4 5 6] listlist类似一个链表，与vector的区别是其会使用括号，如(1 2 3 4)，在对list求值时，第一项会被解析成函数，后面的元素作为参数传递给它，如果不希望求值，可以在前面加上符号&#39; 12345678910111213141516171819202122232425user=&gt; (+ 1 2 3)6user=&gt; '(+ 1 2 3)(+ 1 2 3);; 构造集合(def cards '(10 :ace :jack 9));; 因为list没有索引，所以不能通过索引访问，遍历时需要使用 first, restuser=&gt; (first cards)10user=&gt; (rest cards)'(:ace :jack 9);; 添加元素，可以使用 conj, 但是会添加到集合头部user=&gt; (conj cards :queen)(:queen 10 :ace :jack 9);; 当做栈使用user=&gt; (def stack '(:a :b))user=&gt; (peek stack):auser=&gt; (pop stack) ;; 仍然不会改变集合本身，即执行后 stack依然有两个元素(:b) setset是一个无序不重复的集合 123456789101112131415161718192021222324;; 定义，其中逗号可以省略(def players #&#123;\"Alice\", \"Bob\", \"kelly\"&#125;);; 添加元素user=&gt; (conj players \"Fred\")#&#123;\"Alice\" \"Fred\" \"Bob\" \"Kelly\"&#125;;; 删除元素，使用 disjuser=&gt; (disj players \"Bob\" \"Sal\")#&#123;\"Alice\" \"Kelly\"&#125;;; 检查元素是否存在user=&gt; (contains? players \"Kelly\")true;; 排序setuser=&gt; (conj (sorted-set) \"Bravo\" \"Charlie\" \"Sigma\" \"Alpha\")#&#123;\"Alpha\" \"Bravo\" \"Charlie\" \"Sigma\"&#125;;; 集合合并- intouser=&gt; (def players #&#123;\"Alice\" \"Bob\" \"kelly\"&#125;)user=&gt; (def new-players [\"Tim\" \"Sue\" \"Grey\"])user=&gt; (into player new-players)#&#123;\"Alice\" \"Greg\" \"Sue\" \"Bob\" \"Tim\" \"Kelly\"&#125; map1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556;; 构造数据(def scores &#123;\"Fred\" 1400 \"Bob\" 1240 \"Angela\" 1024&#125;);; 添加元素，使用assoc，如果key已经存在，会覆盖对应的值user=&gt; (assoc scores \"Sally\" 0)&#123;\"Angela\" 1024, \"Bob\" 1240, \"Fred\" 1400, \"Sally\" 0&#125;;; 删除元素，使用dissocuser=&gt; (dissoc scores \"Bob\")&#123;\"Angela\" 1024, \"Fred\" 1400&#125;;; 根据key查找元素，也可以把map当作函数，如(scores \"Angela\")user=&gt; (get scores \"Angela\") ;; (scores \"Angela\")1024;; 使用有默认值的查找user=&gt; (get scores \"Sam\" 0)0;; 检查元素是否存在user=&gt; (contains? scores \"Fred\")trueuser=&gt; (find scores \"Fred\")[\"Fred\" 1400];; 获取Keys或valuesuser=&gt; (keys scores)(\"Fred\" \"Bob\" \"Angela\")user=&gt; (vals scores)(1400 1240 1024);; 创建map，zipmap可以合并两个序列一个作为key，一个作为valsuser=&gt; (def players #&#123;\"Alice\" \"Bob\" \"Kelly\"&#125;)user=&gt; (zipmap players (repeat 0))&#123;\"Kelly\" 0, \"Bob\" 0, \"Alice\" 0&#125;;; 合并mapuser=&gt; (def new-scores &#123;\"Angela\" 300 \"Jeff\" 900&#125;)user=&gt; (merge scores new-scores)&#123;\"Fred\" 1400, \"Bob\" 1240, \"Jeff\" 900, \"Angela\" 300&#125;;; 如果存在重复key时，可以使用merge-with 提供个函数进行冲突解决user=&gt; (def new-scores &#123;\"Fred\" 500 \"Angela\" 900 \"Sam\" 1000&#125;)user=&gt; (merge-with + scores new-scores)&#123;\"Sam\" 1000, \"Fred\" 1950, \"Bob\" 1240, \"Angela\" 1924&#125;;; 排序map，使用sorted-map会根据key进行排序user=&gt; (def sm (sorted-map \"Bravo\" 204 \"Alfa\" 35 \"Sigma\" 99 \"Charlie\" 100))user=&gt; (keys sm)(\"Afla\" \"Bravo\" \"Chalie\" \"Sigma\") 应用对象12345(def person &#123;:first-name \"Kelly\" :last-name \"Keen\" :age 32 :occupation \"Programmer\"&#125;) 获取属性 123456789user=&gt; (get person :occupation)\"Programmer\"user=&gt; (person :occupation)\"Programmer\"user=&gt; (:occupation person)\"Programmer\";; 使用关键字进行获取时，可以指定默认值user=&gt; (:favorite-color person \"beige\")\"beige\" 更新属性 12;; 向person添加或更新属性信息user=&gt; (assoc person :occupation \"Baker\") 删除属性 1user=&gt; (dissoc person :age) 实体嵌套 12345678910(def company &#123;:name \"WidgetCo\" :address &#123;:street \"123 Main St\" :city \"Springfield\" :state \"IL\"&#125;&#125;);; 可以使用 get-in 获取属性，使用assoc-in 或modify更新嵌套属性user=&gt; (get-in company [:address :city])\"Springfield\"user=&gt; (assoc-in company [:address :street] \"303 Broadway\") 使用Records替换map实现的对象 123456789101112131415;; 定义一个对象结构(defrecord Person [first-name last-name age occupation]);; 根据位置创建对象(def kelly (-&gt;Person \"Kelly\" \"Keen\" 32 \"Programmer\"));; 使用map创建对象(def kelly (map-&gt;Person &#123;:first-name \"Kelly\" :last-name \"Keen\" :age 32 :occupation \"Programmer\"&#125;));; 其他使用方式同mapuser=&gt; (:occupation kelly)\"Programmer\" 流程控制语句和表达式在Java中，表达值返回值，语句没有返回值，但是在Clojure中一切都是表达式，都会返回值，多个表达式的情况下会返回最后一个值 流程控制表达式if1234567;; if then elseuser=&gt; (str \"2 is \" (if (even? 2) \"even\" \"odd\"))\"2 is even\";; else是可选的user=&gt; (if (true? false) \"impossible!\")nil Truth在Clojure中，所有的值都可以用来判断true或false, 只有值时false或者nil时结果时false,其余所有值进行逻辑判断时都是true 123456789101112user=&gt; (if true :truthy :falsey):truthyuser=&gt; (if (Object.) :truthy :falsey):truthyuser=&gt; (if [] :truthy :falsey):truthyuser=&gt; (if 0 :truthy :falsey):truthyuser=&gt; (if false :truthy :falsey):falseyuser=&gt; (if nil :truthy :falsey):falsey if and doif语句中的then和else部分只能用来执行单个表达式，可以使用do来创建执行多个语句 12345(if (even? 5) (do (println \"even\") true) (do (println \"odd\") false)) whenwhen相当于简化版的if, 但是它支持多个语句而不用使用do 12(when (neg? x) (throw (RuntimeException. (str \"x must be positive: \" x)))) cond1234(let [x 5] (cond (&lt; x 2) \"x is less than 2\" (&lt; x 10) \"x is less than 10\")) cond and else12345(let [x 11] (cond (&lt; x 2) \"x is less than 2\" (&lt; x 10) \"x is less than 10\" :else \"x is greater than or equal to 10\")) case相比if 和cond，使用其没有匹配到值时会抛出异常 123456user=&gt; (defn foo [x] (case x 5 \"x is 5\" 10 \"x is 10\"))user=&gt; (foo 10)x is 10 case and else12345678user=&gt; (defn foo [x] (case x 5 \"x is 5\" 10 \"x is 10\" \"x isn't 5 or 10\"))user=&gt; (foo 11)x isn't 5 or 10 迭代dotimes执行n次表达值，返回nil 12345user=&gt; (dotimes [i 3] (println i))012 doseq遍历序列 12345user=&gt; (doseq [n (range 3)] (println n))012 doseq与多个绑定值123456789user=&gt; (doseq [letter [:a :b] number (range 3)] (prn [letter number]))[:a 0][:a 1][:a 2][:b 0][:b 1][:b 2] for生成序列，绑定方式同doseq 1234user=&gt; (for [letter [:a :b] number (range 3)] ; list of 0, 1, 2 [letter number])([:a 0] [:a 1] [:a 2] [:b 0] [:b 1] [:b 2]) 递归loop 和 recur1234(loop [i 0] (if (&lt; i 10) (recur (inc i)) ;; 重新执行loop绑定运行 i)) defn 与 recur1234(defn increase [i] ;; 隐士loop绑定 (if (&lt; i 10) (recur (inc i)) i)) 异常异常处理123456(try (/ 2 1) (catch ArithmeticException e \"divide by zero\") (finally (println \"cleanup\"))) 抛出异常123(try (throw (Exception. \"something went wrong\")) (catch Exception e (.getMessage e))) 异常与Clojure数据1234(try (throw (ex-info \"There was a problem\" &#123;:detail 42&#125;)) ;; 使用ex-info设置信息和map (catch Exception e (prn (:detail (ex-data e))))) ;; 使用ex-data从异常中获取map数据，不存在时返回nil 命名空间命名空间可以类似理解成Java中的包名 12345(ns com.some-example.my-app ;; 命名空间 \"My app example\" ;; 文档字符串 (:require [clojure.set :as set] ;; 使用:require表示加载clojure.set，并创建了一个别名 [clojure.string :as str])) 加载java类时，使:import 12345;; 引入了 Date, UUID, File 三个类(ns com.some-example.my-app2 (:import [java.util Date UUID] [java.io File]))","categories":[],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://zhengw-tech.com/tags/clojure/"}]},{"title":"SpEL使用","slug":"spel","date":"2022-01-15T15:05:24.000Z","updated":"2022-01-15T17:13:56.486Z","comments":true,"path":"2022/01/15/spel/","link":"","permalink":"https://zhengw-tech.com/2022/01/15/spel/","excerpt":"Spring Expression Language(SpEL) 是一个表达式语言，可以用来在运行时查询和操作对象图，比较类似于EL表达式，相比其他的表达式语言，可以更好的与Spring集成，如果使用Spring的话，也可以不用再引入额外的依赖 同时它也是可以单独引入并且使用的，这里我们主要就是看一下单独使用的情况下它能做什么以及如何使用 首先需要引入依赖包 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;5.3.12&lt;/version&gt;&lt;/dependency&gt;","text":"Spring Expression Language(SpEL) 是一个表达式语言，可以用来在运行时查询和操作对象图，比较类似于EL表达式，相比其他的表达式语言，可以更好的与Spring集成，如果使用Spring的话，也可以不用再引入额外的依赖 同时它也是可以单独引入并且使用的，这里我们主要就是看一下单独使用的情况下它能做什么以及如何使用 首先需要引入依赖包 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;5.3.12&lt;/version&gt;&lt;/dependency&gt; 普通表达式求值123456789101112ExpressionParser parser = new SpelExpressionParser();String helloWorld = parser.parseExpression(\"'Hello World'\").getValue(String.class);// helloWorld: 'Hello World'Expression expression = parser.parseExpression(\"'hello' + ' world'\");String value = expression.getValue(String.class);// value: 'hello world'Expression expression1 = parser.parseExpression(\"5 + 8\");Integer v1 = expression1.getValue(Integer.class);// v1: 13 在表达式中，支持各种关系、算数、逻辑表达式，同时还可以调用相关的类或者方法 1234567Expression expression = parser.parseExpression(\"('hello' + ' world').toUpperCase()\");String value = expression.getValue(String.class);// value: 'HELLO WORLD'// 对于特定类型，需要使用T(&lt;类型&gt;)来进行表示Boolean value1 = parser.parseExpression(\"T(org.apache.commons.lang3.StringUtils).isNoneBlank('aa')\").getValue(Boolean.class);// value1: true 操作对象当需要使用表达式解析属性、方法等时，都需要用到EvaluationContext这个接口，只不过当我们没有显示提供的时候，SpEL会自动创建一个实现StandardEvaluationContext 12345678910111213141516171819202122// 创建一个对象user, 并将其作为EvaluationContext的rootObjectUser user = new User();user.setUserName(\"zhangsan\");user.setAge(18);EvaluationContext context = new StandardEvaluationContext(user);// StandardEvaluationContext对应构造函数如下// public StandardEvaluationContext(Object rootObject) &#123;// this.rootObject = new TypedValue(rootObject);// &#125;// 使用表达式进行解析rootObject的userName属性，#root.userName中的#root可以省略，即简化为 userNameExpressionParser parser = new SpelExpressionParser();Expression expression = parser.parseExpression(\"#root.userName\");String value = expression.getValue(context, String.class);// value: 'zhangsan'public class User &#123; private String userName; private Integer credits; // 忽略 getter, setter方法&#125; 对于只有一个rootObject的情况，可以不显示指定EvaluationContext，即上述写法可以简化为 123456User user = new User();user.setUserName(\"zhangsan\");user.setAge(18);String userName = parser.parseExpression(\"userName\").getValue(user, String.class);// userName: 'zhangsan' 但是如果除了rootObject外还需要设置其他属性的话，那么EvaluationContext就不能省略了 12345678910111213// 设置user为EvaluationContext的rootObjectUser user = new User();user.setUserName(\"zheng\");user.setAge(18);EvaluationContext context = new StandardEvaluationContext(user);// 设置额外的属性 addAge:10context.setVariable(\"addAge\", 10);// 使用表达式计算结果， 获取属性值的方式为： #属性名ExpressionParser parser = new SpelExpressionParser();Expression expression = parser.parseExpression(\"age + #addAge\");Integer value = expression.getValue(context, Integer.class);// value: 28 同时使用SpEL不仅可以用来读取对象，还可以用来修改对象的值 1234567891011User user = new User();user.setUserName(\"zhangsan\");user.setAge(18);ExpressionParser parser = new SpelExpressionParser();Expression expression = parser.parseExpression(\"userName\");// 将userName的值设置为lisiexpression.setValue(user, \"lisi\");String res = user.getUserName();// res: 'lisi' 集合操作可以用过SpEL表达式实现集合过滤和数据转换操作 过滤通过.?[selectionExpression]可以对集合中的元素进行筛选过滤 1234567891011121314151617181920212223List&lt;User&gt; userList = new ArrayList&lt;&gt;();&#123; User user = new User(); user.setUserName(\"zhangsan\"); user.setAge(18); userList.add(user);&#125;&#123; User user = new User(); user.setUserName(\"lisi\"); user.setAge(10); userList.add(user);&#125;&#123; User user = new User(); user.setUserName(\"wangwu\"); user.setAge(20); userList.add(user);&#125;ExpressionParser parser = new SpelExpressionParser();final Expression expression = parser.parseExpression(\"#this.?[age &gt; 10]\");final List&lt;User&gt; value = expression.getValue(userList, List.class);// value: [User(userName=zhangsan, age=18), User(userName=wangwu, age=20)] 过滤操作还可以用于map类型的数据 12345678Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(\"key1\", 10);map.put(\"key2\", 20);map.put(\"key3\", 30);ExpressionParser parser = new SpelExpressionParser();final Expression expression = parser.parseExpression(\"#root.?[value&gt;10]\");final Map value = expression.getValue(map, Map.class);// value: &#123;key2=20, key3=30&#125; 如果过滤的时候只想取满足条件的第一个值或者最后一个值，可以使用.^[selectionExpression]或者.$[selectionExpression]来分别获取 1234567Expression expression1 = parser.parseExpression(\"#this.^[age&gt;10]\");Object value1 = expression1.getValue(userList);// value1: User(userName=zhangsan, age=18)Expression expression2 = parser.parseExpression(\"#this.$[age&gt;10]\");Object value2 = expression2.getValue(userList);// value2: User(userName=wangwu, age=20) 数据映射转换通过.![projectionExpression]可以对数据进行转换 12345678// 使用上例中的List&lt;User&gt;数据, 忽略设值代码List&lt;User&gt; userList = new ArrayList&lt;&gt;();ExpressionParser parser = new SpelExpressionParser();// 映射为年龄信息Expression expression = parser.parseExpression(\"#this.![age]\");List&lt;?&gt; value = expression.getValue(userList, List.class);// value: [18, 10, 20] 其他Elvis操作符这个操作符相当于对?:这个三元操作符的简化，比如当左侧表达式不为null时返回值本身，否则返回一个固定值 12345// 三元操作符写法String realName = name != null ? name : 'Guest';// 使用Elvis操作符String realName = name ?: 'Guest'; 使用示例 12345678910User user = new User();ExpressionParser parser = new SpelExpressionParser();Expression expression = parser.parseExpression(\"userName ?: 'Guest'\");String value = expression.getValue(user, String.class);// value: 'Guest'user.setUserName(\"zhangsan\");value = expression.getValue(user, String.class);// value: 'zhangsan' 安全导航操作符对于在取属性时可能遇到的空指针问题，如获取user的姓名时，我们通常需要判断user是否为null，这种代码比较啰嗦，取值时可以使用?.方式进行简化 1234567User user = null;ExpressionParser parser = new SpelExpressionParser();// 使用 ?. 取值时，如果对象对null不会出现空指针，只会最终返回nullExpression expression = parser.parseExpression(\"#root?.userName\");String value = expression.getValue(user, String.class);// value: null Elvis操作符和安全导航操作符在Groovy中也有同样的功能 参考资料：https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#expressions","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"},{"name":"spel","slug":"spel","permalink":"https://zhengw-tech.com/tags/spel/"}]},{"title":"Spring循环依赖分析","slug":"spring-circular","date":"2022-01-08T10:22:58.000Z","updated":"2022-02-07T05:08:05.703Z","comments":true,"path":"2022/01/08/spring-circular/","link":"","permalink":"https://zhengw-tech.com/2022/01/08/spring-circular/","excerpt":"我们在使用Spring开发的时候，可能有的时候不小心就会写出来循环依赖，但是大部分情况下都能正常运行，不需要我们特别关注，这是因为Spring进行了相关的处理等 循环依赖的处理还依赖于bean的作用范围，bean的注入方式等，这里我们就以单例模式，属性注入的方式来分析一下Spring对于循环依赖的处理","text":"我们在使用Spring开发的时候，可能有的时候不小心就会写出来循环依赖，但是大部分情况下都能正常运行，不需要我们特别关注，这是因为Spring进行了相关的处理等 循环依赖的处理还依赖于bean的作用范围，bean的注入方式等，这里我们就以单例模式，属性注入的方式来分析一下Spring对于循环依赖的处理 我们以如下场景为例来进行分析，有ServiceA和ServiceB两个Bean, 它们互相依赖 1234567891011@Servicepublic class ServiceA &#123; @Resource private ServiceB serviceB;&#125;@Servicepublic class ServiceB &#123; @Resource private ServiceA serviceA;&#125; 先说结论，然后再进行操作和分析，spring的创建过程大致如下 处理循环依赖的关键就是其中的注册单例Bean工厂（singletonFactories）相关功能 首次获取ServiceA这个bean时，单例工厂中不存在，这时候会进行实例化并将结果添加到bean工厂中 处理ServiceA中属性注入的ServiceB，这时候会从bean工厂中获取ServiceB的bean 单例工厂中不存在的ServiceB, 这时候会进行实例化ServiceB并将结果添加到bean工厂中 处理ServiceB中属性注入的ServiceA，这时候会从bean工厂中获取ServiceA的bean 发现单例工厂中存在ServiceA对应的工厂，从工厂获取bean返回，ServiceB中属性注入完成 SeriveA中属性注入完成，循环依赖处理完成 源码分析因为之前已经初步分析过Bean的创建过程，所以这次我们只关注相关的代码，针对上述过程看一下源码 Bean获取过程12345678910111213141516171819202122232425262728293031323334353637// org.springframework.beans.factory.support.AbstractBeanFactoryprotected &lt;T&gt; T doGetBean(String name, Class&lt;T&gt; requiredType, Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // 检查单例工厂中是否存在，存在的获取并返回 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125;&#125;public Object getSingleton(String beanName) &#123; return getSingleton(beanName, true);&#125;// 这个是处理循环依赖的关键protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 获取对应工厂，存在的获取实例返回 ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125; Bean创建过程123456789101112131415161718192021222324252627282930313233343536373839404142// org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory// 为了简化过程，对源码进行了部分删减protected Object doCreateBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; // 反射实例化Bean BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args); final Object bean = instanceWrapper.getWrappedInstance(); // 单例并且运行循环依赖时，将其注册添加到单例bean工厂中 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; Object exposedObject = bean; try &#123; // Bean中属性等处理（包括属性注入依赖的其他Bean） populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; // 忽略异常处理 &#125; // 创建结束并返回结果 return exposedObject;&#125;// 注册单例Bean工厂protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; // 添加到 singletonFactories this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125;&#125; Bean中属性注入依赖处理这里需要提一下，Bean中属性注入的依赖，是由以下两个BeanPostProcessor来分别进行处理的 org.springframework.context.annotation.CommonAnnotationBeanPostProcessor(处理@Resource) org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor(处理@Autowired) 处理底层是一样的，这次我们就以CommonAnnotationBeanPostProcessor为例进行分析 123456789101112131415161718// org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory// populateBean(beanName, mbd, instanceWrapper);// 方法中代码较多，进行了大量删减，我们只关注一些相关部分protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) &#123; // 获取所有BeanPostProcessor for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 这里会有 CommonAnnotationBeanPostProcessor 进行处理，注入依赖Bean PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); &#125; &#125; &#125;&#125; 1234567891011121314// org.springframework.context.annotation.CommonAnnotationBeanPostProcessorpublic PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) &#123; // 这里会获取有@Resource注解的属性或方法，此次就不进入细看了 InjectionMetadata metadata = findResourceMetadata(beanName, bean.getClass(), pvs); try &#123; // 我们关注一下这个方法 metadata.inject(bean, beanName, pvs); &#125; catch (Throwable ex) &#123; // 忽略异常处理 &#125; return pvs;&#125; 123456789101112131415161718192021222324252627282930313233343536373839// org.springframework.beans.factory.annotation.InjectionMetadatapublic void inject(Object target, String beanName, PropertyValues pvs) throws Throwable &#123; Collection&lt;InjectionMetadata.InjectedElement&gt; checkedElements = this.checkedElements; Collection&lt;InjectionMetadata.InjectedElement&gt; elementsToIterate = (checkedElements != null ? checkedElements : this.injectedElements); if (!elementsToIterate.isEmpty()) &#123; for (InjectionMetadata.InjectedElement element : elementsToIterate) &#123; // 继续跟进这个方法 element.inject(target, beanName, pvs); &#125; &#125;&#125;// org.springframework.beans.factory.annotation.InjectionMetadata.InjectedElementprotected void inject(Object target, @Nullable String requestingBeanName, @Nullable PropertyValues pvs) throws Throwable &#123; // 属性处理 if (this.isField) &#123; Field field = (Field) this.member; ReflectionUtils.makeAccessible(field); // 看一下getResourceToInject这个方法，会从BeanFactory获取/创建对应的Bean后进行赋值 field.set(target, getResourceToInject(target, requestingBeanName)); &#125; else &#123; if (checkPropertySkipping(pvs)) &#123; return; &#125; try &#123; // 方法处理 Method method = (Method) this.member; ReflectionUtils.makeAccessible(method); method.invoke(target, getResourceToInject(target, requestingBeanName)); &#125; catch (InvocationTargetException ex) &#123; throw ex.getTargetException(); &#125; &#125;&#125; getResourceToInject会调用到CommonAnnotationBeanPostProcessor.ResourceElement中的对应方法 123456789101112131415161718192021222324252627282930protected Object getResourceToInject(Object target, @Nullable String requestingBeanName) &#123; // 没有添加@Lazy注解等时会调用 getResource 方法 return (this.lazyLookup ? buildLazyResourceProxy(this, requestingBeanName) : getResource(this, requestingBeanName));&#125;// org.springframework.context.annotation.CommonAnnotationBeanPostProcessor#getResourceprotected Object getResource(CommonAnnotationBeanPostProcessor.LookupElement element, String requestingBeanName) throws NoSuchBeanDefinitionException &#123; return autowireResource(this.resourceFactory, element, requestingBeanName);&#125;protected Object autowireResource(BeanFactory factory, CommonAnnotationBeanPostProcessor.LookupElement element, String requestingBeanName) throws NoSuchBeanDefinitionException &#123; Object resource; Set&lt;String&gt; autowiredBeanNames; String name = element.name; if (this.fallbackToDefaultTypeMatch &amp;&amp; element.isDefaultName &amp;&amp; factory instanceof AutowireCapableBeanFactory &amp;&amp; !factory.containsBean(name)) &#123; // 先忽略，有兴趣可以看下对应代码 &#125; else &#123; // 会从BeanFactory中获取对应属性的Bean, 这样又可以走开头的流程 resource = factory.getBean(name, element.lookupType); autowiredBeanNames = Collections.singleton(name); &#125; return resource;&#125; 以上就是一个简单的循环依赖处理过程","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"}]},{"title":"PF4J入门使用","slug":"pf4j-use","date":"2022-01-02T13:34:51.000Z","updated":"2022-02-07T05:08:05.703Z","comments":true,"path":"2022/01/02/pf4j-use/","link":"","permalink":"https://zhengw-tech.com/2022/01/02/pf4j-use/","excerpt":"写代码我们都知道要抽象，要封装变化，要实现开闭原则，比如对于很多相似的功能，我们可以将通用的功能抽象出来，然后把变化的不同的地方提取出去，比如模版模式、策略模式等都是实现类似的效果 比如对于策略模式，我们通常是定义一个接口，然后有不同的实现，这种是可以的，但是如果通用流程中要扩展的点较多的话，这些不同的实现也需要管理，可以把他们合并到一个单独的包中，再进一步，我们甚至可以将包单独提取出来，支持运行时加载包实现新增功能的支持 JDK对此功能的支持就是 SPI，但是它的限制较多，也不够灵活，比如dubbo就是自己定义了一套SPI的实现，这次我们来看另一个实现，pf4j 提供一套在基本框架中定义扩展点接口，然后通过不同的插件来实现扩展点的功能，来支持对新增开放对修改关闭 这次我们就来学习一下它的使用","text":"写代码我们都知道要抽象，要封装变化，要实现开闭原则，比如对于很多相似的功能，我们可以将通用的功能抽象出来，然后把变化的不同的地方提取出去，比如模版模式、策略模式等都是实现类似的效果 比如对于策略模式，我们通常是定义一个接口，然后有不同的实现，这种是可以的，但是如果通用流程中要扩展的点较多的话，这些不同的实现也需要管理，可以把他们合并到一个单独的包中，再进一步，我们甚至可以将包单独提取出来，支持运行时加载包实现新增功能的支持 JDK对此功能的支持就是 SPI，但是它的限制较多，也不够灵活，比如dubbo就是自己定义了一套SPI的实现，这次我们来看另一个实现，pf4j 提供一套在基本框架中定义扩展点接口，然后通过不同的插件来实现扩展点的功能，来支持对新增开放对修改关闭 这次我们就来学习一下它的使用 使用比如我们有一套通用的流程，假设是下单流程，不同的业务线等对于下单都有一些特殊点，但是它们的基本流程是相似的，这时候我们就可以先定义好通用的流程，不同的地方预留出扩展点接口，使用 pf4j 的流程如下 先定义好扩展点接口（需要定义单独的包，因为基本应用和各个扩展点的包都依赖它） 定义单独的插件包，其中实现扩展点接口的功能 在应用中编写基本流程和扩展点的发现使用功能 这次我们就参考 pf4j 提供的例子来看一下 1. 定义扩展点接口pom.xml首先声明依赖 1234567&lt;dependency&gt; &lt;groupId&gt;org.pf4j&lt;/groupId&gt; &lt;artifactId&gt;pf4j&lt;/artifactId&gt; &lt;version&gt;3.6.0&lt;/version&gt; &lt;!-- 一般应用中会依赖这个包，所以这里设置为provided即可 --&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 之后即可声明各个扩展点接口 1234567/** * 假设我们需要一个通知用户的功能 * 需要注意的是，我们一定要继承 ExtensionPoint 接口，表示这是一个扩展点 */public interface Notice extends ExtensionPoint &#123; boolean notice(List&lt;Long&gt; userIds);&#125; 2. 各个插件实现pom.xml修改 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;!-- 提供id和版本方便后续排查等使用 --&gt; &lt;plugin.id&gt;email-plugin&lt;/plugin.id&gt; &lt;plugin.version&gt;0.0.1&lt;/plugin.version&gt; &lt;!-- 插件类，如果不关心生命周期可以不提供 --&gt; &lt;plugin.class /&gt; &lt;plugin.provider&gt;user1&lt;/plugin.provider&gt; &lt;plugin.dependencies/&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- 相关依赖，注意 scope=provided --&gt; &lt;dependency&gt; &lt;groupId&gt;org.pf4j&lt;/groupId&gt; &lt;artifactId&gt;pf4j&lt;/artifactId&gt; &lt;version&gt;3.6.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zavier.demo&lt;/groupId&gt; &lt;artifactId&gt;extension-api&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 可以定义单独的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;30.1.1-jre&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- 配置打包插件，一个是要将所有依赖包打包成一起，避免和其他包冲突，第二是要将插件信息写入到manifest.mf --&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;attach&gt;false&lt;/attach&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Plugin-Id&gt;$&#123;plugin.id&#125;&lt;/Plugin-Id&gt; &lt;Plugin-Version&gt;$&#123;plugin.version&#125;&lt;/Plugin-Version&gt; &lt;Plugin-Provider&gt;$&#123;plugin.provider&#125;&lt;/Plugin-Provider&gt; &lt;Plugin-Class&gt;$&#123;plugin.class&#125;&lt;/Plugin-Class&gt; &lt;Plugin-Dependencies&gt;$&#123;plugin.dependencies&#125;&lt;/Plugin-Dependencies&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 功能实现 1234567891011121314/** * 需要实现接口及增加Extension注解 */@Extensionpublic class EmailNotice implements Notice &#123; @Override public boolean notice(List&lt;Long&gt; userIds) &#123; // todo逻辑实现 final ArrayList&lt;Object&gt; objects = Lists.newArrayList(); System.out.println(\"email notice\"); return true; &#125;&#125; 如果还有其他插件，也是类似的实现 3.插件使用将之前打包的插件包放到一个路径包下，之后新建一个应用模版，就可以获取插件中的扩展点并使用 1234567891011121314151617public static void main(String[] args) &#123; // 创建的时候，可以指定插件所在的包（其中可以有多个插件包） PluginManager pluginManager = new DefaultPluginManager(Paths.get(\"/u/plugins\")); pluginManager.loadPlugins(); pluginManager.startPlugins(); List&lt;Long&gt; list = new ArrayList&lt;&gt;(); final List&lt;Notice&gt; extensions = pluginManager.getExtensions(Notice.class); extensions.forEach(e -&gt; e.notice(list)); // 也可以获取制定插件中的实现 extensions = pluginManager.getExtensions(Notice.class, \"email-plugin\"); extensions.forEach(e -&gt; e.notice(list)); pluginManager.stopPlugins(); pluginManager.unloadPlugins();&#125; 例子代码地址：https://github.com/zavier/pf4j-demo","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"pf4j","slug":"pf4j","permalink":"https://zhengw-tech.com/tags/pf4j/"}]},{"title":"Thrift(三)-协议使用","slug":"thrift-v3","date":"2021-12-19T15:04:14.000Z","updated":"2023-06-04T14:02:32.460Z","comments":true,"path":"2021/12/19/thrift-v3/","link":"","permalink":"https://zhengw-tech.com/2021/12/19/thrift-v3/","excerpt":"Thrift的关键其实就是在定义好结构后，通过某种序列化方式进行网络传输交互，一般定义结构可以使用IDL的方式来描述各个字段属性等信息，这种方式可以支持跨语言的使用。对于纯Java的应用，也可以通过在类中添加注解的方式来实现，即把IDL中需要定义的信息，通过注解和注解中的信息来进行描述，同样可以达到定义结构的目的 定义好结构之后，就可以通过对应的TProtocol将数据结构进行发送和接收的序列化和反序列化即可，这次我们主要看下TProtocol中的一个实现–TBinaryProtocol","text":"Thrift的关键其实就是在定义好结构后，通过某种序列化方式进行网络传输交互，一般定义结构可以使用IDL的方式来描述各个字段属性等信息，这种方式可以支持跨语言的使用。对于纯Java的应用，也可以通过在类中添加注解的方式来实现，即把IDL中需要定义的信息，通过注解和注解中的信息来进行描述，同样可以达到定义结构的目的 定义好结构之后，就可以通过对应的TProtocol将数据结构进行发送和接收的序列化和反序列化即可，这次我们主要看下TProtocol中的一个实现–TBinaryProtocol 之前我们也看过thrift支持的一些结构类型，如struct、string、map、list等，具体可以看下对应枚举 12345678910111213141516public final class TType &#123; public static final byte STOP = 0; public static final byte VOID = 1; public static final byte BOOL = 2; public static final byte BYTE = 3; public static final byte DOUBLE = 4; public static final byte I16 = 6; public static final byte I32 = 8; public static final byte I64 = 10; public static final byte STRING = 11; public static final byte STRUCT = 12; public static final byte MAP = 13; public static final byte SET = 14; public static final byte LIST = 15; public static final byte ENUM = 16;&#125; 每次发送消息，都有一个消息类型的标识 123456public final class TMessageType &#123; public static final byte CALL = 1; public static final byte REPLY = 2; public static final byte EXCEPTION = 3; public static final byte ONEWAY = 4;&#125; 而TProtocol提供了对应这些结构的读写接口，我们可以大致看一下写接口，读接口也类似 1234567891011121314151617181920212223// 发送消息开始writeMessageBegin(name, type, seq);writeMessageEnd();// 开始写入结构体writeStructBegin(name);writeStructEnd();// 开始写入Field，其他的string、i32等的写入都是在Field的写入范围中进行操作writeFieldBegin(name, type, id);writeFieldEnd();writeFieldStop();writeMapBegin(ktype, vtype, size);writeMapEnd();writeListBegin(etype, size);writeListEnd();writeSetBegin(etype, size);writeSetEnd();writeBool(bool);writeByte(byte);writeI16(i16);writeI32(i32);writeI64(i64);writeDouble(double);writeString(string); 通过阅读生成的代码，我们就可以看到具体的使用了，基本流程大致如下 12345678910111213141516171819202122// 1 开始发送消息，写好消息类型及序号// 类型为请求或响应时name为方法名称，响应与对应的请求序号要相同writeMessageBegin(name, type, seq);// 1.1 开始写入结构体writeStructBegin(name);// 1.1.2 开始写入结构体中的字段（名称、类型、id）, field中的类型也可以是structwriteFieldBegin(name, type, id);// 写入字段值writeString(string);// 写入结束一个字段writeFieldEnd();// 1.1.3 开始写入结构体中的另一个字段writeFieldBegin(name, type, id);// 写入字段值writeString(string);// 写入结束一个字段writeFieldEnd();// 1.1.4 结构体中的字段写入完成writeFieldStop();// 写入结束标识writeStructEnd();writeMessageEnd(); 根据这些接口，掌握了写入流程后，我们可以不使用生成的代码来完成消息的接收和发送，下面我们只使用TBinaryProtocol来实现一个最简单的server服务（对应的接口参考第一篇文章）， 12345678910111213// userService.thriftstruct User &#123; 1:string name; 2:i32 age;&#125;struct UserSearchResult &#123; 1:list&lt;User&gt; users;&#125;service UserService &#123; UserSearchResult searchUsers(1:string name);&#125; 实现代码如下（只是为了展示功能） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// TProtocol需要以来 TTransport,这里进行构造TServerTransport serverTransport = new TServerSocket(12345);serverTransport.listen();final TTransport transport = serverTransport.accept();// 初始化 TProtocolTProtocol protocol = new TBinaryProtocol(transport);while (true) &#123; String name = \"\"; // 开始读取 Message，类型为系统调用 final TMessage tMessage = protocol.readMessageBegin(); if (tMessage.type == TMessageType.CALL) &#123; // 开始读取结构体 protocol.readStructBegin(); // 读取结构体中的属性 final TField tField = protocol.readFieldBegin(); // 如果属性的id是1，对应的name属性（属性基本都是根据id来定位） if (tField.id == 1) &#123; // 读取name的属性值 name = protocol.readString(); &#125; // 因为对应方法只有一个属性，所以到这里可以认为读取完成了 protocol.readFieldEnd(); protocol.readStructEnd(); &#125; protocol.readMessageEnd(); System.out.println(\"Read param name:\" + name); // TODO: 这里就是获取完参数值后，进行业务计算，获取结果 // 开始写入结果，类型为reply, 使用请求的序号 final TMessage respMessage = new TMessage(\"searchUsers\", TMessageType.REPLY, tMessage.seqid); protocol.writeMessageBegin(respMessage); // thrift的响应，需要最外层包装一个id=0的struct，其中的Field对应结果的struct protocol.writeStructBegin(new TStruct(\"success\")); // 开始写入结果的field protocol.writeFieldBegin(new TField(\"success\", TType.STRUCT, (short) 0)); // 开始写入结果struct protocol.writeStructBegin(new TStruct(\"searchResult\")); // 写入结果中的field, 类似为list&lt;user&gt;数据 final TField tField = new TField(\"users\", TType.LIST, (short) 1); // 写入user-field protocol.writeFieldBegin(tField); // 写入具体值（list，结构类型为struct, 元素数量为2个） protocol.writeListBegin(new TList(TType.STRUCT, 2)); // 写入list中的第一个struct protocol.writeStructBegin(new TStruct(\"user\")); protocol.writeFieldBegin(new TField(\"name\", TType.STRING, (short) 1)); protocol.writeString(\"zhangsan1\"); protocol.writeFieldEnd(); protocol.writeFieldBegin(new TField(\"age\", TType.I32, (short) 2)); protocol.writeI32(18); protocol.writeFieldEnd(); protocol.writeFieldStop(); protocol.writeStructEnd(); // 写入list中的第二个struct protocol.writeStructBegin(new TStruct(\"user\")); protocol.writeFieldBegin(new TField(\"name\", TType.STRING, (short) 1)); protocol.writeString(\"lisi1\"); protocol.writeFieldEnd(); protocol.writeFieldBegin(new TField(\"age\", TType.I32, (short) 2)); protocol.writeI32(19); protocol.writeFieldEnd(); protocol.writeFieldStop(); protocol.writeStructEnd(); // 结束list写入及其他对应的结束方法 protocol.writeListEnd(); protocol.writeFieldEnd(); protocol.writeFieldStop(); protocol.writeStructEnd(); protocol.writeFieldEnd(); protocol.writeFieldStop(); protocol.writeStructEnd(); // 结束消息写入 protocol.writeMessageEnd(); // 刷新发送 protocol.getTransport().flush();&#125; 之后启动服务，在使用之前的Client端方法进行调用 1234567891011// client端代码，使用thrift生成的UserService.Client调用TTransport transport = new TSocket(\"localhost\", 12345);transport.open();TProtocol protocol = new TBinaryProtocol(transport);UserService.Client client = new UserService.Client(protocol);UserSearchResult userRes = client.searchUsers(\"zhangsan\");System.out.println(userRes);transport.close(); 执行后可以发现可以实现之前的功能 1234// 服务端终端输出Read param name:zhangsan// 客户端终端输出UserSearchResult(users:[User(name:zhangsan1, age:18), User(name:lisi1, age:19)]) 再进行深入的话，我们可以根据 TBinaryProtocol 中的具体发送信息逻辑，直接使用原生的Java Socket进行编程，只不过会更加麻烦一些，原理基本就是如此","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"thrift","slug":"thrift","permalink":"https://zhengw-tech.com/tags/thrift/"}]},{"title":"Thrift(二)-处理流程分析","slug":"thrift-v2","date":"2021-12-18T06:14:46.000Z","updated":"2022-05-29T09:07:25.558Z","comments":true,"path":"2021/12/18/thrift-v2/","link":"","permalink":"https://zhengw-tech.com/2021/12/18/thrift-v2/","excerpt":"之前介绍过thrift使用, 但是只知道使用总是不够满足，这次我们接着之前的代码，来看下这个具体的实现和处理流程，在介绍之前先看下几个重要的接口 传输层 TTransport : 负责数据传输（大部分场景为负责网络传输） 协议层 TProtocol: 负责进行数据结构的序列化与反序列化（依赖TTransport 进行数据传输及读取） 处理层 TProcessor : 使用协议和传输接口进行具体处理处理","text":"之前介绍过thrift使用, 但是只知道使用总是不够满足，这次我们接着之前的代码，来看下这个具体的实现和处理流程，在介绍之前先看下几个重要的接口 传输层 TTransport : 负责数据传输（大部分场景为负责网络传输） 协议层 TProtocol: 负责进行数据结构的序列化与反序列化（依赖TTransport 进行数据传输及读取） 处理层 TProcessor : 使用协议和传输接口进行具体处理处理 server初始化再次看下Server的初始化启动代码 123456789101112// 创建传输层ServerTransportTServerTransport serverTransport = new TServerSocket(12345);// 实例化接口实现类// 构造Server参数（TProcessor, TTransport, TProtocol-默认TBinaryProtocol）UserService.Processor&lt;UserServiceImpl&gt; processor = new UserService.Processor&lt;&gt;(new UserServiceImpl());final TServer.Args serverArgs = new TServer.Args(serverTransport).processor(processor);// 使用参数初始化Server并启动TServer server = new TSimpleServer(serverArgs);System.out.println(\"Starting the simple server...\");server.serve(); 下面据此来进入源码，了解一下具体实现（本次使用的代码为 libthrift : 0.15.0） 网络传输初始化先来看下传输层TServerTransport，对应的实现TServerSocket就是对平时我们使用的ServerSocket的包装，负责进行相关的网络传输 1234// org.apache.thrift.transport.TServerSocketpublic class TServerSocket extends TServerTransport &#123; private ServerSocket serverSocket_ = null;&#125; 相关参数构造接着分析一下代码UserService.Processor&lt;UserServiceImpl&gt; processor = new UserService.Processor&lt;&gt;(new UserServiceImpl());，这是 UserService.Processor的构造过程 1234567891011121314151617181920212223242526272829303132// UserService.Processor 继承了 org.apache.thrift.TBaseProcessor// 所以先看下 org.apache.thrift.TBaseProcessorpublic abstract class TBaseProcessor&lt;I&gt; implements TProcessor &#123; // 维护了iface为我们的逻辑实现类 UserServiceImpl // 同时维护一个map&lt;方法名, 处理函数&gt; private final I iface; private final Map&lt;String, ProcessFunction&lt;I, ? extends TBase&gt;&gt; processMap; // 处理时根据读取到的方法名获取到对应的函数类进行处理 @Override public void process(TProtocol in, TProtocol out) throws TException &#123; // 读取方法，调用对应的函数进行处理 TMessage msg = in.readMessageBegin(); ProcessFunction fn = processMap.get(msg.name); fn.process(msg.seqid, in, out, iface); &#125;&#125;// thrift自动生成的 UserService.Processorpublic static class Processor&lt;I extends Iface&gt; extends TBaseProcessor&lt;I&gt; implements TProcessor &#123; // 设置iface为我们实现的 UserServiceImpl类 // 同时设置了处理的map&lt;方法名，处理逻辑类&gt; public Processor(I iface) &#123; super(iface, getProcessMap(new HashMap&lt;String, ProcessFunction&lt;I, ? extends TBase&gt;&gt;())); &#125; // 设置各个方法名对应的处理map信息（这里只有searchUsers一个方法） private static &lt;I extends Iface&gt; Map&lt;String, ProcessFunction&lt;I, ? extends TBase&gt;&gt; getProcessMap(Map&lt;String, ProcessFunction&lt;I, ? extends TBase&gt;&gt; processMap) &#123; processMap.put(\"searchUsers\", new searchUsers()); return processMap; &#125;&#125; 再来看下 TServer.Args，它其实类似于我们平时使用的builder模式，用来构造 TServer使用 12345678910111213141516171819public static class Args extends AbstractServerArgs&lt;Args&gt; &#123; public Args(TServerTransport transport) &#123; super(transport); &#125;&#125;// 这里构造了server需要的全部基础类public static abstract class AbstractServerArgs&lt;T extends AbstractServerArgs&lt;T&gt;&gt; &#123; // 传输层，会使用之前构造的 TServerSocket final TServerTransport serverTransport; // 处理工厂，会返回之前构造传入进来的 UserService.Processor TProcessorFactory processorFactory; // 传输层的输入输出工厂，默认空实现，会将入参的TTransport直接返回 TTransportFactory inputTransportFactory = new TTransportFactory(); TTransportFactory outputTransportFactory = new TTransportFactory(); // 协议的输入输出，默认使用二进制的 TBinaryProtocol TProtocolFactory inputProtocolFactory = new TBinaryProtocol.Factory(); TProtocolFactory outputProtocolFactory = new TBinaryProtocol.Factory();&#125; 创建server实例启动最后启动server，这次我们只看最简单的 TSimpleServer 实现 12345678910111213141516171819202122232425262728293031// TSimplerServer.serve 核心代码public void serve() &#123; while (!stopped_) &#123; TTransport client = null; TProcessor processor = null; TTransport inputTransport = null; TTransport outputTransport = null; TProtocol inputProtocol = null; TProtocol outputProtocol = null; ServerContext connectionContext = null; try &#123; // 等待客户端连接（初始启动阻塞的位置） client = serverTransport_.accept(); // 有客户端连接接入 if (client != null) &#123; // 从对应工厂获取实例 processor = processorFactory_.getProcessor(client); inputTransport = inputTransportFactory_.getTransport(client); outputTransport = outputTransportFactory_.getTransport(client); inputProtocol = inputProtocolFactory_.getProtocol(inputTransport); outputProtocol = outputProtocolFactory_.getProtocol(outputTransport); while (true) &#123; // 调用process进行逻辑处理 processor.process(inputProtocol, outputProtocol); &#125; &#125; &#125; catch (TTransportException ttx) &#123; // 代码省略 &#125; &#125;&#125; client初始化及调用相关代码如下 1234567891011121314// 初始化网络连接TTransport transport = new TSocket(\"localhost\", 12345);transport.open();// 构造协议及客户端TProtocol protocol = new TBinaryProtocol(transport);UserService.Client client = new UserService.Client(protocol);// 发起调用获取结果UserSearchResult userRes = client.searchUsers(\"zhangsan\");System.out.println(userRes);// 关闭连接transport.close(); 下面我们来依次分析一下 初始化网络连接12TTransport transport = new TSocket(\"localhost\", 12345);transport.open(); TSocket是对java Socket的包装 12345678910111213141516// TSocket.openpublic void open() throws TTransportException &#123; if (socket_ == null) &#123; initSocket(); &#125; try &#123; // 建立连接及后期构造输入输出流 socket_.connect(new InetSocketAddress(host_, port_), connectTimeout_); inputStream_ = new BufferedInputStream(socket_.getInputStream()); outputStream_ = new BufferedOutputStream(socket_.getOutputStream()); &#125; catch (IOException iox) &#123; close(); throw new TTransportException(TTransportException.NOT_OPEN, iox); &#125;&#125; 构造客户端及调用1234TProtocol protocol = new TBinaryProtocol(transport);UserService.Client client = new UserService.Client(protocol);UserSearchResult userRes = client.searchUsers(\"zhangsan\"); UserService.Client也是thrift自动生成的代码，看下searchUsers方法调用的实现 123456789101112131415161718192021222324// UserService.Clientpublic static class Client extends org.apache.thrift.TServiceClient implements Iface &#123; public UserSearchResult searchUsers(String name) throws TException &#123; send_searchUsers(name); return recv_searchUsers(); &#125; // 发送消息 public void send_searchUsers(String name) throws TException &#123; searchUsers_args args = new searchUsers_args(); args.setName(name); sendBase(\"searchUsers\", args); &#125; // 接受处理结果 public UserSearchResult recv_searchUsers() throws TException &#123; searchUsers_result result = new searchUsers_result(); receiveBase(result, \"searchUsers\"); if (result.isSetSuccess()) &#123; return result.success; &#125; throw new TApplicationException(MISSING_RESULT, \"searchUsers failed: unknown result\"); &#125;&#125; thrift会为我们定义的结构和属性生成相关的类，包含我们定义的参数信息也会有对应的类，每个生成的类型会两个方法，read 和 write 来使用 TProtocol 来实现序列化和传输数据 这里以searchUsers_args（参数对应类）看一下相关的生成代码，代码量比较多，我们只看下核心部分实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// 1. 定义了相关字段及结构信息// 2. 通过TProtocol读取写入数据public static class searchUsers_args implements TBase&lt;UserService.searchUsers_args, UserService.searchUsers_args._Fields&gt;, Serializable, Cloneable, Comparable&lt;UserService.searchUsers_args&gt; &#123; // 定义类对应的结构 private static final TStruct STRUCT_DESC = new TStruct(\"searchUsers_args\"); // 结构中的字段信息（id、名称、类型信息） private static final TField NAME_FIELD_DESC = new TField(\"name\", TType.STRING, (short)1); // 用了通过TProtocol读写(接受、发送) searchUsers_args 数据 private static final SchemeFactory STANDARD_SCHEME_FACTORY = new searchUsers_argsStandardSchemeFactory(); // 参数对应的字段 public String name; // required // 参数结构中对应的每个字段field枚举结构信息 public enum _Fields implements org.apache.thrift.TFieldIdEnum &#123; NAME((short)1, \"name\"); // 名称和属性Fields的映射 private static final Map&lt;String, UserService.searchUsers_args._Fields&gt; byName = new HashMap&lt;&gt;(); // 一些Fields查询逻辑 &#125; public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException &#123; scheme(iprot).read(iprot, this); &#125; public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException &#123; scheme(oprot).write(oprot, this); &#125; private static class searchUsers_argsStandardSchemeFactory implements SchemeFactory &#123; public UserService.searchUsers_args.searchUsers_argsStandardScheme getScheme() &#123; return new UserService.searchUsers_args.searchUsers_argsStandardScheme(); &#125; &#125; private static class searchUsers_argsStandardScheme extends StandardScheme&lt;UserService.searchUsers_args&gt; &#123; public void read(TProtocol iprot, UserService.searchUsers_args struct) throws TException &#123; TField schemeField; // 开始读取结构信息 iprot.readStructBegin(); while (true) &#123; // 开始读取Field schemeField = iprot.readFieldBegin(); // 如果是结束标识则跳过 if (schemeField.type == TType.STOP) &#123; break; &#125; // 根据读取到的id匹配到及类型，再读取对应的值并设置 switch (schemeField.id) &#123; case 1: // NAME if (schemeField.type == TType.STRING) &#123; struct.name = iprot.readString(); struct.setNameIsSet(true); &#125; else &#123; // 类型不同则跳过 TProtocolUtil.skip(iprot, schemeField.type); &#125; break; default: TProtocolUtil.skip(iprot, schemeField.type); &#125; iprot.readFieldEnd(); &#125; iprot.readStructEnd(); &#125; public void write(TProtocol oprot, UserService.searchUsers_args struct) throws TException &#123; // 开始写入结构信息 oprot.writeStructBegin(STRUCT_DESC); if (struct.name != null) &#123; // 写入Field信息 oprot.writeFieldBegin(NAME_FIELD_DESC); oprot.writeString(struct.name); oprot.writeFieldEnd(); &#125; // 写入结束信息 oprot.writeFieldStop(); oprot.writeStructEnd(); &#125; &#125; // 这里使用了 searchUsers_argsStandardSchemeFactory private static &lt;S extends IScheme&gt; S scheme(TProtocol proto) &#123; return (StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme(); &#125;&#125; 构造参数完成后，调用sendBase进行数据发送，sendBase为父类TServiceClient中的方法 消息接收则使用对应的receiveBase方法 123456789101112131415161718192021222324252627282930313233343536public abstract class TServiceClient &#123; // 发送 protected void sendBase(String methodName, TBase&lt;?,?&gt; args) throws TException &#123; sendBase(methodName, args, TMessageType.CALL); &#125; private void sendBase(String methodName, TBase&lt;?,?&gt; args, byte type) throws TException &#123; // 开始放送消息（方法名、类型、序号-递增） oprot_.writeMessageBegin(new TMessage(methodName, type, ++seqid_)); // 调用args类的write方法写入数据 args.write(oprot_); // 结束写入并刷新 oprot_.writeMessageEnd(); oprot_.getTransport().flush(); &#125; // 接收结果 protected void receiveBase(TBase&lt;?,?&gt; result, String methodName) throws TException &#123; TMessage msg = iprot_.readMessageBegin(); // 读取到异常信息处理 if (msg.type == TMessageType.EXCEPTION) &#123; TApplicationException x = new TApplicationException(); x.read(iprot_); iprot_.readMessageEnd(); throw x; &#125; // 读取到的消息序号和自己发送的序号不同时抛出异常，说明不是自己发送的消息的响应 if (msg.seqid != seqid_) &#123; throw new TApplicationException(TApplicationException.BAD_SEQUENCE_ID, String.format(\"%s failed: out of sequence response: expected %d but got %d\", methodName, seqid_, msg.seqid)); &#125; // 调用对应searchUsers_result的read方法，逻辑类似searchUsers_args result.read(iprot_); iprot_.readMessageEnd(); &#125;&#125; server接收请求处理及响应之前server部分看到处理化等待连接，这里直接从接收到请求处理逻辑开始 123456789101112131415161718// TBaseProcessor.processpublic void process(TProtocol in, TProtocol out) throws TException &#123; TMessage msg = in.readMessageBegin(); // 获取方法名称，找到对应的处理函数 ProcessFunction fn = processMap.get(msg.name); if (fn == null) &#123; TProtocolUtil.skip(in, TType.STRUCT); in.readMessageEnd(); TApplicationException x = new TApplicationException(TApplicationException.UNKNOWN_METHOD, \"Invalid method name: '\"+msg.name+\"'\"); out.writeMessageBegin(new TMessage(msg.name, TMessageType.EXCEPTION, msg.seqid)); x.write(out); out.writeMessageEnd(); out.getTransport().flush(); &#125; else &#123; // 使用找到的处理函数进行逻辑处理 fn.process(msg.seqid, in, out, iface); &#125;&#125; 这里我们关注下ProcessFunction 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class ProcessFunction&lt;I, T extends TBase&gt; &#123; // 方法名称 private final String methodName; public final void process(int seqid, TProtocol iprot, TProtocol oprot, I iface) throws TException &#123; // 有各个子类提供对应的类实例 T args = getEmptyArgsInstance(); try &#123; // 通过TProtocol读取数据 args.read(iprot); &#125; catch (TProtocolException e) &#123; // 忽略异常处理 &#125; iprot.readMessageEnd(); TSerializable result = null; byte msgType = TMessageType.REPLY; try &#123; // 获取结果 result = getResult(iface, args); &#125; catch (TTransportException ex) &#123; // 忽略异常处理 &#125; if(!isOneway()) &#123; // 写入响应结果 oprot.writeMessageBegin(new TMessage(getMethodName(), msgType, seqid)); result.write(oprot); oprot.writeMessageEnd(); oprot.getTransport().flush(); &#125; &#125; protected boolean rethrowUnhandledExceptions()&#123; return false; &#125; protected abstract boolean isOneway(); public abstract TBase getResult(I iface, T args) throws TException; public abstract T getEmptyArgsInstance(); public String getMethodName() &#123; return methodName; &#125;&#125; 对于上面例子，对应的ProcessFunction子类为 searchUsers 12345678910111213141516171819202122232425public static class searchUsers&lt;I extends UserService.Iface&gt; extends ProcessFunction&lt;I, UserService.searchUsers_args&gt; &#123; public searchUsers() &#123; super(\"searchUsers\"); &#125; public UserService.searchUsers_args getEmptyArgsInstance() &#123; return new UserService.searchUsers_args(); &#125; protected boolean isOneway() &#123; return false; &#125; @Override protected boolean rethrowUnhandledExceptions() &#123; return false; &#125; public UserService.searchUsers_result getResult(I iface, UserService.searchUsers_args args) throws TException &#123; UserService.searchUsers_result result = new UserService.searchUsers_result(); // 调用iface(业务逻辑实现)进行方法处理，获取并设置结果 result.success = iface.searchUsers(args.name); return result; &#125;&#125; 以上即为简单的一次thrift调用和响应的实现逻辑流程 简单总结一下就是thrift会为每种类型生成对应的一个结构，包括如果参数为多个字段也会合并生成一个结构TBase，其中会使用TProtocol（其中会使用TTransport进行消息发送）进行对应结构数据的写入和读取 每次消息会被包装成一个TMessage，其中会包括方法名、消息类型及递增的一个序号(收到响应时用来进行对应)","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"thrift","slug":"thrift","permalink":"https://zhengw-tech.com/tags/thrift/"}]},{"title":"Thrift(一)-快速入门","slug":"thrift","date":"2021-12-12T13:26:08.000Z","updated":"2022-05-29T09:07:25.558Z","comments":true,"path":"2021/12/12/thrift/","link":"","permalink":"https://zhengw-tech.com/2021/12/12/thrift/","excerpt":"Thrift是facebook开发的一款轻量级的跨语言的RPC实现，它为数据传输、数据序列化和应用层的处理提供了清晰的抽象和实现。它的代码生成器使用简单的定义语言来生成跨语言的代码，来构建可互操作的RPC客户端和服务端。这篇文章主要简单介绍一下thrift的使用","text":"Thrift是facebook开发的一款轻量级的跨语言的RPC实现，它为数据传输、数据序列化和应用层的处理提供了清晰的抽象和实现。它的代码生成器使用简单的定义语言来生成跨语言的代码，来构建可互操作的RPC客户端和服务端。这篇文章主要简单介绍一下thrift的使用 使用thrift的使用可以分为如下几个步骤 使用thrift的接口描述语言（IDL）定义好数据类型和服务接口 安装thrift代码生成工具，来生成对应语言的客户端和服务端代码 服务端需要对具体的服务接口实现逻辑进行编码实现 编写初始化代码进行服务端/客户端的启动或调用 下面我们来分别具体看一下 使用IDL定义数据类型和服务接口因为要实现跨语言的通信，那么就不能使用任何一种语言来定义数据类型和接口，所以thrift提供了IDL来定义相关的信息，其中支持的信息包括 基本类型、结构体、容器、异常、服务接口 等 基本类型 bool byte i16 (有符号的16位整型) i32 (有符号的32位整型) i64 (有符号的64位整型) double (64位浮点数) string (字符串) 因为有的语言没有无符号的数值类型，所以thrift提供的都是有符号的整形 特殊类型 binary （bytes数组) 结构体结构体是用来定义跨语言的通用对象，类似C语言中的结构体或者面向对象语言中的类 1234567// 结构体struct Example &#123; 1:i32 number = 10, // 其中的属性信息，属性可以设置默认值 2:i64 bigNumber, 3:double decimals, 4:string name = &quot;thrifty&quot;&#125; 容器容器即是我们平时常用的集合类，类似java中的list, map等，支持的类型如下 list&lt;type> set&lt;type> map&lt;type1, type2&gt; 异常语法基本同结构体，除了使用 exception 替换 struct 关键字 服务接口定义一个服务接口与面向对象中定义一个接口类似 12345service StringCache &#123; void set(1:i32 key, 2:string value), string get(1:i32 key) throws (1:KeyNotFound knf), void delete(1:i32 key)&#125; 使用thrift提供的跨语言的通用类型系统，就不需要开发人员编写序列化相关代码，thrift会根据定义信息来生成对应语言的相关代码，同时会为每种类型生成read和write方法，使用 TProtocol 对象来实现序列化和传输 下面我们来定义一个服务接口和相关的数据类型（使用Java语言） 123456789101112131415// 定义用户信息struct User &#123; 1:string name; 2:i32 age;&#125;// 定义查询结果struct UserSearchResult &#123; 1:list&lt;User&gt; users;&#125;// 定义查询服务接口service UserService &#123; UserSearchResult searchUsers(1:string name);&#125; 使用thrift代码生成工具生成对应语言(Java)代码windows系统可以根据此页面的windows下载链接进行代码生成工具的下载使用 mac系统可以使用homebrew进行安装brew install thrift 安装完成后，在文件对应路径执行如下命令 thrift --gen java userService.thrift 会在路径下生成gen-java文件夹，其中会包含生成的如下三个文件 User.java, UserSearchResult.java , UserService.java 创建对应的java项目，引入thrift的包 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.15.0&lt;/version&gt;&lt;/dependency&gt; 之后将之前生成的代码复制到项目中即可 服务接口实现服务接口实现通过实现生成的接口的Iface即可 1234567891011121314151617181920212223// UserService.Iface 为自动生成的类public class UserServiceImpl implements UserService.Iface &#123; @Override public UserSearchResult searchUsers(String name) throws TException &#123; // 这里为随便模拟的数据，实际可替换为对应的功能 List&lt;User&gt; userList = new ArrayList&lt;&gt;(); &#123; final User user = new User(); user.setName(name); userList.add(user); &#125; &#123; final User user = new User(); user.setName(name + \"1\"); userList.add(user); &#125; final UserSearchResult result = new UserSearchResult(); result.setUsers(userList); return result; &#125;&#125; 实现客户端服务端初始化代码最后我们来实现服务端和客户端的初始化代码，进行启动并发起实际调用 服务端初始化123456789101112// 设置监听连接的端口TServerTransport serverTransport = new TServerSocket(12345);// 创建服务接口实现的实例，创建对应processor类UserService.Processor&lt;UserServiceImpl&gt; processor = new UserService.Processor&lt;&gt;(new UserServiceImpl());// 设置启动服务端需要的参数：transport 与 processorTServer.Args serverArgs = new TServer.Args(serverTransport).processor(processor);// 创建服务并启动TServer server = new TSimpleServer(serverArgs);System.out.println(\"Starting the simple server...\");server.serve(); 客户端代码1234567891011121314// 设置连接服务端的地址信息TTransport transport = new TSocket(\"localhost\", 12345);transport.open();// 构造客户端TProtocol protocol = new TBinaryProtocol(transport);UserService.Client client = new UserService.Client(protocol);// 进行请求获取响应UserSearchResult userRes = client.searchUsers(\"zhangsan\");System.out.println(JSON.toJSONString(userRes));// 关闭连接transport.close(); 待服务端启动后，再启动客户端即可获取对应的数据 例子代码：https://github.com/zavier/thrift-demo 以上就是thrift的基本使用方式，构造服务端和客户端的代码及实现原理我们后面继续进行分析。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"thrift","slug":"thrift","permalink":"https://zhengw-tech.com/tags/thrift/"}]},{"title":"Maven生命周期与插件笔记","slug":"maven-lifecycle","date":"2021-09-25T14:24:06.000Z","updated":"2022-03-12T14:36:32.807Z","comments":true,"path":"2021/09/25/maven-lifecycle/","link":"","permalink":"https://zhengw-tech.com/2021/09/25/maven-lifecycle/","excerpt":"工作中大部分Java项目都是基于maven来进行项目的构建等工作，但是对于maven这个高频用到的工具其实了解程度还不够，下面主要是学习《Maven实战》中记录的关于生命周期与插件相关的笔记 maven生命周期与插件maven的生命周期是从大量项目和构建工作中总结抽象出来的对所有构建过程进行的抽象和统一，这个生命周期包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等几乎所有构建步骤 虽然maven抽象出了生命周期的概念，但是它并没有对相关的功能进行实现，就像它是负责定义了接口，但是具体实现是由插件来完成，这样可以很好的保证自身的轻量和扩展性","text":"工作中大部分Java项目都是基于maven来进行项目的构建等工作，但是对于maven这个高频用到的工具其实了解程度还不够，下面主要是学习《Maven实战》中记录的关于生命周期与插件相关的笔记 maven生命周期与插件maven的生命周期是从大量项目和构建工作中总结抽象出来的对所有构建过程进行的抽象和统一，这个生命周期包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等几乎所有构建步骤 虽然maven抽象出了生命周期的概念，但是它并没有对相关的功能进行实现，就像它是负责定义了接口，但是具体实现是由插件来完成，这样可以很好的保证自身的轻量和扩展性 而对于maven插件，还有个插件目标的概念，就是可以认为一个插件本身是可以提供很多种功能的，一种功能就是一个插件目标，比如对于 maven-dependency-plugin 这个插件，我们通过执行mvn dependency:help可以看到它有21个插件目标，截取部分内容如下，其中就包含我们平时分析依赖使用的mvn dependency:tree（其中冒号前面是插件前缀，冒号后面是该插件的目标） 123456789101112[INFO] --- maven-dependency-plugin:2.8:help (default-cli) @ maven-code ---[INFO] Maven Dependency Plugin 2.8 Provides utility goals to work with dependencies like copying, unpacking, analyzing, resolving and many more.This plugin has 21 goals:dependency:analyze Analyzes the dependencies of XXX(已省略)dependency:analyze-dep-mgt This mojo looks at the dependencies after final resolution XXX(已省略) maven插件绑定平时我们执行的mvn clean 、mvn compile 、mvn package等等其实都是在调用maven的生命周期阶段，而这些生命周期又与插件进行绑定，执行插件的目标来完成功能，在执行后的命令行输出中可以看到执行的插件目标 maven已经预置了常用的一些绑定配置 声明周期阶段 插件目标 compile maven-compiler-plugin:compile test maven-surefire-plugin:test package maven-jar-plugin:jar install maven-install-plugin:install deploy maven-deploy-plugin:deploy 自定义绑定如果我们想将某个插件目标绑定到生命周期上，可以在文件中自行配置，如想配置在compile阶段就生成源码包： 1234567891011121314151617&lt;!-- pom.xml --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;!-- 插件目标要绑定的生命周期阶段，这里指定compile阶段 --&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;!-- 这里指定要执行的插件目标， jar-no-fork目标负责将源码打成jar包 --&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 这样在执行mvn compile的时候就会发现源码包自动生成在target目录下 可以通过mvn help:describe -Dplugin=org.apache.maven.plugins:maven-source-plugin:2.2.1 -Ddetail查看插件信息，其中包含插件目标默认绑定的生命周期阶段 编写maven插件创建插件对于一些特殊场景，我们可以编写自己的maven插件 1234# 通过maven插件骨架创建项目（也可以通过idea等选择后创建）mvn archetype:generate \\ -DarchetypeGroupId=org.apache.maven.archetypes \\ -DarchetypeArtifactId=maven-archetype-plugin 创建项目后会生成一些样例代码，主要有一个核心代码MyMojo.java 12345678910111213141516171819202122232425262728293031323334// 这是一个生成一个固定文件(touch.txt)到指定目录的插件// 必须继承 AbstractMojo， @Mojob注解中的name就是插件目标名称，defaultPhase为默认执行阶段@Mojo(name = \"touchA\", defaultPhase = LifecyclePhase.COMPILE)public class MyMojo extends AbstractMojo &#123; /** * 输出路径目录 */ @Parameter(defaultValue = \"$&#123;project.build.directory&#125;\", property = \"outputDir\", required = true) private File outputDirectory; public void execute() throws MojoExecutionException &#123; // 正常的业务逻辑，这里是写文件 File f = outputDirectory; if (!f.exists()) &#123; f.mkdirs(); &#125; File touch = new File(f, \"touch.txt\"); FileWriter w = null; try &#123; w = new FileWriter(touch); w.write(\"touch.txt\"); &#125; catch (IOException e) &#123; throw new MojoExecutionException(\"Error creating file \" + touch, e); &#125; finally &#123; if (w != null) &#123; try &#123; w.close(); &#125; catch (IOException e) &#123; // ignore &#125; &#125; &#125; &#125;&#125; 之后执行mvn install即可安装到本地 自定义插件使用在项目中引入对应插件 12345&lt;plugin&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/plugin&gt; 之后在命令行中执行mvn org.example:maven-plugin-demo:1.0-SNAPSHOT:touchA即可在target目录下发现创建的touch.txt文件 如果想将其绑定到maven声明周期中自动执行，如编译阶段执行，那么可以配置如下 123456789101112131415&lt;plugin&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 绑定的阶段 --&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;!-- 执行的目标 --&gt; &lt;goal&gt;touchA&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://zhengw-tech.com/tags/maven/"}]},{"title":"定时任务实现原理浅析","slug":"timed-task","date":"2021-09-20T14:50:53.000Z","updated":"2022-04-30T13:04:50.871Z","comments":true,"path":"2021/09/20/timed-task/","link":"","permalink":"https://zhengw-tech.com/2021/09/20/timed-task/","excerpt":"如果我们有想固定间隔时间执行的任务等，自己实现的一种方式是可以新启动一个线程，在其中sleep固定的时间后执行，但是这种方式在任务多的时候肯定是不行的。现在已经有很多现成的工具我们可以直接使用，这里主要介绍一下JDK的ScheduledThreadPoolExecutor与Netty的HashedWheelTimer，看一下它们的实现原理","text":"如果我们有想固定间隔时间执行的任务等，自己实现的一种方式是可以新启动一个线程，在其中sleep固定的时间后执行，但是这种方式在任务多的时候肯定是不行的。现在已经有很多现成的工具我们可以直接使用，这里主要介绍一下JDK的ScheduledThreadPoolExecutor与Netty的HashedWheelTimer，看一下它们的实现原理 ScheduledThreadPoolExecutorScheduledThreadPoolExecutor是JDK自带的一个用于执行周期任务的线程池，用法大致如下 123456// 创建任务线程池ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(5);// 提交任务executor.schedule(() -&gt; System.out.println(\"111\"), 1, TimeUnit.SECONDS);executor.scheduleAtFixedRate(() -&gt; System.out.println(\"22\"), 2, 3, TimeUnit.SECONDS);executor.scheduleWithFixedDelay(() -&gt; System.out.println(\"33\"), 1, 2, TimeUnit.SECONDS); 了解它原理话需要先了解一下线程池的使用，线程池中是多个线程从一个阻塞队列中获取任务来进行执行 ScheduledThreadPoolExecutor是继承了ThreadPoolExecutor，其中最大的一个区别是提供了一个延迟工作队列DelayedWorkQueue，内部是一个优先级队列，需要最先执行的排在最前面，每次插入数据的时候会重新排序 同时还实现了ScheduledFutureTask任务类，其中除了记录原始任务外还会记录任务要执行的时间等信息 这样每次拿到任务的时候都是需要最先执行的，判断下如果到达了执行时间就可以执行 HashedWheelTimer使用ScheduledThreadPoolExecutor最大的一个问题是每次提交任务的时候，都会再次进行一下队列的排序，这个工作时间复杂度为O(nlogn)，下面我们看一下HashedWheelTimer的使用例子及实现 12345678// 使用示例HashedWheelTimer timer = new HashedWheelTimer();Timeout timeout = timer.newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; System.out.println(\"111\"); &#125;&#125;, 1, TimeUnit.SECONDS); 实现原理如下图所示 有一个固定长度的数组（时间轮），有一个可以理解为指针，每隔固定时间(tickDuration)会移动到下一个数组索引上，循环往复。当指针到达对应数组元素时，会获取链表中的元素进行遍历，如果任务达到了指定轮次和执行时间就执行，否则减少其中的轮次 每个数组元素有一个定时任务的链表，当有一个定时任务提交时，会根据它距离执行的时间，和任务线程启动的时间，来根据差值计算出任务需要放置到的索引位置（超过一圈的会增加一个轮次），插入到对应的链表中 O(1) 。 下面分析一下对应源码，我们只根据主线看一下最核心的流程，相关代码进行了简化调整 12// 初始化 HashedWheelTimerHashedWheelTimer timer = new HashedWheelTimer(); 看下基础的构造器 1234567891011121314151617// 基础构造器（代码已进行简化）public HashedWheelTimer( ThreadFactory threadFactory, long tickDuration, TimeUnit unit, int ticksPerWheel, boolean leakDetection, long maxPendingTimeouts) &#123; // 创建对应的数组 ticksPerWheel默认值为512 wheel = createWheel(ticksPerWheel); // 掩码，用于按位与计算定位索引使用，类似HashMap索引定位方法 mask = wheel.length - 1; // tickDuration默认100ms，将其转为纳秒值后，进行赋值 long duration = unit.toNanos(tickDuration); this.tickDuration = duration; // 创建任务线程(只会创建一个) workerThread = threadFactory.newThread(worker);&#125; 之后开始添加任务 123456Timeout timeout = timer.newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; System.out.println(\"111\"); &#125;&#125;, 1, TimeUnit.SECONDS); 进入对应的源码 12345678910111213141516171819202122232425262728293031public Timeout newTimeout(TimerTask task, long delay, TimeUnit unit) &#123; // 初始化启动时间startTime(基于此时间计算时间差值定位索引)，启动线程 start(); // 用于计算执行时间与startTime的相差时间 long deadline = System.nanoTime() + unit.toNanos(delay) - startTime; // 构造HashedWheelTimeout，添加到对应的队列中 Queue&lt;HashedWheelTimeout&gt; timeouts // 后面在另一个线程中会将对应的的任务分派到时间轮上面 HashedWheelTimeout timeout = new HashedWheelTimeout(this, task, deadline); timeouts.add(timeout); return timeout;&#125;// start函数，进行了一定程度的简化public void start() &#123; switch (WORKER_STATE_UPDATER.get(this)) &#123; case WORKER_STATE_INIT: if (WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_INIT, WORKER_STATE_STARTED)) &#123; // 只有在初始化的时候，这里进行线程的启动 workerThread.start(); &#125; break; &#125; // 等待启动线程中初始化startTime后结束（不然后面添加任务时，无法正确使用startTime值） while (startTime == 0) &#123; try &#123; startTimeInitialized.await(); &#125; catch (InterruptedException ignore) &#123; &#125; &#125;&#125; 线程中对应的代码如下（为了便于理解和关注重点，代码已进行简化调整，详情可以查看对应源码） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970private final class Worker implements Runnable &#123; public void run() &#123; // 初始化 startTime startTime = System.nanoTime(); // 唤醒之前外层的start()函数 startTimeInitialized.countDown(); // 这个任务是一个循环任务，只要是启动状态就会一直循环执行 do &#123; // 获取并等待到下一次执行的时间（相对启动的时间差） final long deadline = waitForNextTick(); if (deadline &gt; 0) &#123; // tick为轮次，计算对应要处理的索引 int idx = (int) (tick &amp; mask); // 将已取消队列中的任务进行清理 processCancelledTasks(); HashedWheelBucket bucket = wheel[idx]; // 将timeouts队列中的任务计算后分派到时间轮对应槽位上 transferTimeoutsToBuckets(); // 进行槽位中所有到期任务的执行(具体在下面分析) bucket.expireTimeouts(deadline); // 轮次+1 tick++; &#125; &#125; while (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_STARTED); // 忽略：未执行的任务等清理工作 &#125; // 获取并等待到下一次执行的时间（相对启动的时间差） private long waitForNextTick() &#123; // 下一轮次的执行时间（相对启动的时间差） long deadline = tickDuration * (tick + 1); // 直到到达执行时间才退出 for (;;) &#123; // 判断到达deadline需要睡眠的时间，如果已经到了则返回当前时间（相对启动的时间差） final long currentTime = System.nanoTime() - startTime; long sleepTimeMs = (deadline - currentTime + 999999) / 1000000; // 已到达指定时间 if (sleepTimeMs &lt;= 0) &#123; return currentTime; &#125; // 时间没到的时候，则sleep差值时间 Thread.sleep(sleepTimeMs); &#125; &#125; // 将timeouts队列中的任务计算后分派到时间轮对应槽位上 private void transferTimeoutsToBuckets() &#123; for (int i = 0; i &lt; 100000; i++) &#123; HashedWheelTimeout timeout = timeouts.poll(); // 用间隔时间除以时间轮的执行周期(默认100ms),计算槽位位置 // 可能大于总槽位数，后面会再次进行计算 long calculated = timeout.deadline / tickDuration; // 计算所在的轮次 timeout.remainingRounds = (calculated - tick) / wheel.length; // 防止处理执行过的任务 final long ticks = Math.max(calculated, tick); // 这里计算真正的槽位索引 int stopIndex = (int) (ticks &amp; mask); // 计算后将其添加到对应槽位里面的队列中 HashedWheelBucket bucket = wheel[stopIndex]; bucket.addTimeout(timeout); &#125; &#125;&#125; 最后看下到期任务的执行部分源码 12345678910111213141516171819202122232425// HashedWheelBucket.expireTimeoutspublic void expireTimeouts(long deadline) &#123; HashedWheelTimeout timeout = head; // 获取槽位对应的链表头，不为空则执行 while (timeout != null) &#123; HashedWheelTimeout next = timeout.next; // 对应的任务到达了当前轮次 if (timeout.remainingRounds &lt;= 0) &#123; // 将当前任务从链表摘除，并获取链表的下一个任务 next = remove(timeout); if (timeout.deadline &lt;= deadline) &#123; // 到期了执行timeout中TimerTask的run方法 timeout.expire(); &#125; &#125; else if (timeout.isCancelled()) &#123; next = remove(timeout); &#125; else &#123; // 没有到达指定轮次的时候，将其轮次减少1 timeout.remainingRounds --; &#125; // 设置值为下一个任务，进入下一次循环判断 timeout = next; &#125;&#125; 以上就是相关的原理分析，如有错误欢迎指正","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"定时任务","slug":"定时任务","permalink":"https://zhengw-tech.com/tags/定时任务/"}]},{"title":"transmittable-thread-local实现原理","slug":"ttl","date":"2021-08-22T11:16:29.000Z","updated":"2021-12-16T15:48:02.897Z","comments":true,"path":"2021/08/22/ttl/","link":"","permalink":"https://zhengw-tech.com/2021/08/22/ttl/","excerpt":"之前简单介绍过 ThreadLocal，但是其中有个问题就是当一个请求中使用到线程池时，无法将主线程中ThreadLocal中的值传递进去，这次我们就看下怎么解决这个问题 比较直接的的方法就是包装一下Runnable或Callable，在创建的时候将主线程中ThreadLocal对应内容传递保存进去，之后执行的时候再取出来重新赋值到对应ThreadLocal中，使用之后再清理掉即可，大致样子如下 1234567891011121314151617181920212223242526272829303132public class SimpleThreadLocalTest &#123; // 创建一个线程池及姓名的ThreadLocal private Executor executor = Executors.newSingleThreadExecutor(); public static ThreadLocal&lt;String&gt; USER_NAME_THREAD_LOCAL = new ThreadLocal&lt;&gt;(); @Test public void test() &#123; USER_NAME_THREAD_LOCAL.set(\"zheng\"); executor.execute(new ThreadLocalRunnable()); &#125; static class ThreadLocalRunnable implements Runnable &#123; private String userName; // 自己定义一个Runnable实现，在创建的时候，记录主线程在ThreadLocal中设置的值 public ThreadLocalRunnable() &#123; this.userName = USER_NAME_THREAD_LOCAL.get(); &#125; @Override public void run() &#123; try &#123; // 在线程池中执行时，重新设置值到ThreadLocal中供后续业务逻辑使用 USER_NAME_THREAD_LOCAL.set(userName); // todo 业务逻辑 System.out.println(\"userName: \" + USER_NAME_THREAD_LOCAL.get()); &#125; finally &#123; // 使用后进行清理 USER_NAME_THREAD_LOCAL.remove(); &#125; &#125; &#125;&#125; 这里很明显可以看出来，自定义的Runnable实现与系统中定义的ThreadLocal进行了强耦合，当有更多的ThreadLocal时会使代码很难维护，比较幸运的是，这种工具已经有了比较好的开源实现，这里就介绍下transmittable-thread-local","text":"之前简单介绍过 ThreadLocal，但是其中有个问题就是当一个请求中使用到线程池时，无法将主线程中ThreadLocal中的值传递进去，这次我们就看下怎么解决这个问题 比较直接的的方法就是包装一下Runnable或Callable，在创建的时候将主线程中ThreadLocal对应内容传递保存进去，之后执行的时候再取出来重新赋值到对应ThreadLocal中，使用之后再清理掉即可，大致样子如下 1234567891011121314151617181920212223242526272829303132public class SimpleThreadLocalTest &#123; // 创建一个线程池及姓名的ThreadLocal private Executor executor = Executors.newSingleThreadExecutor(); public static ThreadLocal&lt;String&gt; USER_NAME_THREAD_LOCAL = new ThreadLocal&lt;&gt;(); @Test public void test() &#123; USER_NAME_THREAD_LOCAL.set(\"zheng\"); executor.execute(new ThreadLocalRunnable()); &#125; static class ThreadLocalRunnable implements Runnable &#123; private String userName; // 自己定义一个Runnable实现，在创建的时候，记录主线程在ThreadLocal中设置的值 public ThreadLocalRunnable() &#123; this.userName = USER_NAME_THREAD_LOCAL.get(); &#125; @Override public void run() &#123; try &#123; // 在线程池中执行时，重新设置值到ThreadLocal中供后续业务逻辑使用 USER_NAME_THREAD_LOCAL.set(userName); // todo 业务逻辑 System.out.println(\"userName: \" + USER_NAME_THREAD_LOCAL.get()); &#125; finally &#123; // 使用后进行清理 USER_NAME_THREAD_LOCAL.remove(); &#125; &#125; &#125;&#125; 这里很明显可以看出来，自定义的Runnable实现与系统中定义的ThreadLocal进行了强耦合，当有更多的ThreadLocal时会使代码很难维护，比较幸运的是，这种工具已经有了比较好的开源实现，这里就介绍下transmittable-thread-local 使用先来看下它的使用方法 123456789101112131415161718192021public class TtlMain &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); // 这里要将ThreadLocal替换为 TransmittableThreadLocal TransmittableThreadLocal&lt;String&gt; nameThreadLocal = new TransmittableThreadLocal&lt;&gt;(); @Test public void test() &#123; // 父线程中进行ThreadLocal赋值 nameThreadLocal.set(\"zheng\"); // 注意这里要用TtlRunnable包装一下Runnable Runnable r = TtlRunnable.get(() -&gt; &#123; // 这里进行业务逻辑的处理，如获取TransmittableThreadLocal中的值，进行使用等 final String s = nameThreadLocal.get(); System.out.println(s); &#125;); // 在线程池中执行任务 executorService.execute(r); &#125;&#125; 如果觉得每次使用TtlRunnable进行包装比较麻烦，可以使用它提供的线程池进行包装 12345678910111213141516public class TtlMain &#123; // 使用 TtlExecutors.getTtlExecutorService 对线程池进行包装，就可以不使用 TtlRunnable ExecutorService executorService = TtlExecutors.getTtlExecutorService(Executors.newSingleThreadExecutor()); TransmittableThreadLocal&lt;String&gt; nameThreadLocal = new TransmittableThreadLocal&lt;&gt;(); @Test public void test() &#123; nameThreadLocal.set(\"zheng\"); executorService.execute(() -&gt; &#123; final String s = nameThreadLocal.get(); System.out.println(s); &#125;); &#125;&#125; 原理原理部分相对啰嗦些，着急知道结果的可以直接看小结部分 TransmittableThreadLocal这里面有个很重要的类：TransmittableThreadLocal，先来看下它的get, set方法部分源码实现 这里可以看到，它继承了InheritableThreadLocal，在 get 和 set 时直接调用父类 InheritableThreadLocal 的方法，就是在set时多了一步，会将TransmittableThreadLocal的实例统一保存起来，这个后面在进行跨线程赋值传递的时候会用到，不需要到处去找都有哪些TransmittableThreadLocal实例的数据要进行复制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// TransmittableThreadLocal 继承了 InheritableThreadLocalpublic class TransmittableThreadLocal&lt;T&gt; extends InheritableThreadLocal&lt;T&gt; implements TtlCopier&lt;T&gt; &#123; // get时，直接调用父类InheritableThreadLocal的get方法即可 @Override public final T get() &#123; T value = super.get(); if (disableIgnoreNullValueSemantics || null != value) addThisToHolder(); return value; &#125; @Override public final void set(T value) &#123; if (!disableIgnoreNullValueSemantics &amp;&amp; null == value) &#123; remove(); &#125; else &#123; // 设置值时，先调用父类InheritableThreadLocal的 set 方法 super.set(value); // 将此TransmittableThreadLocal实例添加到holder的key中 addThisToHolder(); &#125; &#125; // InheritableThreadLocal中存储的是Map结构， // 其中的key为 TransmittableThreadLocal，value没有使用，永远为null // 这里维护了所有使用到的TransmittableThreadLocal实例，统一添加到holder中，后面使用时比较方便 private static final InheritableThreadLocal&lt;WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, ?&gt;&gt; holder = new InheritableThreadLocal&lt;WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, ?&gt;&gt;() &#123; @Override protected WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, ?&gt; initialValue() &#123; return new WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt;(); &#125; @Override protected WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, ?&gt; childValue(WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, ?&gt; parentValue) &#123; return new WeakHashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt;(parentValue); &#125; &#125;; // 将此次增加的TransmittableThreadLocal添加到holder中 // 通过此方法，可以将所有用到的TransmittableThreadLocal实例统一记录下来 private void addThisToHolder() &#123; if (!holder.get().containsKey(this)) &#123; holder.get().put((TransmittableThreadLocal&lt;Object&gt;) this, null); &#125; &#125;&#125; 同时需要注意的是，如果我们有深拷贝的需求，可以实现一个TransmittableThreadLocal子类，重写它的copy方法即可 1234567TransmittableThreadLocal&lt;String&gt; nameThreadLocal = new TransmittableThreadLocal&lt;String&gt;() &#123; @Override public String copy(String parentValue) &#123; // 实现自己的复制逻辑 return super.copy(parentValue); &#125;&#125;; Transmitter除此之外，还有一个很重要的类：Transmitter，它是TransmittableThreadLocal的一个内部类，其中的方法都是静态方法，主要用来在线程切换时进行数据的快照保存(capture)、重放(replay)和恢复(restore)，在看源码之前先看一下使用的例子 利用Transmitter将主线程的数据快照进行记录 在子线程/线程池中执行时，将记录的快照数据进行重新设置到当前线程，并将当前子线程的数据进行备份 执行完毕后将备份的数据恢复到当前线程数据中 12345678910111213141516public void test1() &#123; // 记录主线程当时的数据快照 Object captured = Transmitter.capture(); Callable&lt;String&gt; callable = () -&gt; &#123; // 将记录的主线程快照进行重放，并将当前子线程的数据快照进行备份 Object backup = Transmitter.replay(captured); // (2) try &#123; System.out.println(\"Hello\"); return \"World\"; &#125; finally &#123; // 执行完毕之后，恢复之前备份的子线程快照数据 Transmitter.restore(backup); // (3) &#125; &#125;; executorService.submit(callable);&#125; 下面依次看下这几个步骤的实现 Transmitter.capture这个方法本身比较简单，它是在主线程中执行的，主要就是将之前记录到的所有TransmittableThreadLocal实例数据转成对应map进行返回 123456789101112131415161718192021222324252627282930313233343536373839public static class Transmitter &#123; public static Object capture() &#123; // 将复制的数据保存到快照类中 return new Snapshot(captureTtlValues(), captureThreadLocalValues()); &#125; // 将之前holder中记录的所有使用到的TransmittableThreadLocal实例复制出来 private static HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; captureTtlValues() &#123; HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; ttl2Value = new HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt;(); for (TransmittableThreadLocal&lt;Object&gt; threadLocal : holder.get().keySet()) &#123; ttl2Value.put(threadLocal, threadLocal.copyValue()); &#125; return ttl2Value; &#125; // 这个方式是用于将threadLocalHolder中的ThreadLocal复制出来（这个后面会介绍） private static HashMap&lt;ThreadLocal&lt;Object&gt;, Object&gt; captureThreadLocalValues() &#123; final HashMap&lt;ThreadLocal&lt;Object&gt;, Object&gt; threadLocal2Value = new HashMap&lt;ThreadLocal&lt;Object&gt;, Object&gt;(); for (Map.Entry&lt;ThreadLocal&lt;Object&gt;, TtlCopier&lt;Object&gt;&gt; entry : threadLocalHolder.entrySet()) &#123; final ThreadLocal&lt;Object&gt; threadLocal = entry.getKey(); final TtlCopier&lt;Object&gt; copier = entry.getValue(); threadLocal2Value.put(threadLocal, copier.copy(threadLocal.get())); &#125; return threadLocal2Value; &#125;&#125;// 快照类private static class Snapshot &#123; final HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; ttl2Value; final HashMap&lt;ThreadLocal&lt;Object&gt;, Object&gt; threadLocal2Value; private Snapshot(HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; ttl2Value, HashMap&lt;ThreadLocal&lt;Object&gt;, Object&gt; threadLocal2Value) &#123; this.ttl2Value = ttl2Value; this.threadLocal2Value = threadLocal2Value; &#125;&#125; Transmitter.replay这个方法是在子线程/线程池中执行的，用于将快照中的数据设置到当前线程中，并将当前线程中的数据进行备份返回 1234567891011121314151617181920212223242526272829303132333435363738394041// 这里主要分析下replayTtlValues方法，replayThreadLocalValues逻辑类似就不看了public static Object replay(@NonNull Object captured) &#123; final Snapshot capturedSnapshot = (Snapshot) captured; return new Snapshot(replayTtlValues(capturedSnapshot.ttl2Value), replayThreadLocalValues(capturedSnapshot.threadLocal2Value));&#125;@NonNullprivate static HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; replayTtlValues(@NonNull HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; captured) &#123; HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; backup = new HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt;(); // 遍历当前子线程中的所有TransmittableThreadLocal for (final Iterator&lt;TransmittableThreadLocal&lt;Object&gt;&gt; iterator = holder.get().keySet().iterator(); iterator.hasNext(); ) &#123; TransmittableThreadLocal&lt;Object&gt; threadLocal = iterator.next(); // 将当前子线程的数据进行备份 backup.put(threadLocal, threadLocal.get()); // 快照中没有的TransmittableThreadLocal实例要进行删除 // 避免使用到在调用capture之后添加的值 if (!captured.containsKey(threadLocal)) &#123; iterator.remove(); threadLocal.superRemove(); &#125; &#125; // 为TransmittableThreadLocal设置当前线程对应的值 // 之前的值是其他线程设置的，读取不到，所以方法中对应的是用value的值进行再次赋值 setTtlValuesTo(captured); // 执行TransmittableThreadLocal的beforeExecute方法，一般为空方法，此处可以忽略 doExecuteCallback(true); return backup;&#125;private static void setTtlValuesTo(HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; ttlValues) &#123; for (Map.Entry&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; entry : ttlValues.entrySet()) &#123; TransmittableThreadLocal&lt;Object&gt; threadLocal = entry.getKey(); threadLocal.set(entry.getValue()); &#125;&#125; Transmitter.restore这个方法是在子线程/线程池中执行的，用于在业务逻辑处理完成后，将子线程之前的线程相关数据进行恢复，也即是进行使用后的清理恢复工作 12345678910111213141516171819202122232425262728293031public static void restore(@NonNull Object backup) &#123; final Snapshot backupSnapshot = (Snapshot) backup; restoreTtlValues(backupSnapshot.ttl2Value); restoreThreadLocalValues(backupSnapshot.threadLocal2Value);&#125;private static void restoreTtlValues(HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; backup) &#123; // 直接忽略：调用TransmittableThreadLocal.afterExecute方法，一般也是空方法 doExecuteCallback(false); // 遍历当前线程设置过的所有TransmittableThreadLocal信息 for (final Iterator&lt;TransmittableThreadLocal&lt;Object&gt;&gt; iterator = holder.get().keySet().iterator(); iterator.hasNext(); ) &#123; TransmittableThreadLocal&lt;Object&gt; threadLocal = iterator.next(); // 如果存在备份数据中不存在的TransmittableThreadLocal，则进行删除处理 if (!backup.containsKey(threadLocal)) &#123; iterator.remove(); threadLocal.superRemove(); &#125; &#125; // 重新设置值 setTtlValuesTo(backup);&#125;private static void setTtlValuesTo(@NonNull HashMap&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; ttlValues) &#123; // 重新为当前线程的TransmittableThreadLocal设置备份的值 for (Map.Entry&lt;TransmittableThreadLocal&lt;Object&gt;, Object&gt; entry : ttlValues.entrySet()) &#123; TransmittableThreadLocal&lt;Object&gt; threadLocal = entry.getKey(); threadLocal.set(entry.getValue()); &#125;&#125; 有了上面的这些类和方法进行支撑，TtlRunnable或者TtlExecutors等进行使用时就比较容易了，我们简单看一下 12345678910111213141516171819202122232425262728293031public final class TtlRunnable implements Runnable, TtlWrapper&lt;Runnable&gt;, TtlEnhanced, TtlAttachments &#123; private final AtomicReference&lt;Object&gt; capturedRef; private final Runnable runnable; private final boolean releaseTtlValueReferenceAfterRun; // 构造函数，记录保证runnable及主线程的中的数据快照，这里调用了Transmitter.capture（之前已经分析） private TtlRunnable(Runnable runnable, boolean releaseTtlValueReferenceAfterRun) &#123; this.capturedRef = new AtomicReference&lt;Object&gt;(capture()); this.runnable = runnable; this.releaseTtlValueReferenceAfterRun = releaseTtlValueReferenceAfterRun; &#125; // 这里就是标准的处理逻辑，在子线程中进行 replay, 执行业务逻辑，再restore @Override public void run() &#123; // 线程池/子线程中执行时，获取快照中的数据 final Object captured = capturedRef.get(); if (captured == null || releaseTtlValueReferenceAfterRun &amp;&amp; !capturedRef.compareAndSet(captured, null)) &#123; throw new IllegalStateException(\"TTL value reference is released after run!\"); &#125; // 重新设置快照中的数据到当前线程中，并创建当前线程的数据进行备份 final Object backup = replay(captured); try &#123; // 执行业务逻辑 runnable.run(); &#125; finally &#123; // 执行后将备份的数据恢复 restore(backup); &#125; &#125;&#125; 其中我们还可以发现一个点就是Transmitter除了处理TransmittableThreadLocal中的holder，还用同样的方法处理使用它的一个静态成员变量threadLocalHolder 12// threadLocalHolder 与 holder 一个不同点是，它不是一个InheritableThreadLocal实例private static volatile WeakHashMap&lt;ThreadLocal&lt;Object&gt;, TtlCopier&lt;Object&gt;&gt; threadLocalHolder = new WeakHashMap&lt;ThreadLocal&lt;Object&gt;, TtlCopier&lt;Object&gt;&gt;(); 这个threadLocalHolder的作用是对于在项目中使用了ThreadLocal，但是却无法替换为TransmittableThreadLocal的情况，可以使用Transmitter提供的注册方法，将项目中的threadLocal注册到它的threadLocalHolder中，后面进行capture等操作时holder和threadLocalHolder都会进行处理使用 123456// 使用注册代码Transmitter.registerThreadLocalWithShadowCopier(threadLocal);// 自己实现TtlCopierTransmitter.registerThreadLocal(threadLocal, copyLambda);// 不再使用后进行注销Transmitter.unregisterThreadLocal(threadLocal); 对应的部分源码： 12345678910111213141516171819public static &lt;T&gt; boolean registerThreadLocalWithShadowCopier(@NonNull ThreadLocal&lt;T&gt; threadLocal) &#123; return registerThreadLocal(threadLocal, (TtlCopier&lt;T&gt;) shadowCopier, false);&#125;public static &lt;T&gt; boolean registerThreadLocal(@NonNull ThreadLocal&lt;T&gt; threadLocal, @NonNull TtlCopier&lt;T&gt; copier, boolean force) &#123; if (threadLocal instanceof TransmittableThreadLocal) &#123; logger.warning(\"register a TransmittableThreadLocal instance, this is unnecessary!\"); return true; &#125; synchronized (threadLocalHolderUpdateLock) &#123; if (!force &amp;&amp; threadLocalHolder.containsKey(threadLocal)) return false; WeakHashMap&lt;ThreadLocal&lt;Object&gt;, TtlCopier&lt;Object&gt;&gt; newHolder = new WeakHashMap&lt;ThreadLocal&lt;Object&gt;, TtlCopier&lt;Object&gt;&gt;(threadLocalHolder); newHolder.put((ThreadLocal&lt;Object&gt;) threadLocal, (TtlCopier&lt;Object&gt;) copier); threadLocalHolder = newHolder; return true; &#125;&#125; 小结通过上面的分析，可以发现核心类其实就是两个：TransmittableThreadLocal 和 Transmitter 在使用 TransmittableThreadLocal 时，它在将值保存到父类 InheritableThreadLocal 中的同时，会将当前的 TransmittableThreadLocal 实际进行存储，这样使用完成后，它自己就会维护一份所有用到的TransmittableThreadLocal 实例，不管它是用户信息的，还是其他信息的实例 有了上面维护的信息，就可以借助Transmitter来对其中的数据进行操作，一般操作步骤如下 主线程：调用Transmitter.capture，将当前主线程中的所有TransmittableThreadLocal和值进行快照保存(Map结构，结果要作为value进行存储，否则其他线程取不到TransmittableThreadLocal的value值) 子线程：调用Transmitter.replay，用于将之前保存的所有TransmittableThreadLocal实例及其值重新设置一下（需要借助之前保存的map结构，因为TransmittableThreadLocal中的数据是线程隔离的），并将当前线程的所有TransmittableThreadLocal实例进行备份返回 子线程：业务代码执行完毕之后调用Transmitter.restore，用于将之前备份的数据进行恢复，原理同replay方法","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"Java编译时注解处理器","slug":"java-annotation-processor","date":"2021-06-06T14:15:37.000Z","updated":"2022-12-11T12:34:47.440Z","comments":true,"path":"2021/06/06/java-annotation-processor/","link":"","permalink":"https://zhengw-tech.com/2021/06/06/java-annotation-processor/","excerpt":"Java注解大家都了解，平时我们使用最多的就是在运行时也有效的注解：@Retention(RetentionPolicy.RUNTIME)，可以根据这类注解在运行时进行一些特殊的逻辑处理，如Spring中的AOP使用。但是除了这类在运行时存在的注解，还有两种会保留到源码@Retention(RetentionPolicy.SOURCE)和字节码@Retention(RetentionPolicy.CLASS)中的注解，这种注解有什么作用呢？ 这里介绍一种比较常见的用法-Java注解处理器(Java Annotation Process)，它可以在运行时获取注解信息，生成一些额外的文件信息，如我们常用的lombok或mapstruct都是使用这种技术","text":"Java注解大家都了解，平时我们使用最多的就是在运行时也有效的注解：@Retention(RetentionPolicy.RUNTIME)，可以根据这类注解在运行时进行一些特殊的逻辑处理，如Spring中的AOP使用。但是除了这类在运行时存在的注解，还有两种会保留到源码@Retention(RetentionPolicy.SOURCE)和字节码@Retention(RetentionPolicy.CLASS)中的注解，这种注解有什么作用呢？ 这里介绍一种比较常见的用法-Java注解处理器(Java Annotation Process)，它可以在运行时获取注解信息，生成一些额外的文件信息，如我们常用的lombok或mapstruct都是使用这种技术 下面我们通过一个非常简单的例子来介绍一个它的用法：给前端提供接口时，后端在编写接口文档时，经常会需要将一个类的结构转成json结构并添加注解后提供给前端，这里我们通过注解，在编译时生成类的结构信息 定义注解首先创建一个定义注解的模板，我们定义如下两个注解 123456// 用于类上面的描述使用@Target(ElementType.TYPE)@Retention(RetentionPolicy.CLASS)public @interface ClassDoc &#123; String desc() default \"\";&#125; 123456// 用于属性上面的描述使用@Target(ElementType.FIELD)@Retention(RetentionPolicy.CLASS)public @interface FieldDoc &#123; String desc() default \"\";&#125; 创建注解处理器创建用于根据注解生成文档的注解处理器，因为Processor需要SPI方式声明，即在META-INFO/services路径下创建文件（javax.annotation.processing.Processor）并在其中声明对应的实现com.github.zavier.processor.DocProcessor 这里我们使用google的 auto-service来简化声明流程 12345&lt;dependency&gt; &lt;groupId&gt;com.google.auto.service&lt;/groupId&gt; &lt;artifactId&gt;auto-service&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// === 这个功能现在比较简陋，主要为了说明注解处理的使用，目前只支持最简单的属性解析，暂不支持集合及嵌套等结构 ===// 声明需要支持的注解类全名称@SupportedAnnotationTypes(&#123;\"com.github.zavier.annotation.ClassDoc\"&#125;)// 声明支持的版本@SupportedSourceVersion(SourceVersion.RELEASE_8)// 使用 autoService来声明处理器@AutoService(Processor.class)public class DocProcessor extends AbstractProcessor &#123; private final ConcurrentHashMap&lt;String, List&lt;FieldDocInfo&gt;&gt; typeDocMap = new ConcurrentHashMap&lt;&gt;(); @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) &#123; try &#123; // 是否是处理最后一轮,最后一轮时才真正生成文档 if (roundEnv.processingOver()) &#123; StringBuilder sb = new StringBuilder(); typeDocMap.forEach((typeName, docInfoList) -&gt; &#123; sb.append(\"# \").append(typeName).append(\"\\r\\n\").append(\"&#123;\\r\\n\"); for (FieldDocInfo fieldDocInfo : docInfoList) &#123; sb.append(\" \").append(\"# \").append(fieldDocInfo.desc).append(\"\\r\\n\"); sb.append(\" \").append(fieldDocInfo.name).append(\": \").append(fieldDocInfo.type).append(\"\\r\\n\"); &#125; sb.append(\"&#125;\\r\\n\"); &#125;); // 创建文件，并写入结果 final FileObject resource = processingEnv.getFiler().createResource(StandardLocation.CLASS_OUTPUT, \"\", \"doc/doc.txt\"); try (OutputStream out = resource.openOutputStream()) &#123; BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(out, UTF_8)); writer.write(sb.toString()); writer.newLine(); writer.flush(); &#125; &#125; else &#123; // 获取有 ClassDoc 注解的元素 final Set&lt;? extends Element&gt; elements = roundEnv.getElementsAnnotatedWith(ClassDoc.class) .stream() .filter(TypeElement.class::isInstance) .collect(Collectors.toSet()); for (Element element : elements) &#123; final String typeElementName = element.getAnnotation(ClassDoc.class).desc(); // 获取有ClassDoc注解类内部的元素 final List&lt;FieldDocInfo&gt; collect = element.getEnclosedElements() .stream() .filter(VariableElement.class::isInstance) .map(VariableElement.class::cast) .map(ele -&gt; &#123; // 处理其中的属性信息 final String name = ele.getSimpleName().toString(); final String desc = ele.getAnnotation(FieldDoc.class).desc(); final TypeKind kind = ele.asType().getKind(); if (kind == TypeKind.DECLARED) &#123; // 如果属性为类的话，则获取对应类的简单名称 final TypeMirror typeMirror = ele.asType(); final DeclaredType mirror = (DeclaredType) typeMirror; TypeElement e = (TypeElement) (mirror).asElement(); final Name simpleName = e.getSimpleName(); return new FieldDocInfo(name, desc, simpleName.toString()); &#125; else &#123; return new FieldDocInfo(name, desc, kind.name()); &#125; &#125;).collect(Collectors.toList()); typeDocMap.put(typeElementName, collect); &#125; &#125; &#125; catch (IOException e) &#123; processingEnv.getMessager().printMessage(Diagnostic.Kind.ERROR, e.getMessage()); &#125; return false; &#125; static class FieldDocInfo &#123; private String name; private String desc; private String type; public FieldDocInfo() &#123; &#125; public FieldDocInfo(String name, String desc, String type) &#123; this.name = name; this.desc = desc; this.type = type; &#125; // 省略 getter setter方法 &#125;&#125; 下面来看下使用方式 123456789@ClassDoc(desc = \"用户\")public class User &#123; @FieldDoc(desc = \"姓名\") private String name; @FieldDoc(desc = \"年龄\") private Integer age;&#125; 引入处理器的包，编辑后即可在maven target目录下找到生成的文档文件 项目Demo地址：https://github.com/zavier/annotation-processor 参考资料https://www.baeldung.com/java-annotation-processing-builder https://www.jianshu.com/p/5ca05317286e","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"一种动态添加外部Jar包中SpringBean的方式","slug":"dymantic-load-spring-bean","date":"2021-04-16T14:26:48.000Z","updated":"2023-05-27T15:05:49.085Z","comments":true,"path":"2021/04/16/dymantic-load-spring-bean/","link":"","permalink":"https://zhengw-tech.com/2021/04/16/dymantic-load-spring-bean/","excerpt":"我们在日常写代码的过程中，经常会有一个扩展点接口，同时会有多种实现，类似策略模式，在运行时动态获取具体的实现 如果想在不需要重新部署项目的情况下，新增一种扩展点的实现并且能够生效使用，有什么方式呢？ 先想个简单的例子来说明一下上面说的场景，比如价格计算 123interface PriceCalculater &#123; BigDecimal calc(GoodsDetail detail);&#125; 123456789101112131415@Servicepublic class DirectReducePriceCalculator implements PriceCalculater &#123; @Resource private ActivityService activityService; public BigDecimal calc(GoodsDetail goods) &#123; // 随便写的，只是为了稍微贴近一点实际~~~~ Activity activity = activityService.getDirectReductActivity(goods); if (activity != null) &#123; return detail.getPrice().subtract(activity.getReducePrice()); &#125; return detail.getPrice(); &#125;&#125; 并且有一个对应的工厂类，用于获取对应的计算器","text":"我们在日常写代码的过程中，经常会有一个扩展点接口，同时会有多种实现，类似策略模式，在运行时动态获取具体的实现 如果想在不需要重新部署项目的情况下，新增一种扩展点的实现并且能够生效使用，有什么方式呢？ 先想个简单的例子来说明一下上面说的场景，比如价格计算 123interface PriceCalculater &#123; BigDecimal calc(GoodsDetail detail);&#125; 123456789101112131415@Servicepublic class DirectReducePriceCalculator implements PriceCalculater &#123; @Resource private ActivityService activityService; public BigDecimal calc(GoodsDetail goods) &#123; // 随便写的，只是为了稍微贴近一点实际~~~~ Activity activity = activityService.getDirectReductActivity(goods); if (activity != null) &#123; return detail.getPrice().subtract(activity.getReducePrice()); &#125; return detail.getPrice(); &#125;&#125; 并且有一个对应的工厂类，用于获取对应的计算器 1234567891011121314151617181920@Componentpublic class PriceCalculaterFactory implements ApplicationContextAware &#123; private ApplicationContext applicationContext; private Map&lt;String, PriceCalculater&gt; priceCalculaterMap; @PostConstruct public void init() &#123; priceCalculaterMap = applicationContext.getBeansOfType(PriceCalculater.class); &#125; public PriceCalculater getPriceCalculatorByName(String name) &#123; return priceCalculaterMap.get(name); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; 这时候，要添加或更新一个外部jar包中定义的bean（如新的某种计算策略）到当前应用要如何做呢？ 假设定义如下 1234567891011@Servicepublic class XyPriceCalculator implements PriceCalculater &#123; @Resource private ActivityService activityService; public BigDecimal calc(GoodsDetail goods) &#123; // TODO &#125;&#125; 首先能想到的是，因为可能更新，这样同名的类会无法加载，所以需要一个自定义的类加载器，我们来定义一个继承URLClassLoader的类加载器 1234567891011121314public class CustomizeClassLoader extends URLClassLoader &#123; public CustomizeClassLoader() &#123; super(new URL[0]); &#125; public void addFile(File file) &#123; try &#123; addURL(file.getCanonicalFile().toURI().toURL()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 加载外部jar包中定义的class 12CustomizeClassLoader classLoader = new CustomizeClassLoader();classLoader.addFile(new File(\"xx/yy/cc.jar\")); 接下来，我们要想办法初始化其中的bean，因为我们加载的只是一个class，还没有初始化为Spring容器中的bean 因为外部jar包中定义的类可能还需要依赖当前项目中的bean，所以一种可行的方式就是创建一个ApplicationContext，并将当前Spring的上下文设置为新创建的ApplicationContext的父上下文，这样当前上下文中找不到的bean会到父上下文中进行查找，可以顺利的添加依赖，完成bean的创建 但是这时候还有一个问题就是我们加载外部class用的是自定义的类加载器，而当前spring相关类都是由applicationClassLoader加载的，它无法读取自定义类加载器加载的class，这时候也有一种方式，就是spring读取class的时候默认优先是从线程上下文类加载器进行加载的，所以我们可以把自定义类加载器设置为当前线程的上下文类加载器即可 最后一步当然就是把创建好的bean添加到工厂中即可，总体代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041@Componentpublic class PriceCalculaterFactory implements ApplicationContextAware &#123; private ApplicationContext applicationContext; private Map&lt;String, PriceCalculater&gt; priceCalculaterMap; @PostConstruct public void init() &#123; priceCalculaterMap = applicationContext.getBeansOfType(PriceCalculater.class); &#125; public PriceCalculater getPriceCalculatorByName(String name) &#123; return priceCalculaterMap.get(name); &#125; public void refresh() &#123; // 1. 创建自定义类加载器，并加载外部jar包 CustomizeClassLoader classLoader = new CustomizeClassLoader(); classLoader.addFile(new File(\"xx/yy/cc.jar\")); // 2. 将自定义类加载器设置为当前线程上下文类加载器 Thread.currentThread().setContextClassLoader(classLoader); // 3. 创建ApplicationContext, 设置父上下文为当前应用上下文，同时使用自定义类加载器加载解析外部定义bean final AnnotationConfigWebApplicationContext newContext = new AnnotationConfigWebApplicationContext(); // 设置父上下文为当前应用上下文(用于查找外部定义的bean中依赖的当前应用中的bean) newContext.setParent(newContext); // 假设外部包中定义bean所在的类路径为xxx.yyy newContext.scan(\"xxx.yyy\"); // 读取解析并创建bean newContext.refresh(); // 4. 将创建的bean注册到工厂中(这里可以注意下，子上下文的getBeansOfType方法获取不到父上下文中的bean) Map&lt;String, PriceCalculater&gt; newMap = newContext.getBeansOfType(PriceCalculater.class); if (!newMap.isEmpty()) &#123; priceCalculaterMap.putAll(newMap); &#125; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; 上面只是一个简单的例子，抛砖引玉 对于之前提到的，Spring使用当前线程上下文类加载器加载类对应源码部分如下 123456789org.springframework.context.annotation.ClassPathBeanDefinitionScanner#scan|- org.springframework.context.annotation.ClassPathBeanDefinitionScanner#doScan |- ClassPathScanningCandidateComponentProvider#findCandidateComponents |- ClassPathScanningCandidateComponentProvider#scanCandidateComponentsResource[] resources = getResourcePatternResolver().getResources(packageSearchPath); |- ClassPathScanningCandidateComponentProvider#getResourcePatternResolver |- new PathMatchingResourcePatternResolver() |- new DefaultResourceLoader() |- ClassUtils.getDefaultClassLoader(); 12345678910111213141516171819202122232425// ClassUtils.javapublic static ClassLoader getDefaultClassLoader() &#123; ClassLoader cl = null; try &#123; // 优先使用了线程上下文类加载器进行类加载！！！ cl = Thread.currentThread().getContextClassLoader(); &#125; catch (Throwable ex) &#123; // Cannot access thread context ClassLoader - falling back... &#125; if (cl == null) &#123; // No thread context class loader -&gt; use class loader of this class. cl = ClassUtils.class.getClassLoader(); if (cl == null) &#123; // getClassLoader() returning null indicates the bootstrap ClassLoader try &#123; cl = ClassLoader.getSystemClassLoader(); &#125; catch (Throwable ex) &#123; // Cannot access system ClassLoader - oh well, maybe the caller can live with null... &#125; &#125; &#125; return cl;&#125; 如果有错误的地方，或者大家有更好的方案，欢迎提出指正，谢谢","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"}]},{"title":"SpringMVC自定义参数解析","slug":"spring-customize-argument-resolver","date":"2021-02-01T15:18:45.000Z","updated":"2021-04-17T14:50:06.969Z","comments":true,"path":"2021/02/01/spring-customize-argument-resolver/","link":"","permalink":"https://zhengw-tech.com/2021/02/01/spring-customize-argument-resolver/","excerpt":"我们日常开发过程中，入参出参基本都是与后端对应的类结构完全一致，SpringMVC自动帮我们处理了参数转换的过程，GET 和 POST 的几种常见传参方式如下123456789101112131415161718192021222324// HTTP请求参数名需要与属性名userName相同@GetMapping(\"/listUser\")public List&lt;User&gt; listUser(String userName) &#123; return new ArrayList&lt;&gt;();&#125;@GetMapping(\"/listUser\")// HTTP请求参数名需要与注解中的名称username相同相同public List&lt;User&gt; listUser1(@RequestParam(\"username\") String userName) &#123; return new ArrayList&lt;&gt;();&#125;@GetMapping(\"/listUser\")// 参数太多则可以使用类接收，url中的参数会自动转化赋值到SearchUserParam类中的同名属性上public List&lt;User&gt; listUser2(SearchUserParam searchUserParam) &#123; return new ArrayList&lt;&gt;();&#125;// POST方式基本同上，post body中的json串会被反序列化到对应的参数user类@PostMapping(\"/save\")public Long save(@RequestBody User user) &#123; return 1L;&#125; 上面的几种用法基本能满足我们大部分的需求，但是仍有一些特殊情况无法满足","text":"我们日常开发过程中，入参出参基本都是与后端对应的类结构完全一致，SpringMVC自动帮我们处理了参数转换的过程，GET 和 POST 的几种常见传参方式如下123456789101112131415161718192021222324// HTTP请求参数名需要与属性名userName相同@GetMapping(\"/listUser\")public List&lt;User&gt; listUser(String userName) &#123; return new ArrayList&lt;&gt;();&#125;@GetMapping(\"/listUser\")// HTTP请求参数名需要与注解中的名称username相同相同public List&lt;User&gt; listUser1(@RequestParam(\"username\") String userName) &#123; return new ArrayList&lt;&gt;();&#125;@GetMapping(\"/listUser\")// 参数太多则可以使用类接收，url中的参数会自动转化赋值到SearchUserParam类中的同名属性上public List&lt;User&gt; listUser2(SearchUserParam searchUserParam) &#123; return new ArrayList&lt;&gt;();&#125;// POST方式基本同上，post body中的json串会被反序列化到对应的参数user类@PostMapping(\"/save\")public Long save(@RequestBody User user) &#123; return 1L;&#125; 上面的几种用法基本能满足我们大部分的需求，但是仍有一些特殊情况无法满足 使用先来看下GET方法，入参太多时我们会定义类，但是类中的属性必须是和参数名一致，也不能进行嵌套，不然就无法转换，比如下面这种定义 1234567public class SearchUserParam &#123; // 基本信息查询 private Integer age; private String name; // 假设我们能支持动态的一些属性查询支持，但是又不想每次专门修改结构，所以定义一个扩展的map private Map&lt;String, String&gt; ext;&#125; 对于上面的扩展参数，如果有一天我们需要支持根据地区进行查询，对于HTTP GET请求中的此次增加的入参如regionId=100这种情况，后端就会接收不到这个参数 一种解决方法当然是我们可以通过修改类结构增加参数来处理，这里主要来说说如果不修改类结构我们如何处理这种情况 这里就需要用到 SpringMVC 提供的 HandlerMethodArgumentResolver 类，所有的参数处理都是这个接口的实现，我们可以利用它来自定义我们的参数解析实现，如 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class SearchUserHandlerMethodArgumentResolver implements HandlerMethodArgumentResolver &#123; private Set&lt;String&gt; supportParams = new HashSet&lt;&gt;(); @PostConstruct public void init() &#123; supportParams.add(\"name\"); supportParams.add(\"age\"); &#125; // 设置支持解析的参数类型 @Override public boolean supportsParameter(MethodParameter parameter) &#123; return parameter.getParameterType() == SearchUserParam.class; &#125; // 进行http请求参数的解析转换 @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(); Iterator&lt;String&gt; parameterNames = webRequest.getParameterNames(); Map&lt;String, Object&gt; extMap = new HashMap&lt;&gt;(); while (parameterNames.hasNext()) &#123; String paramName = parameterNames.next(); if (supportParams.contains(paramName)) &#123; result.put(paramName, webRequest.getParameter(paramName)); &#125; else &#123; extMap.put(paramName, webRequest.getParameter(paramName)); &#125; &#125; result.put(\"ext\", extMap); return JSON.parseObject(result, SearchUserParam.class); &#125;&#125; Spring中的 PageableHandlerMethodArgumentResolver 也是利用了这个原理，会将请求参数中的分页参数填充到请求参数接收类 Pageable 中，如： 123public Page&lt;User&gt; pageUsers(Pageable pageable, QueryUser query) &#123; // 注册了 PageableHandlerMethodArgumentResolver 后， 请求url中的page、size参数会自动填充到 pageable 对应的实例中&#125; 我们可以利用这个特性在接收参数中定义一些需要用到的类，然后通过参数解析器进行添加，如用户信息等 上面说的是对于 GET 请求，接下来看下 POST 请求的处理，POST请求我们一般都是使用 json 这种格式作为入参和出参，而 SpringMVC 默认使用 jackson 进行响应的序列化和反序列化 所以 POST 请求的处理我们直接借助于 jackson 提供的方法即可，通过实现 JsonSerializer 或 JsonDeserializer 来实现对应属性的序列化与反序列化，在借由 SpringMVC 提供的 @JsonComponent 注解等方式进行设置即可，下面举一个简单的例子 1234567891011121314151617181920212223242526@JsonComponentpublic class UserCodec &#123; public static class UserSerializer extends JsonSerializer&lt;User&gt; &#123; @Override public void serialize(User user, JsonGenerator gen, SerializerProvider serializers) throws IOException &#123; gen.writeStartObject(); gen.writeStringField(\"user-name\", user.getName()); gen.writeNumberField(\"user-age\", user.getAge()); gen.writeEndObject(); &#125; &#125; public static class UserDeserializer extends JsonDeserializer&lt;User&gt; &#123; @Override public User deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException &#123; JsonNode node = p.getCodec().readTree(p); User user = new User(); user.setName(node.get(\"user-name\").asText()); IntNode ageNode = (IntNode) node.get(\"user-age\"); user.setAge(ageNode.intValue()); return user; &#125; &#125;&#125; 之后在对应类上面添加注解1234567@Data@JsonSerialize(using = UserSerializer.class)@JsonDeserialize(using = UserDeserializer.class)public class User &#123; private String name; private Integer age;&#125; 这样就实现了自定义的序列化与反序列化，当然我们也可以根据自己的实际需求实现更复杂的转换 原理这个参数解析的原理比较简单，主要就是有一个参数解析器链，以类似责任链的方式进行处理，哪个解析器能处理就进行对应的处理，下面我们具体看下 SpringMVC主要依靠 HandlerMapping 和 HandlerAdapter 来实现路由到方法的映射和方法调用的实现, HandlerMapping 用来处理请求和 Controller 中的方法映射关系及匹配，而 HandlerAdapter 则是用来在匹配到方法后进行实际的方法调用，包括其中的参数处理(使用 HandlerMethodArgumentResolver)这里我们主要看下最常用的 RequestMappingHandlerAdapter的处理过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; // 初始化过程中会注册所有的参数解析器 @Override public void afterPropertiesSet() &#123; initControllerAdviceCache(); if (this.argumentResolvers == null) &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultArgumentResolvers(); this.argumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.initBinderArgumentResolvers == null) &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultInitBinderArgumentResolvers(); this.initBinderArgumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.returnValueHandlers == null) &#123; List&lt;HandlerMethodReturnValueHandler&gt; handlers = getDefaultReturnValueHandlers(); this.returnValueHandlers = new HandlerMethodReturnValueHandlerComposite().addHandlers(handlers); &#125; &#125; // 获取参数解析器 private List&lt;HandlerMethodArgumentResolver&gt; getDefaultArgumentResolvers() &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = new ArrayList&lt;&gt;(30); // 基于参数注解的参数解析器 resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), false)); resolvers.add(new RequestParamMapMethodArgumentResolver()); resolvers.add(new PathVariableMethodArgumentResolver()); resolvers.add(new PathVariableMapMethodArgumentResolver()); resolvers.add(new MatrixVariableMethodArgumentResolver()); resolvers.add(new MatrixVariableMapMethodArgumentResolver()); resolvers.add(new ServletModelAttributeMethodProcessor(false)); resolvers.add(new RequestResponseBodyMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestPartMethodArgumentResolver(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestHeaderMethodArgumentResolver(getBeanFactory())); resolvers.add(new RequestHeaderMapMethodArgumentResolver()); resolvers.add(new ServletCookieValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new ExpressionValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new SessionAttributeMethodArgumentResolver()); resolvers.add(new RequestAttributeMethodArgumentResolver()); // 基于参数类型的参数解析器 resolvers.add(new ServletRequestMethodArgumentResolver()); resolvers.add(new ServletResponseMethodArgumentResolver()); resolvers.add(new HttpEntityMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RedirectAttributesMethodArgumentResolver()); resolvers.add(new ModelMethodProcessor()); resolvers.add(new MapMethodProcessor()); resolvers.add(new ErrorsMethodArgumentResolver()); resolvers.add(new SessionStatusMethodArgumentResolver()); resolvers.add(new UriComponentsBuilderMethodArgumentResolver()); if (KotlinDetector.isKotlinPresent()) &#123; resolvers.add(new ContinuationHandlerMethodArgumentResolver()); &#125; // 这里是我们自定义的参数解析器 if (getCustomArgumentResolvers() != null) &#123; resolvers.addAll(getCustomArgumentResolvers()); &#125; // Catch-all 其他的参数解析器 resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), true)); resolvers.add(new ServletModelAttributeMethodProcessor(true)); return resolvers; &#125;&#125; 上面主要是一些初始化注册的逻辑，接下来看一下实际调用过程的处理 1234567891011121314151617181920212223// RequestMappingHandlerAdapter.java （代码进行了简化）protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &#123; // 1. 创建调用方法 ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); // 2. 实际调用方法 invocableMethod.invokeAndHandle(webRequest, mavContainer); return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125;&#125;protected ServletInvocableHandlerMethod createInvocableHandlerMethod(HandlerMethod handlerMethod) &#123; // 创建调用方法 return new ServletInvocableHandlerMethod(handlerMethod);&#125; 调用方法处理在 ServletInvocableHandlerMethod 的父类 InvocableHandlerMethod 中1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class InvocableHandlerMethod extends HandlerMethod &#123; // resolvers中是参数解析器的组合，具体后面看下 private HandlerMethodArgumentResolverComposite resolvers = new HandlerMethodArgumentResolverComposite(); public Object invokeForRequest(NativeWebRequest request, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; // 将请求中的参数转换为方法调用的参数 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &#123; logger.trace(\"Arguments: \" + Arrays.toString(args)); &#125; // 调用实际方法 return doInvoke(args); &#125; protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; MethodParameter[] parameters = getMethodParameters(); if (ObjectUtils.isEmpty(parameters)) &#123; return EMPTY_ARGS; &#125; Object[] args = new Object[parameters.length]; for (int i = 0; i &lt; parameters.length; i++) &#123; MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); args[i] = findProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; // 1. 判断参数解析器中是否有支持此参数的解析 if (!this.resolvers.supportsParameter(parameter)) &#123; throw new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\")); &#125; try &#123; // 2. 找到后调用对应解析器进行参数处理 args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); &#125; catch (Exception ex) &#123; throw ex; &#125; &#125; return args; &#125; protected Object doInvoke(Object... args) throws Exception &#123; Method method = getBridgedMethod(); ReflectionUtils.makeAccessible(method); try &#123; if (KotlinDetector.isSuspendingFunction(method)) &#123; return CoroutinesUtils.invokeSuspendingFunction(method, getBean(), args); &#125; // 反射调用方法 return method.invoke(getBean(), args); &#125; catch (IllegalArgumentException ex) &#123; // 先忽略异常处理等 &#125; &#125;&#125; 最后看下上面resolvers(HandlerMethodArgumentResolverComposite)中的处理，在GET方法中我们写的自定义参数解析器也是在这里进行处理的1234567891011121314151617181920212223242526272829303132333435public class HandlerMethodArgumentResolverComposite implements HandlerMethodArgumentResolver &#123; // 之前注册的参数解析器集合 private final List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers = new ArrayList&lt;&gt;(); @Override public boolean supportsParameter(MethodParameter parameter) &#123; return getArgumentResolver(parameter) != null; &#125; public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); if (resolver == null) &#123; throw new IllegalArgumentException(\"Unsupported parameter type [\" + parameter.getParameterType().getName() + \"]. supportsParameter should be called first.\"); &#125; return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory); &#125; // 遍历解析器集合，查询匹配的进行返回处理 private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) &#123; HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter); if (result == null) &#123; for (HandlerMethodArgumentResolver resolver : this.argumentResolvers) &#123; // 如果支持对此参数类型进行解析，则返回这个解析器 if (resolver.supportsParameter(parameter)) &#123; result = resolver; this.argumentResolverCache.put(parameter, result); break; &#125; &#125; &#125; return result; &#125;&#125; 关于SpringMVC中自定义参数的转换内容基本就是这些，如有错误欢迎指正","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"}]},{"title":"状态机简介","slug":"statemachine","date":"2020-11-29T12:20:32.000Z","updated":"2021-04-17T14:50:06.969Z","comments":true,"path":"2020/11/29/statemachine/","link":"","permalink":"https://zhengw-tech.com/2020/11/29/statemachine/","excerpt":"之前通过《状态模式》介绍了一下状态模式的使用，这次我们来介绍一下有限状态机 维基百科中是这样定义的：有限状态机(FSM)又称有限状态自动机(FSA)，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型，在任何给定时间都可以恰好处于有限数量的状态之一 其实状态模式也可以算是状态机的一种实现，除了状态模式，还有一种实现方式就是创建一个描绘迁移的数据表，该表被一个处理事件的处理引擎解释。引擎查找与事件匹配的迁移，调用响应的动作并更改状态，这样状态机的逻辑全部集中在了一个地方 所以表驱动的状态机和状态模式的主要区别就是：状态模式对于状态相关的行为进行建模，而表驱动的方法着重于定义状态转换","text":"之前通过《状态模式》介绍了一下状态模式的使用，这次我们来介绍一下有限状态机 维基百科中是这样定义的：有限状态机(FSM)又称有限状态自动机(FSA)，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型，在任何给定时间都可以恰好处于有限数量的状态之一 其实状态模式也可以算是状态机的一种实现，除了状态模式，还有一种实现方式就是创建一个描绘迁移的数据表，该表被一个处理事件的处理引擎解释。引擎查找与事件匹配的迁移，调用响应的动作并更改状态，这样状态机的逻辑全部集中在了一个地方 所以表驱动的状态机和状态模式的主要区别就是：状态模式对于状态相关的行为进行建模，而表驱动的方法着重于定义状态转换 这里我们介绍一下表驱动的状态机实现，虽然这方式叫基于表驱动的状态机，但是这个表不是说特指我们平时用的数据库的表，而是一种关系的记录 现在已经有了很多成熟开源的状态机可以使用，如 Spring Statemachine、Squirrel Statemachine和stateless4j，平时工作如果需要，直接使用就好而不需要自己再开发，这次就以最轻量级的 stateless4j 为例来介绍一下状态机的使用 还是使用《敏捷软件开发：原则、模式与实践（C#版）》中的闸机例子 具体代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// &lt;dependency&gt;// &lt;groupId&gt;com.github.stateless4j&lt;/groupId&gt;// &lt;artifactId&gt;stateless4j&lt;/artifactId&gt;// &lt;version&gt;2.6.0&lt;/version&gt;// &lt;/dependency&gt;StateMachineConfig&lt;State, Trigger&gt; phoneCallConfig = new StateMachineConfig&lt;&gt;();// 配置状态机在关门状态下，对于不同事件触发的状态变化及行为phoneCallConfig.configure(State.LOCKED) // 投币则状态变为打开状态，并且进行开门操作 .permit(Trigger.COIN, State.UNLOCKED, () -&gt; &#123; System.out.println(\"opening...\"); &#125;) // 关门状态下通过，则状态不变，且触发警报行为 .permitInternal(Trigger.PASS, () -&gt; &#123; // alarm System.out.println(\"alarming...\"); &#125;);phoneCallConfig.configure(State.UNLOCKED) // 开门状态下，通过则状态改为关门状态，并且触发关门动作 .permit(Trigger.PASS, State.LOCKED, () -&gt; &#123; System.out.println(\"locking...\"); &#125;) // 开门状态下，投币状态不变，且触发致谢行为 .permitInternal(Trigger.COIN, () -&gt; &#123; // thank you System.out.println(\"thank you...\"); &#125;);StateMachine&lt;State, Trigger&gt; turnStileSm = new StateMachine&lt;&gt;(State.LOCKED, phoneCallConfig);// 投币开门turnStileSm.fire(Trigger.COIN);Assert.assertEquals(State.UNLOCKED, turnStileSm.getState());// 开门投币-致谢turnStileSm.fire(Trigger.COIN);Assert.assertEquals(State.UNLOCKED, turnStileSm.getState());// 通过关门turnStileSm.fire(Trigger.PASS);Assert.assertEquals(State.LOCKED, turnStileSm.getState());// 关门通过-报警turnStileSm.fire(Trigger.PASS);Assert.assertEquals(State.LOCKED, turnStileSm.getState()); 当然，这里只是展示了一下简单的用法，具体有兴趣的可以去了解一下对应状态机提供的API 状态机可以应用的地方还有很多，如 TCP协议中，在连接的不同状态（建立连接、监听中、关闭），对于发送等行为处理逻辑不同 一些画图类工具，用户选择了如画矩形、画圆形等按钮，则触发状态转换，此时拖动数据会触发画图的不同画圆或者画矩形等行为 用户界面，对于哪些按钮是激活态，哪些按钮置灰不可用，则可以通过状态来进行控制，不同状态下的展示效果不同 参考资料 《设计模式-可复用面向对象软件的基础》 《敏捷软件开发：原则、模式与实践（C#版）》","categories":[],"tags":[{"name":"状态机","slug":"状态机","permalink":"https://zhengw-tech.com/tags/状态机/"}]},{"title":"单元测试之Mock","slug":"unit-test-mock","date":"2020-10-29T13:05:01.000Z","updated":"2021-04-17T14:50:06.970Z","comments":true,"path":"2020/10/29/unit-test-mock/","link":"","permalink":"https://zhengw-tech.com/2020/10/29/unit-test-mock/","excerpt":"单元测试是对我们写的代码的最小单元进行测试，一般来说就是对函数(方法)进行测试，大家都知道写单元测试的好处，但是具体要怎么写呢？被测试的类可能依赖外部的类或服务，这个依赖的外部接口如何Mock，依赖注入的类如何替换成自己Mock的类等等，下面就介绍一种常用的Mock方式","text":"单元测试是对我们写的代码的最小单元进行测试，一般来说就是对函数(方法)进行测试，大家都知道写单元测试的好处，但是具体要怎么写呢？被测试的类可能依赖外部的类或服务，这个依赖的外部接口如何Mock，依赖注入的类如何替换成自己Mock的类等等，下面就介绍一种常用的Mock方式 首先，既然是单元测试，那么要做的第一件事就是屏蔽掉对外部的依赖，不让它们对我们要测试的方法产生影响。屏蔽的方式一般就是通过Mock，这里简单介绍一种Mock框架 Mockito 首先需要引入对应的依赖，如果使用Maven则需要在pom.xml中添加如下内容 123456&lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-all&lt;/artifactId&gt; &lt;version&gt;1.10.19&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 创建测试类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class UserTest &#123; @Test public void test() &#123; // 创建Mock对象 final UserService mockUserService = Mockito.mock(UserService.class); // 设置mock对象的行为 final User user = new User(); user.setName(\"Test\"); Mockito.when(mockUserService.getUser(Mockito.anyInt())).thenReturn(user); Assert.assertEquals(\"Test\", mockUserService.getUser(1).getName()); &#125;&#125;// 创建Mock对象也可以使用注解的方式public class UserTest &#123; @Mock private UserService mockUserService; @Before public void init() &#123; MockitoAnnotations.initMocks(this); &#125; @Test public void test() &#123; final User user = new User(); user.setName(\"Test\"); Mockito.when(mockUserService.getUser(Mockito.anyInt())).thenReturn(user); Assert.assertEquals(\"Test\", mockUserService.getUser(1).getName()); &#125;&#125;// 或者这样写，都是可以的，如果需要调用真实对象，将Mock改为Spy，去掉when..then逻辑即可@RunWith(MockitoJUnitRunner.class)public class UserTest &#123; @Mock private UserService mockUserService; @Test public void test() &#123; final User user = new User(); user.setName(\"Test\"); Mockito.when(mockUserService.getUser(Mockito.anyInt())).thenReturn(user); Assert.assertEquals(\"Test\", mockUserService.getUser(1).getName()); &#125;&#125; Mock了依赖的对象后，接下来就是将依赖的类替换成这个Mock类，一般我们项目都会使用Spring，如果是通过构造器注入或者Setter注入的方式的话，可以直接将Mock对象传递进去即可，如果使用了@Autowired 或者 @Resource注解方式来进行注入的话，则可以使用@InjectMocks注解来将依赖对应设置进去 123456789101112131415161718192021222324@RunWith(MockitoJUnitRunner.class)public class UserTest &#123; @InjectMocks private UserService userService; // 会自动注入到 UserService 中 @Mock private UserDao userDao; @Test public void test() &#123; final UserDao userDao = userService.getUserDao(); Assert.assertNotNull(userDao); &#125;&#125;public class UserService &#123; private UserDao userDao; public UserDao getUserDao() &#123; return userDao; &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"单元测试","slug":"单元测试","permalink":"https://zhengw-tech.com/tags/单元测试/"}]},{"title":"Flyway简介","slug":"flyway","date":"2020-10-01T16:31:10.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2020/10/02/flyway/","link":"","permalink":"https://zhengw-tech.com/2020/10/02/flyway/","excerpt":"平时我们写代码一般使用Git等工具来进行版本管理，而Flyway可以理解为是用来进行数据库的版本管理的，它的功能是比较强大的，可以帮忙我们自动执行SQL，确保各个环境(开发、测试等)数据表的同步等，详细内容可以参考文档，这里简单介绍一下常用的使用方法 基本maven使用引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.flywaydb&lt;/groupId&gt; &lt;artifactId&gt;flyway-core&lt;/artifactId&gt; &lt;version&gt;7.0.0&lt;/version&gt;&lt;/dependency&gt; 创建SQL脚本并执行在src/resources下创建 db/migration目录，在其中创建对应的SQL文件，其中又分为不同的文件类型，基于约定由于配置的原则，通过文件命名方式进行区分 版本迁移以V开头，只会执行一次；回退迁移以U开头，一般不使用；可重复执行迁移以R开头，每次修改后都会重新执行","text":"平时我们写代码一般使用Git等工具来进行版本管理，而Flyway可以理解为是用来进行数据库的版本管理的，它的功能是比较强大的，可以帮忙我们自动执行SQL，确保各个环境(开发、测试等)数据表的同步等，详细内容可以参考文档，这里简单介绍一下常用的使用方法 基本maven使用引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.flywaydb&lt;/groupId&gt; &lt;artifactId&gt;flyway-core&lt;/artifactId&gt; &lt;version&gt;7.0.0&lt;/version&gt;&lt;/dependency&gt; 创建SQL脚本并执行在src/resources下创建 db/migration目录，在其中创建对应的SQL文件，其中又分为不同的文件类型，基于约定由于配置的原则，通过文件命名方式进行区分 版本迁移以V开头，只会执行一次；回退迁移以U开头，一般不使用；可重复执行迁移以R开头，每次修改后都会重新执行 版本迁移类型 在db/migration目录下创建版本迁移文件 V1__CreateUser.sql 12345create table user ( id bigint not null auto_increment, name varchar(50) not null, primary key (id)) 以Java API方式调用执行 123456public static void main(String[] args) &#123; final Flyway flyway = Flyway.configure() .dataSource(\"jdbc:mysql://localhost:3306/test\", \"user\", \"password\") .load(); flyway.migrate();&#125; 执行后会发现，之前空的库里面多了两张表（SQL已经执行） 12345678mysql&gt; show tables;+-----------------------+| Tables_in_test |+-----------------------+| flyway_schema_history | // 用来记录数据库的各个版本信息| user | // 创建的用户表+-----------------------+2 rows in set (0.00 sec) 如果启动时没有flyway_schema_history(默认表名)表，则会初始创建一个 多次执行会发现，只有第一次会执行 V1__CreateUser.sql，后面就不会再次执行了 可重复执行迁移类型 在db/migration目录下创建版本迁移文件 R__AddUser.sql 1insert into user (name) values (\"test\"); 执行后发现user表中多了一条记录，再次执行也是只有一条记录，只有当我们修改内容后才会再次执行 这时我们修改文件内容为 1insert into user (name) values (\"test1\"); 再次执行代码发现SQL会再次执行 1234567mysql&gt; select * from user;+----+-------+| id | name |+----+-------+| 1 | test || 2 | test1 |+----+-------+ 这时我们来看下历史记录表，总共有三次执行记录 12345678mysql&gt; select * from flyway_schema_history;+----------------+---------+-------------+------+--------------------+------------+--------------+---------------------+----------------+---------+| installed_rank | version | description | type | script | checksum | installed_by | installed_on | execution_time | success |+----------------+---------+-------------+------+--------------------+------------+--------------+---------------------+----------------+---------+| 1 | 1 | CreateUser | SQL | V1__CreateUser.sql | -171442567 | root | 2020-10-01 23:54:35 | 23 | 1 || 2 | NULL | AddUser | SQL | R__AddUser.sql | 517863463 | root | 2020-10-02 00:15:06 | 10 | 1 || 3 | NULL | AddUser | SQL | R__AddUser.sql | -267384455 | root | 2020-10-02 00:15:47 | 11 | 1 |+----------------+---------+-------------+------+--------------------+------------+--------------+---------------------+----------------+---------+ Spring Boot使用在Spring Boot项目中引入flyway依赖后，在配置文件中进行对应的配置，如 12345678910111213141516# 开启spring.flyway.enabled=true# 禁止清理数据表spring.flyway.clean-disabled=true# 版本控制信息表名，默认 flyway_schema_historyspring.flyway.table=flyway_schema_history# 是否允许不按顺序迁移spring.flyway.out-of-order=false# 如果数据库不是空表，需要设置成 true，否则启动报错spring.flyway.baseline-on-migrate=true# 与 baseline-on-migrate: true 搭配使用，小于此版本的不执行spring.flyway.baseline-version=0# 使用的schemaspring.flyway.schemas=test# 执行迁移时是否自动调用验证spring.flyway.validate-on-migrate=true 之后配置对应的数据源信息，在项目启动时会自动根据情况执行对应的SQL 这个主要是因为spring-boot-autoconfigure包中包含对应的Flyway配置","categories":[],"tags":[{"name":"flyway","slug":"flyway","permalink":"https://zhengw-tech.com/tags/flyway/"}]},{"title":"Guava EventBus","slug":"guaua-eventbus","date":"2020-10-01T13:35:12.000Z","updated":"2023-06-21T00:22:52.299Z","comments":true,"path":"2020/10/01/guaua-eventbus/","link":"","permalink":"https://zhengw-tech.com/2020/10/01/guaua-eventbus/","excerpt":"在我们日常开发中经常有这种类型的场景： 新建用户后，需要进行一些操作，如发送优惠券等（和创建用户本身无关的操作） 数据变更时，对应的展示表格等信息需要进行对应的更新 即当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新 观察者模式（发布-订阅）就是这种情况下的一种解决方案，使用这种方式可以让解耦发布者和订阅者，互相不需要知道对方，之前一篇文档中简单介绍过Spring中的事件使用，这次介绍一种非Spring环境下Guava提供的EventBus的使用","text":"在我们日常开发中经常有这种类型的场景： 新建用户后，需要进行一些操作，如发送优惠券等（和创建用户本身无关的操作） 数据变更时，对应的展示表格等信息需要进行对应的更新 即当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新 观察者模式（发布-订阅）就是这种情况下的一种解决方案，使用这种方式可以让解耦发布者和订阅者，互相不需要知道对方，之前一篇文档中简单介绍过Spring中的事件使用，这次介绍一种非Spring环境下Guava提供的EventBus的使用 使用下面简单介绍一下EventBus的使用，使用起来其实是比较简单的，代码如下 创建事件类 1234// 一个简单的普通类public class UserCreateEvent &#123; // 定义需要的属性&#125; 定义监听者 12345678910111213141516171819// 定义一个发送短信通知的服务public class SendSmsService &#123; // 使用 @Subscribe 标识此方法用来处理事件消息 @Subscribe // 方法参数只能为1个，且为对应要处理的事件类 public void listen(UserCreateEvent event) &#123; // todo send sms System.out.println(this.getClass().getSimpleName() + \"-\" + event); &#125;&#125;// 定义一个发送优惠券的服务public class SendCouponService &#123; @Subscribe public void listen(UserCreateEvent event) &#123; // todo send coupon System.out.println(this.getClass().getSimpleName() + \"-\" + event); &#125;&#125; 初始化EventBus 1234// 初始化EventBus(异步处理需使用AsyncEventBus), 注册监听者EventBus eventBus = new EventBus();eventBus.register(new SendCouponService());eventBus.register(new SendSmsService()); 事件触发 12// 直接使用EventBus的post发送事件即可eventBus.post(new UserCreateEvent()); 原理使用其实挺简单的，下面我们可以想下它是怎么实现的 解析：首先在register注册监听者时解析对应监听类，获取@Subscribe注解方法及对应参数中的监听类信息 注册：需要维护一个注册表，记录被监听事件及对应的处理方法集合 派发执行：当调用EventBus发送事件时，可能根据同步或异步方式进行消息分发 解析注册 Guava的解析注册的类为SubscriberRegistry 12345678910111213141516171819202122232425262728293031323334// 总的维护的订阅信息表private final ConcurrentMap&lt;Class&lt;?&gt;, CopyOnWriteArraySet&lt;Subscriber&gt;&gt; subscribers = Maps.newConcurrentMap();void register(Object listener) &#123; // 获取监听者监听的事件类及对应的监听方法信息 Multimap&lt;Class&lt;?&gt;, Subscriber&gt; listenerMethods = findAllSubscribers(listener); for (Entry&lt;Class&lt;?&gt;, Collection&lt;Subscriber&gt;&gt; entry : listenerMethods.asMap().entrySet()) &#123; Class&lt;?&gt; eventType = entry.getKey(); Collection&lt;Subscriber&gt; eventMethodsInListener = entry.getValue(); // 使用CopyOnWriteArraySet在添加的同时可以不影响读（快照读） CopyOnWriteArraySet&lt;Subscriber&gt; eventSubscribers = subscribers.get(eventType); if (eventSubscribers == null) &#123; CopyOnWriteArraySet&lt;Subscriber&gt; newSet = new CopyOnWriteArraySet&lt;&gt;(); eventSubscribers = MoreObjects.firstNonNull(subscribers.putIfAbsent(eventType, newSet), newSet); &#125; eventSubscribers.addAll(eventMethodsInListener); &#125;&#125;private Multimap&lt;Class&lt;?&gt;, Subscriber&gt; findAllSubscribers(Object listener) &#123; Multimap&lt;Class&lt;?&gt;, Subscriber&gt; methodsInListener = HashMultimap.create(); Class&lt;?&gt; clazz = listener.getClass(); // 获取 @Subscribe注解的所有方法 for (Method method : getAnnotatedMethods(clazz)) &#123; // 第一个参数为监听的事件 Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); Class&lt;?&gt; eventType = parameterTypes[0]; // 记录事件的监听者信息，包括实例类及对应的方法（后面可以反射调用） methodsInListener.put(eventType, Subscriber.create(bus, listener, method)); &#125; return methodsInListener;&#125; 消息派发 1234567891011public void post(Object event) &#123; // 获取事件的所有订阅者 Iterator&lt;Subscriber&gt; eventSubscribers = subscribers.getSubscribers(event); if (eventSubscribers.hasNext()) &#123; // 消息派发 dispatcher.dispatch(event, eventSubscribers); &#125; else if (!(event instanceof DeadEvent)) &#123; // 没有订阅者时发送DeadEvent事件 post(new DeadEvent(this, event)); &#125;&#125; 消息派发目前提供了三种实现 PerThreadQueuedDispatcher 每个线程一个队列派发 LegacyAsyncDispatcher 异步派发使用 ImmediateDispatcher 立即派发(无队列) 下面依次看下 123456789101112131415161718192021222324252627282930313233343536373839404142434445// PerThreadQueuedDispatcher（同步EventBus默认使用）// 同步使用时不同线程发送事件处理不会互相影响private static final class PerThreadQueuedDispatcher extends Dispatcher &#123; // 使用ThreadLocal，一个线程一个队列 private final ThreadLocal&lt;Queue&lt;Event&gt;&gt; queue = new ThreadLocal&lt;Queue&lt;Event&gt;&gt;() &#123; @Override protected Queue&lt;Event&gt; initialValue() &#123; return Queues.newArrayDeque(); &#125; &#125;; private final ThreadLocal&lt;Boolean&gt; dispatching = new ThreadLocal&lt;Boolean&gt;() &#123; @Override protected Boolean initialValue() &#123; return false; &#125; &#125;; @Override void dispatch(Object event, Iterator&lt;Subscriber&gt; subscribers) &#123; // 先获取当前线程的队列 Queue&lt;Event&gt; queueForThread = queue.get(); // 将每个事件和所有的订阅者作为一个节点入队 queueForThread.offer(new Event(event, subscribers)); if (!dispatching.get()) &#123; dispatching.set(true); try &#123; Event nextEvent; while ((nextEvent = queueForThread.poll()) != null) &#123; while (nextEvent.subscribers.hasNext()) &#123; // 派发事件消息 nextEvent.subscribers.next().dispatchEvent(nextEvent.event); &#125; &#125; &#125; finally &#123; dispatching.remove(); queue.remove(); &#125; &#125; &#125; &#125; 1234567891011121314151617181920// LegacyAsyncDispatcher(异步AsyncEventBus默认使用)private static final class LegacyAsyncDispatcher extends Dispatcher &#123; // 全局队列 private final ConcurrentLinkedQueue&lt;Dispatcher.LegacyAsyncDispatcher.EventWithSubscriber&gt; queue = Queues.newConcurrentLinkedQueue(); @Override void dispatch(Object event, Iterator&lt;Subscriber&gt; subscribers) &#123; while (subscribers.hasNext()) &#123; // 一个事件和一个订阅者作为一个节点入队 queue.add(new Dispatcher.LegacyAsyncDispatcher.EventWithSubscriber(event, subscribers.next())); &#125; Dispatcher.LegacyAsyncDispatcher.EventWithSubscriber e; while ((e = queue.poll()) != null) &#123; e.subscriber.dispatchEvent(e.event); &#125; &#125; &#125; 123456789101112// ImmediateDispatcherprivate static final class ImmediateDispatcher extends Dispatcher &#123; private static final ImmediateDispatcher INSTANCE = new ImmediateDispatcher(); @Override void dispatch(Object event, Iterator&lt;Subscriber&gt; subscribers) &#123; checkNotNull(event); while (subscribers.hasNext()) &#123; subscribers.next().dispatchEvent(event); &#125; &#125;&#125; 最后我们看下dispatchEvent方法 12345678910111213141516171819202122232425final void dispatchEvent(final Object event) &#123; // 同步和异步在构造时使用不同的executor executor.execute( new Runnable() &#123; @Override public void run() &#123; try &#123; invokeSubscriberMethod(event); &#125; catch (InvocationTargetException e) &#123; bus.handleSubscriberException(e.getCause(), context(event)); &#125; &#125; &#125;);&#125;// 同步Executor实现如下enum DirectExecutor implements Executor &#123; INSTANCE; @Override public void execute(Runnable command) &#123; // 同步调用 command.run(); &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"guava","slug":"guava","permalink":"https://zhengw-tech.com/tags/guava/"},{"name":"eventbus","slug":"eventbus","permalink":"https://zhengw-tech.com/tags/eventbus/"}]},{"title":"记一次调用HTTPS接口证书问题排查","slug":"https-problem-record","date":"2020-06-30T09:59:35.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2020/06/30/https-problem-record/","link":"","permalink":"https://zhengw-tech.com/2020/06/30/https-problem-record/","excerpt":"问题发现系统调用HTTPS接口时出现异常，异常信息如下 123javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:unable to find valid certification path to requested target 排查怀疑1： 接口提供方的证书过期了？（其实仔细看日志的话就可以排除这个可能） 操作： 通过本地浏览器打开对应url，浏览器显示正常的安全信息，证书也未过期，oracle的证书样例如下(例子中的根证书颁发机构为 DigiCert Global Root CA )，这时可以排除证书问题","text":"问题发现系统调用HTTPS接口时出现异常，异常信息如下 123javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:unable to find valid certification path to requested target 排查怀疑1： 接口提供方的证书过期了？（其实仔细看日志的话就可以排除这个可能） 操作： 通过本地浏览器打开对应url，浏览器显示正常的安全信息，证书也未过期，oracle的证书样例如下(例子中的根证书颁发机构为 DigiCert Global Root CA )，这时可以排除证书问题 怀疑2: 接口换了证书，服务器没有对应的根证书？ 操作： 通过浏览器访问，查询到接口提供方对应的根证书颁发机构为：DST Root CA X3 上网查询到 获取服务器（linux）所有根证书的命令 如下 1awk -v cmd=&apos;openssl x509 -noout -subject&apos; &apos;/BEGIN/&#123;close(cmd)&#125;;&#123;print | cmd&#125;&apos; &lt; /etc/ssl/certs/ca-bundle.crt 在服务器执行后，可以在其中找到对应的一行信息 1subject= /O=Digital Signature Trust Co./CN=DST Root CA X3 这时又可以证明服务器是有对应的根证书的，排除此可能 其实这时候有点没有头绪了，不知道如何继续，直到后来发现 JVM 读取的是它自己的证书而不是服务器的… 怀疑3： JVM的受信证书中没有对应的根证书？ 操作： 查询对应 jvm 默认的受信根证书列表 1keytool -keystore &quot;$JAVA_HOME/jre/lib/security/cacerts&quot; -storepass changeit -list -v 在其结果中查询无 DST Root CA X3 相关信息！ 至此找到了问题的原因，不过也挺奇怪的，服务器和我本地安装的都是 jdk1.8，但是我本地 jvm 中是有这个根证相关信息的 解决 使用keytool工具将导出的证书导入到jvm的受信证书中去，详细操作在stackoverflow 在Java代码中设置 信任任何证书（不安全） 1234567891011121314151617181920private void trustEveryone() &#123; try &#123; HttpsURLConnection.setDefaultHostnameVerifier(new HostnameVerifier()&#123; public boolean verify(String hostname, SSLSession session) &#123; return true; &#125;&#125;); SSLContext context = SSLContext.getInstance(\"TLS\"); context.init(null, new X509TrustManager[]&#123;new X509TrustManager()&#123; public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123;&#125; public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123;&#125; public X509Certificate[] getAcceptedIssuers() &#123; return new X509Certificate[0]; &#125;&#125;&#125;, new SecureRandom()); HttpsURLConnection.setDefaultSSLSocketFactory(context.getSocketFactory()); &#125; catch (Exception e) &#123; // should never happen e.printStackTrace(); &#125; &#125; 以上为排查的具体过程，如果有错误，欢迎大家告知补充，谢谢","categories":[],"tags":[{"name":"https","slug":"https","permalink":"https://zhengw-tech.com/tags/https/"}]},{"title":"Spring事务基本原理","slug":"spring-transaction","date":"2020-03-29T01:48:42.000Z","updated":"2022-02-07T05:08:05.704Z","comments":true,"path":"2020/03/29/spring-transaction/","link":"","permalink":"https://zhengw-tech.com/2020/03/29/spring-transaction/","excerpt":"本文主要对基于XML和基于注解配置声明式事务的执行过程进行介绍，因为Spring的事务是基于AOP的，所以最好了解一些AOP相关的基础内容，下面我们就开始进入正文 配置使用我们使用一个功能，首先就是需要配置，这里我们写一个基于Mybatis的配置，dataSource相关的配置都忽略，直接看事务相关的配置 123456&lt;!-- 声明使用的事务管理器 --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;constructor-arg ref=\"dataSource\" /&gt;&lt;/bean&gt;&lt;!-- 启用注解式声明事务 --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\" /&gt; 这样配置后，在对应的方法上添加@Transactional注解即可启用事务，非常方便 原理Spring的事务配置和使用是很简单的，但是我们一定不会满足于此，接下面我们就来分析一下上面这几行配置如何起到这么大的作用","text":"本文主要对基于XML和基于注解配置声明式事务的执行过程进行介绍，因为Spring的事务是基于AOP的，所以最好了解一些AOP相关的基础内容，下面我们就开始进入正文 配置使用我们使用一个功能，首先就是需要配置，这里我们写一个基于Mybatis的配置，dataSource相关的配置都忽略，直接看事务相关的配置 123456&lt;!-- 声明使用的事务管理器 --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;constructor-arg ref=\"dataSource\" /&gt;&lt;/bean&gt;&lt;!-- 启用注解式声明事务 --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\" /&gt; 这样配置后，在对应的方法上添加@Transactional注解即可启用事务，非常方便 原理Spring的事务配置和使用是很简单的，但是我们一定不会满足于此，接下面我们就来分析一下上面这几行配置如何起到这么大的作用 TransactionManager先来看下 DataSourceTransactionManager 这个类的基础关系 这个关系还是比较简单的，一个接口PlatformTransactionManager， 有接口就基本会有一个抽象类 AbstractPlatformTransactionManager 看下接口的定义 123456789// PlatformTransactionManager接口功能比较简单，主要就是获取事务，提交事务，回滚事务public interface PlatformTransactionManager &#123; // 获取当前存在的事务或者创建一个新事务 TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; // 提交事务 void commit(TransactionStatus status) throws TransactionException; // 回滚事务 void rollback(TransactionStatus status) throws TransactionException;&#125; 其中几个类的作用我们需要明确一下 TransactionDefinition 1234567891011121314151617181920212223242526272829303132// TransactionDefinition 用于定义事务的隔离级别，传播规则，超时时间，是否只读事务public interface TransactionDefinition &#123; // 事务传递规则定义 int PROPAGATION_REQUIRED = 0; int PROPAGATION_SUPPORTS = 1; int PROPAGATION_MANDATORY = 2; int PROPAGATION_REQUIRES_NEW = 3; int PROPAGATION_NOT_SUPPORTED = 4; int PROPAGATION_NEVER = 5; int PROPAGATION_NESTED = 6; // 事务隔离级别定义 int ISOLATION_DEFAULT = -1; int ISOLATION_READ_UNCOMMITTED = Connection.TRANSACTION_READ_UNCOMMITTED; int ISOLATION_READ_COMMITTED = Connection.TRANSACTION_READ_COMMITTED; int ISOLATION_REPEATABLE_READ = Connection.TRANSACTION_REPEATABLE_READ; int ISOLATION_SERIALIZABLE = Connection.TRANSACTION_SERIALIZABLE; // 超时时间 int TIMEOUT_DEFAULT = -1; // 获取传递规则 int getPropagationBehavior(); // 获取隔离级别 int getIsolationLevel(); // 获取超时时间 int getTimeout(); // 是否只读事务 boolean isReadOnly(); // 获取事务名称 String getName();&#125; TransactionStatus TransactionStatus中主要是保存事务的状态，以及一些保存点（用于事务嵌套回滚等）的信息 AbstractPlatformTransactionManager123456// AbstractPlatformTransactionManager 中定义了基本骨架// 留给子类实现的方法有如下等一些方法protected abstract Object doGetTransaction() throws TransactionException;protected abstract void doBegin(Object transaction, TransactionDefinition definition) throws TransactionException;protected abstract void doCommit(DefaultTransactionStatus status) throws TransactionExceptionprotected abstract void doRollback(DefaultTransactionStatus status) throws TransactionException; TransactionManager中用于定义协议，通用的实现基本都在对应的抽象类中(可以理解为模板方法模式)，在抽象类中定义模板方法，具体子类负责实现。 AbstractPlatformTransactionManager主要封装了传递规则等的处理逻辑，这里就先不进入具体分析了，大家有兴趣可以去看下对应的源码 DataSourceTransactionManager有了抽象类封装基本骨架，子类实现起来就比较简单了，我们挑几个方法看一下就好 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; // 新建一个事务，注意其中的ConnectionHolder获取 // TransactionSynchronizationManager 是一个基于 ThreadLocal的同步管理器 // 第一次调用时，其中没有值，ConnectionHolder值是null @Override protected Object doGetTransaction() &#123; DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(this.dataSource); txObject.setConnectionHolder(conHolder, false); return txObject; &#125; // 判断是否事务（连接）已经存在，主要就是判断 ConnectionHolder 是否为空等 @Override protected boolean isExistingTransaction(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; return (txObject.getConnectionHolder() != null &amp;&amp; txObject.getConnectionHolder().isTransactionActive()); &#125; // 事务（连接）不存在时，使用此方法进行初始化 @Override protected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try &#123; if (txObject.getConnectionHolder() == null || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; // 事务信息中连接不存在，则从 dataSource中进行连接获取 Connection newCon = this.dataSource.getConnection(); &#125; txObject.setConnectionHolder(new ConnectionHolder(newCon), true); txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // 关闭自动提交 if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); con.setAutoCommit(false); &#125; prepareTransactionalConnection(con, definition); txObject.getConnectionHolder().setTransactionActive(true); // 设置超时时间 int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; // 将连接信息绑定到线程中（通过TransactionSynchronizationManager中的ThreadLocal) if (txObject.isNewConnectionHolder()) &#123; TransactionSynchronizationManager.bindResource(getDataSource(), txObject.getConnectionHolder()); &#125; &#125; catch (Throwable ex) &#123; // 已删除 &#125; &#125; // 基本的通过连接提交事务， doRollback方法也类似，就不再贴代码了 @Override protected void doCommit(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try &#123; con.commit(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(\"Could not commit JDBC transaction\", ex); &#125; &#125;&#125; 到这里算是事务管理器的部分简单整理完了，其实就是Spring提供了一套事务功能的基本抽象（其中包括事务传递行为），然后由各个子类进行具体的实现 同时Spring使用基于 ThreadLocal 的 TransactionSynchronizationManager 进行事务资源的管理，如连接等 1234567891011121314151617181920212223242526272829303132333435363738394041424344// TransactionSynchronizationManager 部分代码public abstract class TransactionSynchronizationManager &#123; private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;Map&lt;Object, Object&gt;&gt;(\"Transactional resources\"); private static final ThreadLocal&lt;Set&lt;TransactionSynchronization&gt;&gt; synchronizations = new NamedThreadLocal&lt;Set&lt;TransactionSynchronization&gt;&gt;(\"Transaction synchronizations\"); private static final ThreadLocal&lt;String&gt; currentTransactionName = new NamedThreadLocal&lt;String&gt;(\"Current transaction name\"); private static final ThreadLocal&lt;Boolean&gt; currentTransactionReadOnly = new NamedThreadLocal&lt;Boolean&gt;(\"Current transaction read-only status\"); private static final ThreadLocal&lt;Integer&gt; currentTransactionIsolationLevel = new NamedThreadLocal&lt;Integer&gt;(\"Current transaction isolation level\"); private static final ThreadLocal&lt;Boolean&gt; actualTransactionActive = new NamedThreadLocal&lt;Boolean&gt;(\"Actual transaction active\"); public static boolean hasResource(Object key) &#123; Object actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key); Object value = doGetResource(actualKey); return (value != null); &#125; private static Object doGetResource(Object actualKey) &#123; Map&lt;Object, Object&gt; map = resources.get(); if (map == null) &#123; return null; &#125; Object value = map.get(actualKey); return value; &#125; public static void bindResource(Object key, Object value) throws IllegalStateException &#123; Object actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key); Assert.notNull(value, \"Value must not be null\"); Map&lt;Object, Object&gt; map = resources.get(); if (map == null) &#123; map = new HashMap&lt;Object, Object&gt;(); resources.set(map); &#125; Object oldValue = map.put(actualKey, value); &#125;&#125; 编程事事务有了以上的基础后，我们就可以使用编程式的方式来使用事务了，代码如下： 123456789101112131415161718192021// dataSource与transactionManager都可以配置交给Spring管理DriverManagerDataSource dataSource = new DriverManagerDataSource(\"jdbc:mysql://xx\", \"root\", \"root\");PlatformTransactionManager transactionManager = new DataSourceTransactionManager(dataSource);JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);DefaultTransactionDefinition def = new DefaultTransactionDefinition();def.setTimeout(5);// 这里会将Connection设置到TransactionSynchronizationManager中(如果之前不存在)TransactionStatus status = transactionManager.getTransaction(def);try &#123; // 事务操作，jdbcTemplate会优先从TransactionSynchronizationManager中获取连接 Integer integer = jdbcTemplate.queryForObject(\"select count(*) from hero\", Integer.class); System.out.println(\"count is: \" + integer); // 事务提交 transactionManager.commit(status);&#125; catch (DataAccessException e) &#123; transactionManager.rollback(status); throw e;&#125;// 上述方法还可以使用org.springframework.transaction.support.TransactionTemplate来简化实现 其中jdbcTemplate最终会调用org.springframework.jdbc.datasource.DataSourceUtils#doGetConnection来获取连接资源 1234567891011121314151617181920212223242526272829303132public static Connection doGetConnection(DataSource dataSource) throws SQLException &#123; // 调用 TransactionSynchronizationManager 的 getResource 方法 ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); if (conHolder != null &amp;&amp; (conHolder.hasConnection() || conHolder.isSynchronizedWithTransaction())) &#123; conHolder.requested(); if (!conHolder.hasConnection()) &#123; logger.debug(\"Fetching resumed JDBC Connection from DataSource\"); conHolder.setConnection(dataSource.getConnection()); &#125; return conHolder.getConnection(); &#125; logger.debug(\"Fetching JDBC Connection from DataSource\"); Connection con = dataSource.getConnection(); if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; ConnectionHolder holderToUse = conHolder; if (holderToUse == null) &#123; holderToUse = new ConnectionHolder(con); &#125; else &#123; holderToUse.setConnection(con); &#125; holderToUse.requested(); TransactionSynchronizationManager.registerSynchronization( new DataSourceUtils.ConnectionSynchronization(holderToUse, dataSource)); holderToUse.setSynchronizedWithTransaction(true); if (holderToUse != conHolder) &#123; TransactionSynchronizationManager.bindResource(dataSource, holderToUse); &#125; &#125; return con;&#125; 注解式声明事务介绍完DataSourceTransactionManager， 我们看下Spring是如何通过注解来实现使用事务的，目前我们配置的内容只有&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&gt;， 那么我们就从这里入手 Spring处理自定义标签是使用特定的handler进行的，所以我们可以根据命名空间直接找到TxNamespaceHandler 12345678public class TxNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser(\"advice\", new TxAdviceBeanDefinitionParser()); registerBeanDefinitionParser(\"annotation-driven\", new AnnotationDrivenBeanDefinitionParser()); registerBeanDefinitionParser(\"jta-transaction-manager\", new JtaTransactionManagerBeanDefinitionParser()); &#125;&#125; 找到对应的Bean解析器 AnnotationDrivenBeanDefinitionParser，进入 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class AnnotationDrivenBeanDefinitionParser implements BeanDefinitionParser &#123; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; registerTransactionalEventListenerFactory(parserContext); String mode = element.getAttribute(\"mode\"); if (\"aspectj\".equals(mode)) &#123; // mode=\"aspectj\" registerTransactionAspect(element, parserContext); &#125; else &#123; // mode=\"proxy\", 默认的，我们之前的配置会进入这里 AopAutoProxyConfigurer.configureAutoProxyCreator(element, parserContext); &#125; return null; &#125; private static class AopAutoProxyConfigurer &#123; public static void configureAutoProxyCreator(Element element, ParserContext parserContext) &#123; // 启用 AOP（AutoProxyCreator）自动发现Advisor并进行对对应类创建代理功能 AopNamespaceUtils.registerAutoProxyCreatorIfNecessary(parserContext, element); String txAdvisorBeanName = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME; if (!parserContext.getRegistry().containsBeanDefinition(txAdvisorBeanName)) &#123; Object eleSource = parserContext.extractSource(element); // 创建TransactionAttributeSource Bean // 这个类主要用来获取注解等中的配置的事务信息 RootBeanDefinition sourceDef = new RootBeanDefinition(\"org.springframework.transaction.annotation.AnnotationTransactionAttributeSource\"); sourceDef.setSource(eleSource); sourceDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); String sourceName = parserContext.getReaderContext().registerWithGeneratedName(sourceDef); // 创建TransactionInterceptor Bean // 这个类主要配置AOP拦截到后的处理逻辑 RootBeanDefinition interceptorDef = new RootBeanDefinition(TransactionInterceptor.class); interceptorDef.setSource(eleSource); interceptorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registerTransactionManager(element, interceptorDef); interceptorDef.getPropertyValues().add(\"transactionAttributeSource\", new RuntimeBeanReference(sourceName)); String interceptorName = parserContext.getReaderContext().registerWithGeneratedName(interceptorDef); // 创建 TransactionAttributeSourceAdvisor Bean // 这个类主要用来判断Bean是否需要代理，及包装代理后对应的处理逻辑 RootBeanDefinition advisorDef = new RootBeanDefinition(BeanFactoryTransactionAttributeSourceAdvisor.class); advisorDef.setSource(eleSource); advisorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); advisorDef.getPropertyValues().add(\"transactionAttributeSource\", new RuntimeBeanReference(sourceName)); advisorDef.getPropertyValues().add(\"adviceBeanName\", interceptorName); if (element.hasAttribute(\"order\")) &#123; advisorDef.getPropertyValues().add(\"order\", element.getAttribute(\"order\")); &#125; parserContext.getRegistry().registerBeanDefinition(txAdvisorBeanName, advisorDef); CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), eleSource); compositeDef.addNestedComponent(new BeanComponentDefinition(sourceDef, sourceName)); compositeDef.addNestedComponent(new BeanComponentDefinition(interceptorDef, interceptorName)); compositeDef.addNestedComponent(new BeanComponentDefinition(advisorDef, txAdvisorBeanName)); parserContext.registerComponent(compositeDef); &#125; &#125; &#125;&#125; 首先我们要看一下AopNamespaceUtils.registerAutoProxyCreatorIfNecessary(parserContext, element)，这个是很关键的，Spring的事务是基于AOP的，所以这里注册了一个AOP的一个自动发现并创建代理类的Bean， 我们跟进代码会发现注册的BeanInfrastructureAdvisorAutoProxyCreator，AdvisorAutoProxyCreator Bean是Spring AOP自动创建代理的关键，它实现了 BeanPostProcessor接口，并在每个Bean创建初始化前后，对满足条件的Bean进行替换代理 12345678910111213141516171819202122232425262728293031323334353637// AbstractAutoProxyCreatorpublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125;protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (beanName != null &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 如果匹配上，则创建对应的代理 // 其中的 Advisor就是我们添加的 BeanFactoryTransactionAttributeSourceAdvisor Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 接着来看下 TransactionAttributeSourceAdvisor，AOP里面的关键Advisor中包含两个职责，一个用来匹配切点的Pointcut, 还有一个用来增强的 Advice，在这里分别依赖 AnnotationTransactionAttributeSource 和 TransactionInterceptor 来实现 规则匹配- 基于AnnotationTransactionAttributeSource 先来看下基于 AnnotationTransactionAttributeSource 的匹配规则功能（已删除大部分代码） 123456789101112131415161718192021222324// TransactionAttributeSourceAdvisorpublic class TransactionAttributeSourceAdvisor extends AbstractPointcutAdvisor &#123; // 包装 TransactionAttributeSource 为 pointcut private final TransactionAttributeSourcePointcut pointcut = new TransactionAttributeSourcePointcut() &#123; @Override protected TransactionAttributeSource getTransactionAttributeSource() &#123; return (transactionInterceptor != null ? transactionInterceptor.getTransactionAttributeSource() : null); &#125; &#125;;&#125;// TransactionAttributeSourcePointcutabstract class TransactionAttributeSourcePointcut extends StaticMethodMatcherPointcut implements Serializable &#123; // pointcut的匹配实现 @Override public boolean matches(Method method, Class&lt;?&gt; targetClass) &#123; if (TransactionalProxy.class.isAssignableFrom(targetClass)) &#123; return false; &#125; TransactionAttributeSource tas = getTransactionAttributeSource(); // 这里可以简单理解为，如果有Transactional注解，则认为方法匹配成功 return (tas == null || tas.getTransactionAttribute(method, targetClass) != null); &#125;&#125; 增强实现- 基于TransactionInterceptor 直接看起代码方法invoke 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// TransactionInterceptor@Overridepublic Object invoke(final MethodInvocation invocation) throws Throwable &#123; Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); return invokeWithinTransaction(invocation.getMethod(), targetClass, new TransactionAspectSupport.InvocationCallback() &#123; // 回调中执行具体的事务中逻辑 @Override public Object proceedWithInvocation() throws Throwable &#123; return invocation.proceed(); &#125; &#125;);&#125;// TransactionAspectSupport 中实现protected Object invokeWithinTransaction(Method method, Class&lt;?&gt; targetClass, final TransactionAspectSupport.InvocationCallback invocation) throws Throwable &#123; final TransactionAttribute txAttr = getTransactionAttributeSource().getTransactionAttribute(method, targetClass); final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // 获取事务 TransactionAspectSupport.TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try &#123; // 调用实际业务方法 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // 异常时进行回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; // 没有异常时则提交事务 commitTransactionAfterReturning(txInfo); return retVal; &#125;&#125;protected TransactionAspectSupport.TransactionInfo createTransactionIfNecessary( PlatformTransactionManager tm, TransactionAttribute txAttr, final String joinpointIdentification) &#123; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123; // 调用 transactionManager的获取事务方法 status = tm.getTransaction(txAttr); &#125; &#125; return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);&#125;protected void completeTransactionAfterThrowing(TransactionAspectSupport.TransactionInfo txInfo, Throwable ex) &#123; if (txInfo != null &amp;&amp; txInfo.hasTransaction()) &#123; if (txInfo.transactionAttribute.rollbackOn(ex)) &#123; try &#123; // 调用transactionManager的回滚方法 txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus()); &#125; catch (Error err) &#123; // ... &#125; &#125; &#125;&#125;protected void commitTransactionAfterReturning(TransactionAspectSupport.TransactionInfo txInfo) &#123; if (txInfo != null &amp;&amp; txInfo.hasTransaction()) &#123; // 调用transactionManager 提交事务 txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125;&#125; 注解实现的原理基本就是上面的这些了，总结一下就是 首先启用AOP的自动代理创建功能 创建Advisor, 使用 AnnotationTransactionAttributeSource 实现 pointcut的功能，通过方法注解匹配 使用TransactionInterceptor实现增强(Advice)，其中包装业务逻辑，使用TransactionManager调用具体事务","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"},{"name":"事务","slug":"事务","permalink":"https://zhengw-tech.com/tags/事务/"}]},{"title":"从源码看ThreadLocal","slug":"threadlocal","date":"2020-03-22T08:46:11.000Z","updated":"2021-08-22T05:28:48.066Z","comments":true,"path":"2020/03/22/threadlocal/","link":"","permalink":"https://zhengw-tech.com/2020/03/22/threadlocal/","excerpt":"对于多线程并发对数据的修改的情况，其实除了使用锁或者CAS机制之外，有的情况我们完全可以为每一个线程分配单独的数据，这个数量只能在对应的线程下才能访问到，这样就能避免资源的争抢 或者对于单次请求全局的一些信息，比如当前请求对应的用户信息，可以不通过参数的方式依次传递，而是在全局的一个地方维护，比如当请求进来时，就将当前用户的信息存储进去，但是因为我们的服务是多线程的，同时可能有很多的请求，所以需要用户信息有线程隔离的能力，不能访问到或覆盖了别的线程的用户信息 JDK提供的对应功能的类就是ThreadLocal","text":"对于多线程并发对数据的修改的情况，其实除了使用锁或者CAS机制之外，有的情况我们完全可以为每一个线程分配单独的数据，这个数量只能在对应的线程下才能访问到，这样就能避免资源的争抢 或者对于单次请求全局的一些信息，比如当前请求对应的用户信息，可以不通过参数的方式依次传递，而是在全局的一个地方维护，比如当请求进来时，就将当前用户的信息存储进去，但是因为我们的服务是多线程的，同时可能有很多的请求，所以需要用户信息有线程隔离的能力，不能访问到或覆盖了别的线程的用户信息 JDK提供的对应功能的类就是ThreadLocal 使用先来看下最简单的例子 12345678910111213141516171819202122private static ThreadLocal&lt;String&gt; nameThreadLocal = new ThreadLocal&lt;&gt;();private static ExecutorService executorService = Executors.newSingleThreadExecutor();public static void main(String[] args) throws Exception &#123; // 在当前线程中设置值 nameThreadLocal.set(\"zheng\"); testGet(); executorService.shutdown();&#125;private static void testGet() &#123; // 在当前线程中获取 String name = nameThreadLocal.get(); System.out.println(\"相同线程获取名称：\" + name); // 在另一个线程中获取threadlocal中的值 executorService.execute(() -&gt; &#123; String name1 = nameThreadLocal.get(); System.out.println(\"不同线程获取名称：\" + name1); &#125;);&#125; 输出结果如下： 12相同线程获取名称：zheng不同线程获取名称：null 即在哪个线程下设置的值，则只有在对应的线程下才能获取到，其他线程无法获取和操作 原理作为一个技术人，只会使用是不能让我们满足的，下面我们就一起看看这个到底是怎么实现的 为了避免大家心急，先来简单说一下结论，之后我们再去看源码（基于JDK1.8） 其实在每个Thread类中，也就是每个线程中都有一个 ThreadLocalMap 类型的变量，这个类和我们平时使用的HashMap等的原理其实是比较相像的，如果大家对于HashMap的原理不太熟悉，可以参考一下我之前的文章，这里就不再介绍了 在这个Map中的key就是我们之前定义的ThradLocal实例，获取值时，在当前线程的ThreadLocalMap中根据ThreadLocal实例去匹配即可，由于不同线程是不同的Thread实例，所以ThreadLocalMap是独立的，互相不可见 好，现在开始进入源码分析阶段，先从set方法开始 1234567891011121314151617181920212223242526// ThreadLocalpublic void set(T value) &#123; // 从当前线程中获取 ThreadLocalMap 实例 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // 不存在则创建ThreadLocalMap // 存在则添加键值对，key为当前ThreadLocal实例,value为对应值 if (map != null) // 1. 添加到ThreadLocalMap中 map.set(this, value); else createMap(t, value);&#125;// 从线程Thread中获取对应的ThreadLocalMap类型变量threadLocals// public class Thread implements Runnable &#123;// ThreadLocal.ThreadLocalMap threadLocals = null;// &#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;// 初始化创建Mapvoid createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 上面的部分看起来还是比较简单的，我们再接着看下键值对是如何添加到ThreadLocalMap中的（对应上面源码中标注的1处），先看下ThreadLocalMap中的几个关键属性 1234567891011121314151617static class ThreadLocalMap &#123; // 用于存储键值对 &lt;ThreadLocal, value&gt; // 注意：从这里可以看出来，其中的key也就是ThreadLocal实例是一个弱引用 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private static final int INITIAL_CAPACITY = 16; // Entry数组，储存对应的键值对数据 private Entry[] table; private int size = 0; private int threshold; // ...&#125; 弱引用 这里要先提一下弱引用，弱引用是只要发生了GC，就会被回收掉（相关的还有强引用，软引用，虚引用等） 而这里Entry是继承了WeakReference的，但是要注意一下，只有其中的ThreadLocal引用是弱引用，而其中的value并不是弱引用的，在发生垃圾回收时，只有ThreadLocal部分会被回收，value并不会 所以，如果出现Entry e != null &amp;&amp; e.get() == null时，说明其中的key被垃圾回收掉了 接下来分析 ThreadLocalMap的set方法 12345678910111213141516171819202122232425262728293031323334353637383940414243// ThreadLocalMapprivate void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; // 1. 注意这里的获取索引位置与HashMap有很大的不同 int i = key.threadLocalHashCode &amp; (len-1); // 获取对应索引位置，如果其中不为null说明发生了哈希冲突 // 这时会判断如果key相等（同一个ThradLocal实例)则进行值替换 // 如果之前key已经被垃圾回收，则进行值替换 // 否则进行索引递增查询查找，找到第一个为空的槽位进行插入 for (Entry e = tab[i]; e != null; // 顺序循环重找，具体可以见下面的方法体 e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 直接使用==比较，判断是否是同一个ThreadLocal实例 // 2. 注意这里的key比较也与HashMap不同 if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; // 3. e不为null, k==null说明之前的key已经被垃圾回收了，可以替换赋值 replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; // 先进行一下清除被垃圾回收的槽位操作，如果有清除操作就不再判断是否需要rehash // 4. 如果没有清除任何槽位，则判断是否达到rehash阈值，达到则进行rehash if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;// 依次顺序递增，循环获取索引private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125; 索引计算及冲突处理 先来对比HashMap说一下槽位的定位及发生哈希冲突时的处理方式，对应上述源码标记1，2处 HashMap：在HashMap中，计算槽位使用的是key对应类的hashCode()，哈希冲突时先使用使用equals方法比较是否是同一个key，真正冲突后在对应槽位形成链表（达到8个后会转为红黑树） 在HashMap中，计算槽位使用的是key对应类的hashCode()，哈希冲突时先使用使用equals方法比较是否是同一个key，真正冲突后在对应槽位形成链表（达到8个后会转为红黑树） ThreadLocalMap：对比着我们看下ThreadLocalMap 123456789101112131415// 计算索引的方法int i = key.threadLocalHashCode &amp; (len-1);// 每个实例独立的变量private final int threadLocalHashCode = nextHashCode();// 每次创建新实例时，threadLocalHashCode都会依次递增private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;// 静态变量，初始值为0private static AtomicInteger nextHashCode = new AtomicInteger();// 每次创建新实例，threadLocalHashCode递增的值private static final int HASH_INCREMENT = 0x61c88647; 很明显可以看出来，ThreadLocalMap的key对应的索引位计算并不依赖hashCode方法，而是使用了一个每次创建都会递增的一个值（0x61c88647这个值大家有兴趣可以去搜索了解一下，主要就是为了hash值能均匀的分布在二次方的数组里） 在哈希冲突时，也没有使用equals方法进行后续比较，而是直接使用了==比较，因为它不需要像我们业务处理时根据根据特定逻辑判断是否相等，不同的实例值一定不能互相覆盖，所以直接判断是否是同一个实例即可 再就是发出真实冲突时，没有使用链表，而是接着此索引向后查找到第一个空的槽位，进行插入 下面再来看下上面标示3处的代码，这里主要处理的情况是在插入时，计算到的索引位已经有值，但是其中的key已经被回收掉了，这时候进行占用相关的操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465if (k == null) &#123; // 3. e不为null, k==null说明之前的key已经被垃圾回收了，可以替换赋值 replaceStaleEntry(key, value, i); return;&#125;// 进入这里时，可以确定索引位 staleSlot的槽位中的key已经被垃圾回收// 这个方法主要功能如下// 1. 先向前获取被垃圾回收key的槽位// 2. 向后遍历，如果发现相同key的槽位，则将其前置到staleSlot位// 并替换前面索引对应的值，之后从发现位索引开始向后进行key被垃圾回收的槽位清理// 3. 如果向后没有找到要相同的key, 则简单替换staleSlot槽位的内容，之后进行key回收节点的清理等private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 向前遍历有数据(不为null)的槽位，查找到第一个被垃圾回收掉key的槽位的索引 int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 向后遍历非空的槽位 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 如果在要替换的槽位后面又找到了当前ThreadLocal实例的key // 则对两个槽位的值进行替换，并将value的值进行覆盖 if (k == key) &#123; e.value = value; // 替换后，会导致 i 索引位置对应的key是已经被垃圾回收的槽位 tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 如果staleSlot前面没有被垃圾回收的key，则从i索引位开始清理被垃圾回收的key if (slotToExpunge == staleSlot) slotToExpunge = i; // expungeStaleEntry 方法负责从i索引位开始清理被垃圾回收的key， // 直到遇到为null的槽位并返回对应索引 // cleanSomeSlots 从索引开始，进行log2(len)次数的垃圾回收key探测 // 探测到的槽位，也会进行清理操作 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 当遇到垃圾回收的key // 并且staleSlot前面没有被垃圾回收的key，则从i索引位开始清理被垃圾回收的key if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 如果后面没有当前ThreadLocal实例的槽位，则与staleSlot位的数据进行覆盖替换 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 如果staleSlot前面有被垃圾回收的key，则从发现的前面的被垃圾回收key槽位的索引进行清理操作 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 前面的内容中还涉及了两个方法(expungeStaleEntry 和 cleanSomeSlots)，我们依次看下 123456789101112131415161718192021222324252627282930313233343536373839// 这个方法主要对staleSlot索引槽位进行清理// 并对其后面的（直到遇到未赋值=null的槽位）不在计算索引位的值进行重定位private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 清理值 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // 从当前索引位向后查找所有被垃圾回收的key的槽位，进行清理（直到遇到未赋值=null的槽位） // 这个过程中如果遇到计算的索引与当前索引，则重新为其寻找位置（从计算的索引依次向后查找为null的槽位） // 返回为null的节点的索引 Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 最后来看下cleanSomeSlots方法，这个方法比较简单 1234567891011121314151617// 从i+1位开始，进行log2(n)个数量的扫描// 如果发现被垃圾回收key的槽位，则对其进行清理private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125; 对于Map相关类，我们都知道扩容时会进行rehash，所以我们接下来就是看下ThreadLocalMap的 rehash 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private void rehash() &#123; // 遍历所有槽位，对key被垃圾回收的节点进行清理 expungeStaleEntries(); // 如果清理后仍达到rehash的阈值，则进行resize if (size &gt;= threshold - threshold / 4) resize();&#125;// 遍历所有槽位，对key被垃圾回收的节点进行清理private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125;// 扩容两倍，重新计算索引位，遇到key被垃圾回收的节点直接丢弃private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 以上就是set方法的全部内容 最后我们来看下get方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// ThreadLocalpublic T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; // 调用 ThreadLocalMap.getEntry方法 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;// ThreadLocalMap.getEntry方法 内容如下private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 计算索引 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // 如果索引对应的内容存在，key也没有被垃圾回收，则返回对应的槽位内容 if (e != null &amp;&amp; e.get() == key) return e; else // 否则向后查找 return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 向后查找,如果找到对应key，则返回 // 如果遇到key被垃圾回收的槽位，则进行清理 // 否则继续查找，直到遇到内容为null的节点，这时表示节点不存在，返回null while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; InheritableThreadLocal虽然ThreadLocal可以让我们创建线程独立的数据，但是有的时候又需要跨线程进行使用，比如在执行任务的时候，需要创建新的线程来加快执行速度，这时候新创建线程的时候需要把当前线程设置到ThreadLocal中的值传递进去，此时可以使用InheritableThreadLocal，使用方法同ThreadLocal 在Thread类中，threadLocals 和 InheritableThreadLocal 都是其中的属性，源码部分如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Thread implements Runnable &#123; /* ThreadLocal 使用 */ ThreadLocal.ThreadLocalMap threadLocals = null; /* * InheritableThreadLocal 使用 */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; // 构造函数 public Thread() &#123; init(null, null, \"Thread-\" + nextThreadNum(), 0); &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true); &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; if (name == null) &#123; throw new NullPointerException(\"name cannot be null\"); &#125; // 忽略了一些代码，只看InheritableThreadLocal部分 Thread parent = currentThread(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); // 这里将当前线程(非子线程)中的inheritableThreadLocals中的值复制到子线程中，这样子线程中就可以通过inheritableThreadLocal使用了 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); this.stackSize = stackSize; tid = nextThreadID(); &#125;&#125; 需要注意的是，在直接创建子线程的时候可以通过inheritableThreadLocal进行传递，但是如果是线程池的场景，则无法这样使用 以上就是ThreadLocal的全部内容，如有错误欢迎指正","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"Redis RDB与AOF","slug":"redis-persistence","date":"2020-03-14T16:13:37.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2020/03/15/redis-persistence/","link":"","permalink":"https://zhengw-tech.com/2020/03/15/redis-persistence/","excerpt":"Redis的存储是基于内存的，这就有意味着，如果服务重启那么所有的数据都会丢失，这是我们不能接受的，为此，Redis提供了 RDB 与 AOF 两种持久化机制 简介RDB: 对于RDB，我们可以把它理解一个定时的快照，就是每隔一段时间（或其他策略），它会创建一个当时所有数据的一个快照，默认存储到的文件为 dump.rdb AOF: 因为RDB创建的是所有数据的快照，这点就决定了它不可能进行高频率的执行，但是如果不经常性的执行，那么当出现如服务器宕机等情况时，会丢失从上次快照到当前的所有操作数据。为了解决这个问题，AOF应运而生，它会在每次执行操作的时候，将这个操作命令进行持久化存储，默认存储到的文件为 appendonly.aof，这样恢复的时候，可以将 aof文件中的所有命令重新执行一遍，即可恢复数据","text":"Redis的存储是基于内存的，这就有意味着，如果服务重启那么所有的数据都会丢失，这是我们不能接受的，为此，Redis提供了 RDB 与 AOF 两种持久化机制 简介RDB: 对于RDB，我们可以把它理解一个定时的快照，就是每隔一段时间（或其他策略），它会创建一个当时所有数据的一个快照，默认存储到的文件为 dump.rdb AOF: 因为RDB创建的是所有数据的快照，这点就决定了它不可能进行高频率的执行，但是如果不经常性的执行，那么当出现如服务器宕机等情况时，会丢失从上次快照到当前的所有操作数据。为了解决这个问题，AOF应运而生，它会在每次执行操作的时候，将这个操作命令进行持久化存储，默认存储到的文件为 appendonly.aof，这样恢复的时候，可以将 aof文件中的所有命令重新执行一遍，即可恢复数据 配置及使用RDB和AOF的配置都在redis的配置文件redis.conf中进行配置，我们看下主要的配置 RDB的主要配置如下 1234567rdbcompression yes # 是否使用 LZF算法 压缩字符串dbfilename dump.rdb # 持久化存储的文件名称# save &lt;seconds&gt; &lt;changes&gt;, 表示在多少秒内发生了指定次数的数据变化，那么就会进行RDB持久化save 900 1 # 900秒内有 1 次修改，就进行RDB持久化save 300 10 # 300秒内有 10 次修改，就进行RDB持久化save 60 10000 # 60秒内有 10000 次修改，就进行RDB持久化 同时，我们也可以通过执行save (同步执行，会阻塞请求) 和bgsave (另起子进程执行，可以同时接受其他命令执行) 手动触发数据快照的创建 AOF的主要配置为 1234567891011appendonly yes # 是否开启aof,默认关闭appendfilename &quot;appendonly.aof&quot; # 持久化存储的文件名## 触发AOF重写配置（需要同时满足）auto-aof-rewrite-percentage 100 # 代表当前AOF文件的大小和上一次重写后的文件大小的比值auto-aof-rewrite-min-size 64mb # 表示触发AOF重写是的文件最小体积## 同步文件配置（选择其中一个）# appendfsync always # 命令写入aop后，让操作系统同步文件到硬盘中appendfsync everysec # 命令写入aop后，每秒种 让操作系统同步文件到硬盘中（默认）# appendfsync no # 命令写入aop后，让操作系统自行决定何时同步文件到硬盘中 对于AOF，有个重写的概念，因为它保存的是所有指定的修改数据指令，其中有许多是可以精简的，举个例子，比如有如下命令 12set k1 v1del k1 我们看一眼就知道最终redis中是没有k1这个数据的，但是aof却要存储这两个指令，其实完全可以将这两个命令删除掉，当然还有很多其他情况下，也是可以对命令进行精简的 我们可以通过配置auto-aof-rewrite-percentage和auto-aof-rewrite-min-size来控制重新的触发条件，或者可以手动执行bgrewriteaof来触发AOF重写 重写时，会根据现有的数据，重新生成新的AOF文件，之后将在重写执行过程中用户新产生的命令追加到此AOF文件中，最后替换老的文件 其中还有一个同步文件配置，是因为调用操作系统写入时，并不一定会实时写入硬盘，而是写入到一个内存缓冲区，之后由操作系统不定时写入到硬盘。这本来是操作系统提升写入速度的机制，但是对于Redis来说却有可能导致数据的丢失，所以可以通过配置appendfsync控制刷到硬盘的频率，但这也需要平衡，每次都刷到硬盘会导致性能的下降，一般默认每秒一次即可 RDB和AOF配置及状态也可以通过执行info persistence查看 重启恢复在Redis重新启动时，因为aof数据相比rdb会更新一些，所以如果开启了AOF，并且aof文件存在，那么使用aof文件进行数据恢复，服务端日志打印 * DB loaded from append only file: 0.000 seconds 如果AOF关闭，rdb文件存在则加载rdb文件恢复数据，服务端打印如下日志 * DB loaded from disk: 0.000 seconds 文件结构对于持久化的文件结构，我们可以简单看下 RDB文件先来看下RDB的 dump.rdb 文件，RDB的文件格式有许多版本，最新的 redis5.0 使用的是 版本9，具体版本可以参考RDB_Version_History，而关于 RDB文件结构的文档，目前只找到了关于 版本7 的，最新的版本并没有找到对应的文档资料 我们就找个简单的例子来看一下，具体的大家可以参考上面的资料 我本地安装的redis版本是5.0的，就先看下对应的RDB文件吧，先flushall清空数据后，执行set kk vv，再手动执行一下bgsave触发RDB 之后使用16进制的模式打开rdb文件，内容如下（右侧为对应的字符内容） 12345675245 4449 5330 3030 39fa 0972 6564 6973 | REDIS0009..redis2d76 6572 0535 2e30 2e33 fa0a 7265 6469 | -ver.5.0.3..redi732d 6269 7473 c040 fa05 6374 696d 65c2 | s-bits.@..ctime.22e4 6c5e fa08 7573 6564 2d6d 656d c2f0 | &quot;.l^..used-mem..0710 00fa 0c61 6f66 2d70 7265 616d 626c | .....aof-preambl65c0 00fe 00fb 0100 0002 6b6b 0276 76ff | e.........kk.vv.3545 3136 adb7 3b22 | 5E16..;&quot; 这里我们就结合源码来看一下，对应源码部分为（为了简单，已删除大部分内容） 123456789101112131415161718192021222324252627282930313233int rdbSaveRio(rio *rdb, int *error, int flags, rdbSaveInfo *rsi) &#123; snprintf(magic,sizeof(magic),\"REDIS%04d\",RDB_VERSION); // 1. 首先是写入魔术 REDIS 后面再加 4位的版本号 if (rdbWriteRaw(rdb,magic,9) == -1) goto werr; // 2. 写入Aux部分（不知道作用...） if (rdbSaveInfoAuxFields(rdb,flags,rsi) == -1) goto werr; for (j = 0; j &lt; server.dbnum; j++) &#123; redisDb *db = server.db+j; dict *d = db-&gt;dict; if (dictSize(d) == 0) continue; di = dictGetSafeIterator(d); // 3. 写入选择DB操作类型 if (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == -1) goto werr; // 4. 写入具体DB的数值 if (rdbSaveLen(rdb,j) == -1) goto werr; uint64_t db_size, expires_size; db_size = dictSize(db-&gt;dict); expires_size = dictSize(db-&gt;expires); // 5. 写入 RESIZEDB 操作类型 if (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == -1) goto werr; // 6. 写入db中key数量 if (rdbSaveLen(rdb,db_size) == -1) goto werr; // 7. 写入db中有过期时间的key数量 if (rdbSaveLen(rdb,expires_size) == -1) goto werr; // 其余部分省略 &#125;&#125; 各个操作码对应的值为： 12345678910/* Special RDB opcodes (saved/loaded with rdbSaveType/rdbLoadType). */#define RDB_OPCODE_MODULE_AUX 247 /* Module auxiliary data. */#define RDB_OPCODE_IDLE 248 /* LRU idle time. */#define RDB_OPCODE_FREQ 249 /* LFU frequency. */#define RDB_OPCODE_AUX 250 /* RDB aux field. */#define RDB_OPCODE_RESIZEDB 251 /* Hash table resize hint. */#define RDB_OPCODE_EXPIRETIME_MS 252 /* Expire time in milliseconds. */#define RDB_OPCODE_EXPIRETIME 253 /* Old expire time in seconds. */#define RDB_OPCODE_SELECTDB 254 /* DB number of the following keys. */#define RDB_OPCODE_EOF 255 /* End of the RDB file. */ 这里我们就可以和前面的文件内容进行对照了，最开始部分为 REDIS0009 为魔术 REDIS及版本9，后面的为aux域，这里我们先跳过，直接到我们关心的数据相关部分，内容为 所以现在直接跳过这部分内容，到数据部分，内容为 116进制： fe 00fb 0100 0002 6b6b 0276 76ff 3545 3136 adb7 3b22 依次顺序看下 FE 00 FE对应的10进制是254，即RDB_OPCODE_SELECTDB, 结合后面的00就表示 select 0 FB 01 00这个对应的是 RDB_OPCODE_RESIZEDB 表示 DB中的key数量为1个，有过期时间的key为0个 0002 6B6B 0276 76中，最开始的 00 通过0 = “String Encoding”可以得知表示值类型为string，后面的 02 表示的是长度为2，之后的两个字节 6B6B（0x6B的10进制为107，对应ASCII码字符为k） 表示的是我们之前设置的键: kk，再之后的 02 表示的也是长度为2， 对应的 7676（0x76的10进制为118，对应ASCII码字符为v） 表示的是设置的值：vv 紧接后面的 FF 对应的是RDB_OPCODE_EOF，标识RDB文件结束了 最后的都是3545 3136 adb7 3b22 为8为校验码 AOF最后看下AOF的文件格式，这次我们不用16进制打开，而是使用文本编辑器直接打开，内容如下 12345678910111213141516➜ cat appendonly.aofREDIS0009� redis-ver5.0.3�redis-bits�@�ctime�m m^used-mem� aof-preamble���kkvv��/�X�*2$6SELECT$10*3$3set$2kk$2vv 其实可以很明显的看到，前面的一段和RDB格式基本相同，而后面的其实就是我们执行的命令对应的RESP协议内容，这里就不再过多介绍了，不太了解的可以参考文档Redis Protocol specification， 或者我之前写的Redis服务端-客户端通信协议 内容到这里就介绍完了，如有错误，欢迎指正","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://zhengw-tech.com/tags/redis/"}]},{"title":"Netty服务端使用及简介","slug":"netty-server","date":"2020-02-29T05:44:46.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2020/02/29/netty-server/","link":"","permalink":"https://zhengw-tech.com/2020/02/29/netty-server/","excerpt":"最近因为工作原因，学习了一下Netty，这里写个笔记记录一下 Netty是什么呢？它是一款异步的事件驱动的网络应用程序框架，使用它可以快速的开发出可维护的高性能的面向协议的服务器和客户端—《Netty实战》 这是有两个关键词是异步和事件驱动，先来简单介绍一下 异步是指什么呢？就是发送消息和接收消息是异步的，如调用发送方法后，进行的异步发送，你不知道到底发送出去了没有，如果想要知道结果怎么办呢？这时候可以设置回调函数，发送结果会通过回调函数传回来，当然，其实也可以阻塞同步等待结果，不过那可能就会影响其他数据的处理了 事件驱动呢，我理解就是接收数据等的时候，如在数据可以到达可读取的时候，IO线程会通知调用我们相应的方法进行数据处理流程","text":"最近因为工作原因，学习了一下Netty，这里写个笔记记录一下 Netty是什么呢？它是一款异步的事件驱动的网络应用程序框架，使用它可以快速的开发出可维护的高性能的面向协议的服务器和客户端—《Netty实战》 这是有两个关键词是异步和事件驱动，先来简单介绍一下 异步是指什么呢？就是发送消息和接收消息是异步的，如调用发送方法后，进行的异步发送，你不知道到底发送出去了没有，如果想要知道结果怎么办呢？这时候可以设置回调函数，发送结果会通过回调函数传回来，当然，其实也可以阻塞同步等待结果，不过那可能就会影响其他数据的处理了 事件驱动呢，我理解就是接收数据等的时候，如在数据可以到达可读取的时候，IO线程会通知调用我们相应的方法进行数据处理流程 好了，下面我们看一段来自Netty官网的服务端代码 12345678910111213141516171819202122232425262728293031323334353637public class DiscardServer &#123; private int port; public DiscardServer(int port) &#123; this.port = port; &#125; public void run() throws Exception &#123; // EventLoopGroup可以理解为线程池，bossGroup中的线程主要负责监听连接请求，转发给workerGroup EventLoopGroup bossGroup = new NioEventLoopGroup(); // workerGroup主要负责在建立连接后的所有处理 EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) // 指定worker线程（与客户端连接）的处理链，数据在其中流转处理 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; // 向其中添加自定义的处理器 ch.pipeline().addLast(new DiscardServerHandler()); &#125; &#125;) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); // 绑定端口，启动服务等待连接请求 ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; &#125; 我们可以结合下面的图来理解一下 先来介绍几个概念 NioEventLoopGroup: 可以理解为一个线程池 NioEventLoop: 可以理解为单个线程，一个NioEventLoopGroup可以有多个NioEventLoop Selector: 可以理解为Java NIO中的选择器，负责监听通道事件，一个NioEventLoop有一个Selector Channel: 可以理解为Java NIO中的Channel通道，代表一个到客户端的连接，使用时需要注册到NioEventLoop中，NioEventLoop中可以有多个Channel，其中的Selector负责监听所有的channel事件 HandlePipeline/ Handler : 每个channel有一个对应的处理链，链中的handler也分为入站handler(处理接收到的数据)和出站handler(处理将要发送的数据)，当selector监听到对应事件发生时，线程会依次调用链中hanler的对应方法处理数据 有了前面的准备，这时候我们来分析一下初始化启动的流程 首先会创建一个NioServerSocketChannel(boss)，初始化其数据的处理器链handlerPipeline（其中有一个ServerBootstrapAcceptor） 将NioServerSocketChannel注册到EventLoopGroup的NioEventLoop中，每个NioEventLoop有一个Selector, 负责监听其下面的所有channel的事件 当有客户端发起连接时，selector会通知NioServerSocketChannel， 而NioServerSocketChannel会将数据转发到对应的处理链中 当处理链中的ServerBootstrapAcceptor接收到连接事件后，会获取对应的与客户端连接的channel，为其绑定初始阶段配置的handlerPipeline，并在NioServerSocketChannel(worker)中选择一个NioEventLoop进行注册，其中的Selector会负责监听事件，之后与此客户端的所有交互都由这个NioEventLoop中的线程负责执行 NioServerSocketChannel的 bossGroup与 workerGroup可以共用一个的 最后，再来介绍一下入站的Handler写法，同样是来自官网的demo 1234567891011121314151617// 继承 ChannelInboundHandlerAdapter 说明是入站事件的处理器public class DiscardServerHandler extends ChannelInboundHandlerAdapter &#123; // 当有数据可以读取时，会调用此方法 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // 这里可以进行对应的数据处理 ((ByteBuf) msg).release(); // (3) &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // 发生异常时关闭连接 cause.printStackTrace(); ctx.close(); &#125;&#125; 与此对应的处理出队事件的处理器是ChannelOutboundHandlerAdapter，如要要使用继承此类重写要处理的事件方法即可 好了，主要的服务端创建处理流程就是这些，如有错误欢迎指正","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"netty","slug":"netty","permalink":"https://zhengw-tech.com/tags/netty/"}]},{"title":"C语言实现的封装，继承，多态","slug":"oop-c","date":"2020-01-27T05:22:36.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2020/01/27/oop-c/","link":"","permalink":"https://zhengw-tech.com/2020/01/27/oop-c/","excerpt":"提到面向对象编程，我们想到的就是封装、继承、多态，但是其实这几个特性并不是只有面向对象语言才能实现，面向过程的C语言也是可以支持实现这三个特性的，下面我们来具体看下 封装1234// point.hstruct Point;struct Point* makePoint(double x, double y);double distance(struct Point *p1, struct Point *p2); 123456789101112131415161718192021// point.c#include \"point.h\"#include &lt;stdlib.h&gt;#include &lt;math.h&gt;struct Point &#123; double x, y;&#125;;struct Point* makePoint(double x, double y) &#123; struct Point* p = malloc(sizeof (struct Point)); p-&gt;x = x; p-&gt;y = y; return p;&#125;double distance(struct Point* p1, struct Point* p2) &#123; double dx = p1-&gt;x - p2-&gt;x; double dy = p1-&gt;y - p2-&gt;y; return sqrt(dx*dx + dy*dy);&#125;","text":"提到面向对象编程，我们想到的就是封装、继承、多态，但是其实这几个特性并不是只有面向对象语言才能实现，面向过程的C语言也是可以支持实现这三个特性的，下面我们来具体看下 封装1234// point.hstruct Point;struct Point* makePoint(double x, double y);double distance(struct Point *p1, struct Point *p2); 123456789101112131415161718192021// point.c#include \"point.h\"#include &lt;stdlib.h&gt;#include &lt;math.h&gt;struct Point &#123; double x, y;&#125;;struct Point* makePoint(double x, double y) &#123; struct Point* p = malloc(sizeof (struct Point)); p-&gt;x = x; p-&gt;y = y; return p;&#125;double distance(struct Point* p1, struct Point* p2) &#123; double dx = p1-&gt;x - p2-&gt;x; double dy = p1-&gt;y - p2-&gt;y; return sqrt(dx*dx + dy*dy);&#125; 这样使用point.h 的程序就不知道 Point 的内部结构，实现了数据的封装，外部只能使用声明的两个函数，如： 123456789// 使用 demo#include &lt;stdio.h&gt;#include \"point.h\"int main() &#123; struct Point* p1 = makePoint(5, 6); struct Point* p2 = makePoint(6, 7); printf(\"%lf\",distance(p1, p2));&#125; 继承接着上面的代码 12345678910111213141516171819202122232425#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include \"point.h\"struct NamedPoint &#123; double x, y; char* name;&#125;;struct NamedPoint* makeNamedPoint(double x, double y, char* name) &#123; struct NamedPoint* p = malloc(sizeof(struct NamedPoint)); p-&gt;x = x; p-&gt;y = y; p-&gt;name = name; return p;&#125; int main() &#123; struct NamedPoint* p1 = makeNamedPoint(0, 0, \"origin\"); struct NamedPoint* p2 = makeNamedPoint(3, 4, \"new\"); // 本来接受的参数只能是 Point类型的指针，这里是把 NamedPoint的指针进行强转 printf(\"%lf\",distance((struct Point*)p1, (struct Point*)p2));&#125; 这是能够进行强转调用，是因为 NamedPoint 结构体的前两个成员的顺序与 Point 结构体的完全一致，所以可以进行强转，这其实就可以算是一个单继承 多态最后我们来看一下多态，这个C语言也是可以实现的，通过使用函数指针 先看一个简单的例子 123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;// 定义函数指针typedef int (*myFunc)(int, int);// 定义函数1int add(int n, int m) &#123; return n + m;&#125;// 定义函数2int substract(int n, int m) &#123; return n - m;&#125;int main() &#123; // 为函数指针使用不同的函数实现进行调用 myFunc f = &amp;add; printf(\"%d\\n\", f(1, 2)); f = &amp;substract; printf(\"%d\\n\", f(1, 2));&#125; 上面的例子如果大家感受还不太明显的话，接下来看一个 redis 源码中的使用 123456789// dict.htypedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType; 上面这个结构中都是函数指针，可以类比为 Java 中的接口及对应函数声明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// uint64_t (*hashFunction)(const void *key) 实现函数uint64_t dictSdsHash(const void *key) &#123; return dictGenHashFunction((unsigned char*)key, sdslen((char*)key));&#125;// int (*keyCompare)(void *privdata, const void *key1, const void *key2) 实现函数int dictSdsKeyCompare(void *privdata, const void *key1, const void *key2) &#123; int l1,l2; DICT_NOTUSED(privdata); l1 = sdslen((sds)key1); l2 = sdslen((sds)key2); if (l1 != l2) return 0; return memcmp(key1, key2, l1) == 0;&#125;// ================= 具体的类型实现 =================/* Set dictionary type. Keys are SDS strings, values are ot used. */dictType setDictType = &#123; dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ dictSdsDestructor, /* key destructor */ NULL /* val destructor */&#125;;/* Sorted sets hash (note: a skiplist is used in addition to the hash table) */dictType zsetDictType = &#123; dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ NULL, /* Note: SDS string shared &amp; freed by skiplist */ NULL /* val destructor */&#125;;/* Db-&gt;dict, keys are sds strings, vals are Redis objects. */dictType dbDictType = &#123; dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ dictSdsDestructor, /* key destructor */ dictObjectDestructor /* val destructor */&#125;; 这几个类型都可以类比看做上面的接口的具体实现类，每个类有自己对应的函数实现 所以不是使用了面向对象的语言，写出的代码就是面向对象的，而使用了面向过程的语言写出来的代码就不行，只不过面向对象的语言对面向对象提供了更好的支持，写起来更方便，更安全而已。代码质量的好坏不是仅仅靠使用了什么高级语言就可以的，要想提升代码质量还是需要我们去不断思考和实践的","categories":[],"tags":[{"name":"c","slug":"c","permalink":"https://zhengw-tech.com/tags/c/"}]},{"title":"Tomcat NioEndpoint浅析","slug":"tomcat-nioendpoint","date":"2020-01-12T07:35:43.000Z","updated":"2021-04-17T14:50:06.970Z","comments":true,"path":"2020/01/12/tomcat-nioendpoint/","link":"","permalink":"https://zhengw-tech.com/2020/01/12/tomcat-nioendpoint/","excerpt":"NioEndpoint 是 Tomcat 中负责使用 NIO 方式进行网络通信功能的模块，它负责监听处理请求连接，并将解析出的字节流传递给 Processor 进行后续的处理 下面梳理一下主要的处理流程，如下图","text":"NioEndpoint 是 Tomcat 中负责使用 NIO 方式进行网络通信功能的模块，它负责监听处理请求连接，并将解析出的字节流传递给 Processor 进行后续的处理 下面梳理一下主要的处理流程，如下图 创建Acceptor(默认1个)，并启动在对应端口进行监听 创建Poller(多核下默认为2个)并启动，每个 Poller 在创建时会开启一个 Selector Acceptor 监听到连接后，将其转发注册到随机的一个 Poller 中 Poller 在获取到连接后，将其包装为 PollerEvent，并添加到其 events 列表中 Poller 在执行时，会循环获取 events，执行其 run方法 PollerEvent 执行时，会将其中的 SocketChannel 注册到selector中，监听对应事件 当有事件触发时，Poller 会将对应的连接转发给 Endpoint Endpoint 会创建对应的 SocketProcessor, 并将其提交到线程池中执行 SocketProcessor 会获取 Endpoint 中的 hanler进行处理 简化一下，可以得到如下结果 如果还有兴趣，可以看下接下来的代码， 为了简单，省略了部分代码，处理流程可根据序号进行跟进 Endpoint 的基础类为 AbstractEndpoint，部分简略后的代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public abstract class AbstractEndpoint&lt;S&gt; &#123; public final void start() throws Exception &#123; bind(); startInternal(); &#125; /** * 创建Acceptor, 进行端口监听 */ protected abstract Acceptor createAcceptor(); public abstract void bind() throws Exception; public abstract void unbind() throws Exception; public abstract void startInternal() throws Exception; public abstract void stopInternal() throws Exception; // 抽象方法，创建 SocketProcessor protected abstract SocketProcessorBase&lt;S&gt; createSocketProcessor( SocketWrapperBase&lt;S&gt; socketWrapper, SocketEvent event); // 16. public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper, SocketEvent event, boolean dispatch) &#123; try &#123; if (socketWrapper == null) &#123; return false; &#125; // 16. 创建 SockerProcessor SocketProcessorBase&lt;S&gt; sc = processorCache.pop(); if (sc == null) &#123; sc = createSocketProcessor(socketWrapper, event); &#125; else &#123; sc.reset(socketWrapper, event); &#125; // 17. 放入线程池中进行执行 Executor executor = getExecutor(); if (dispatch &amp;&amp; executor != null) &#123; executor.execute(sc); &#125; else &#123; sc.run(); &#125; &#125; catch (RejectedExecutionException ree) &#123; getLog().warn(sm.getString(\"endpoint.executor.fail\", socketWrapper) , ree); return false; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); // This means we got an OOM or similar creating a thread, or that // the pool and its queue are full getLog().error(sm.getString(\"endpoint.process.fail\"), t); return false; &#125; return true; &#125;&#125; NioEndpoint 有如下几个主要方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class NioEndpoint &#123; // 初始化ServerSocketChannel 并绑定端口 public void bind() throws Exception &#123;...&#125; // 创建 Executor // 创建 Poller 集合(默认单核1个，多核为2个)并依次启动 // 创建 Acceptor(默认1个)并启动 public void startInternal() throws Exception &#123; if (!running) &#123; // 1. 创建 Executor if ( getExecutor() == null ) &#123; createExecutor(); &#125; // 2. 创建启动 poller 线程 pollers = new Poller[getPollerThreadCount()]; for (int i=0; i&lt;pollers.length; i++) &#123; pollers[i] = new Poller(); Thread pollerThread = new Thread(pollers[i], getName() + \"-ClientPoller-\"+i); pollerThread.setPriority(threadPriority); pollerThread.setDaemon(true); pollerThread.start(); &#125; // 3. 启动 acceptor 线程 startAcceptorThreads(); &#125; &#125; @Override protected AbstractEndpoint.Acceptor createAcceptor() &#123; return new Acceptor(); &#125; // NioEndpoint 中实现的抽象类中的 Acceptor如下（省略调整了部分代码） protected class Acceptor extends AbstractEndpoint.Acceptor &#123; @Override public void run() &#123; while (running) &#123; // 如果达到最大连接数则阻塞等待 countUpOrAwaitConnection(); // 4. 等待客户端的连接 SocketChannel socket = serverSock.accept(); if (!setSocketOptions(socket)) &#123; closeSocket(socket); &#125; &#125; &#125; &#125; // 5. protected boolean setSocketOptions(SocketChannel socket) &#123; try &#123; socket.configureBlocking(false); Socket sock = socket.socket(); // 5. 生成 NioChannel NioChannel channel = new NioChannel(socket, bufhandler); // 6. 随机获取一个 poller, 将 NioChannel 注册进去 getPoller0().register(channel); &#125; catch (Throwable t) &#123; // Tell to close the socket return false; &#125; return true; &#125; // 17. NioEndpoint 的 SocketProcessor protected class SocketProcessor extends SocketProcessorBase&lt;NioChannel&gt; &#123; public SocketProcessor(SocketWrapperBase&lt;NioChannel&gt; socketWrapper, SocketEvent event) &#123; super(socketWrapper, event); &#125; @Override protected void doRun() &#123; NioChannel socket = socketWrapper.getSocket(); SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); try &#123; if (handshake == 0) &#123; SocketState state = SocketState.OPEN; // 18. 处理请求 if (event == null) &#123; state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ); &#125; else &#123; state = getHandler().process(socketWrapper, event); &#125; if (state == SocketState.CLOSED) &#123; close(socket, key); &#125; &#125; else if (handshake == -1 ) &#123; getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL); close(socket, key); &#125; else if (handshake == SelectionKey.OP_READ)&#123; socketWrapper.registerReadInterest(); &#125; else if (handshake == SelectionKey.OP_WRITE)&#123; socketWrapper.registerWriteInterest(); &#125; &#125; catch (CancelledKeyException cx) &#123; socket.getPoller().cancelledKey(key); &#125; catch (VirtualMachineError vme) &#123; ExceptionUtils.handleThrowable(vme); &#125; catch (Throwable t) &#123; log.error(\"\", t); socket.getPoller().cancelledKey(key); &#125; finally &#123; socketWrapper = null; event = null; //return to cache if (running &amp;&amp; !paused) &#123; processorCache.push(this); &#125; &#125; &#125; &#125;&#125; 下面我们看一下 Poller 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public class Poller implements Runnable &#123; private Selector selector; private final SynchronizedQueue&lt;PollerEvent&gt; events = new SynchronizedQueue&lt;&gt;(); public Poller() throws IOException &#123; this.selector = Selector.open(); &#125; // 7. public void register(final NioChannel socket) &#123; socket.setPoller(this); NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this); socket.setSocketWrapper(ka); ka.setPoller(this); ka.setReadTimeout(getSocketProperties().getSoTimeout()); ka.setWriteTimeout(getSocketProperties().getSoTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); ka.setReadTimeout(getConnectionTimeout()); ka.setWriteTimeout(getConnectionTimeout()); PollerEvent r = eventCache.pop(); ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. // 7. 创建 PollerEvent 对象， 添加到 events 中，注意这里的 interestOps 为 OP_REGISTER if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); addEvent(r); &#125; @Override public void run() &#123; // Loop until destroy() is called while (true) &#123; boolean hasEvents = false; try &#123; if (!close) &#123; // 8. 依次注册监听事件，select hasEvents = events(); if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; keyCount = selector.selectNow(); &#125; else &#123; // 11. selector.select keyCount = selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; &#125; catch (Throwable x) &#123; continue; &#125; // 如果时间超时后，没有任何事件，则再次执行 events if ( keyCount == 0 ) hasEvents = (hasEvents | events()); // 12. 有关注的事件到来 Iterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null; while (iterator != null &amp;&amp; iterator.hasNext()) &#123; SelectionKey sk = iterator.next(); NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment(); if (attachment == null) &#123; iterator.remove(); &#125; else &#123; iterator.remove(); // 13. 处理对应的事件key processKey(sk, attachment); &#125; &#125;//while //process timeouts timeout(keyCount,hasEvents); &#125;//while getStopLatch().countDown(); &#125; // 9. 依次调用之前插入的每个 event 的 run方法 public boolean events() &#123; boolean result = false; PollerEvent pe = null; for (int i = 0,size = events.size(); i&lt;size &amp;&amp; (pe = events.poll())!=null; i++) &#123; result = true; try &#123; pe.run(); pe.reset(); if (running &amp;&amp; !paused) &#123; eventCache.push(pe); &#125; &#125; catch ( Throwable x ) &#123; log.error(\"\",x); &#125; &#125; return result; &#125; // 14. protected void processKey(SelectionKey sk, NioSocketWrapper attachment) &#123; try &#123; if ( close ) &#123; cancelledKey(sk); &#125; else if ( sk.isValid() &amp;&amp; attachment != null ) &#123; if (sk.isReadable() || sk.isWritable() ) &#123; if ( attachment.getSendfileData() != null ) &#123; processSendfile(sk,attachment, false); &#125; else &#123; unreg(sk, attachment, sk.readyOps()); boolean closeSocket = false; // 14. 如果数据已经准备好，可以进行读取了 if (sk.isReadable()) &#123; // 15. 处理socket, 调用 AbstractEndpoint 中的 processSocket 方法 if (!processSocket(attachment, SocketEvent.OPEN_READ, true)) &#123; closeSocket = true; &#125; &#125; if (!closeSocket &amp;&amp; sk.isWritable()) &#123; if (!processSocket(attachment, SocketEvent.OPEN_WRITE, true)) &#123; closeSocket = true; &#125; &#125; if (closeSocket) &#123; cancelledKey(sk); &#125; &#125; &#125; &#125; else &#123; //invalid key cancelledKey(sk); &#125; &#125; catch ( CancelledKeyException ckx ) &#123; cancelledKey(sk); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); log.error(\"\",t); &#125; &#125;&#125; 接着来看下 PollerEvent 的实现 123456789101112131415161718192021222324252627282930313233343536373839public static class PollerEvent implements Runnable &#123; private NioChannel socket; private int interestOps; private NioSocketWrapper socketWrapper; @Override public void run() &#123; if (interestOps == OP_REGISTER) &#123; try &#123; // 10. 注册一个 OP_READ 事件 socket.getIOChannel().register( socket.getPoller().getSelector(), SelectionKey.OP_READ, socketWrapper); &#125; catch (Exception x) &#123; log.error(sm.getString(\"endpoint.nio.registerFail\"), x); &#125; &#125; else &#123; final SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); try &#123; if (key == null) &#123; socket.socketWrapper.getEndpoint().countDownConnection(); ((NioSocketWrapper) socket.socketWrapper).closed = true; &#125; else &#123; final NioSocketWrapper socketWrapper = (NioSocketWrapper) key.attachment(); if (socketWrapper != null) &#123; int ops = key.interestOps() | interestOps; socketWrapper.interestOps(ops); key.interestOps(ops); &#125; else &#123; socket.getPoller().cancelledKey(key); &#125; &#125; &#125; catch (CancelledKeyException ckx) &#123; try &#123; socket.getPoller().cancelledKey(key); &#125; catch (Exception ignore) &#123;&#125; &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://zhengw-tech.com/tags/tomcat/"}]},{"title":"Tomcat整体结构概览","slug":"tomcat-1","date":"2020-01-12T07:14:16.000Z","updated":"2021-04-17T14:50:06.970Z","comments":true,"path":"2020/01/12/tomcat-1/","link":"","permalink":"https://zhengw-tech.com/2020/01/12/tomcat-1/","excerpt":"这里主要介绍一下 Tomcat 的整体设计结构 整体结构Tomcat 的整体结构如下 主要分为两大部分，连接器和容器","text":"这里主要介绍一下 Tomcat 的整体设计结构 整体结构Tomcat 的整体结构如下 主要分为两大部分，连接器和容器 连接器ProtocolHandlerEndPointEndPoint 负责进行 TCP 监听连接，解析之后将消息转发给Processor ProcessorProcessor 进行应用层对应的解析，如HTTP1.1协议，为请求和响应生成对应的Tomcat 的 Request 和 Response 对象 AdapterAdapter 主要负责将 Tomcat 的 Request 和 Response对象转换为 Servlet 的 ServletRequest 和 ServletResponse 对象 容器容器中也是分层的，从 Engine -&gt; Host -&gt; Context -&gt; Wrapper，消息进行层层对位转发 Server.xml下面看一个具体 Tomcat 的 serverl.xml配置信息对应一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Server port=\"8005\" shutdown=\"SHUTDOWN\"&gt; &lt;Listener className=\"org.apache.catalina.startup.VersionLoggerListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" /&gt; &lt;Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" /&gt; &lt;Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" /&gt; &lt;/GlobalNamingResources&gt; &lt;!-- 对应图中最外层的Service --&gt; &lt;Service name=\"Catalina\"&gt; &lt;!-- 对应图中上半部分的连接器 --&gt; &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; &lt;!-- 支持NIO的连接器 --&gt; &lt;!-- &lt;Connector port=\"8443\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" maxThreads=\"150\" SSLEnabled=\"true\"&gt; &lt;SSLHostConfig&gt; &lt;Certificate certificateKeystoreFile=\"conf/localhost-rsa.jks\" type=\"RSA\" /&gt; &lt;/SSLHostConfig&gt; &lt;/Connector&gt; --&gt; &lt;!-- AJP协议的连接器 --&gt; &lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;!-- 表示图中下半部分的最外层的 Engine --&gt; &lt;Engine name=\"Catalina\" defaultHost=\"localhost\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/&gt; &lt;/Realm&gt; &lt;!-- 对应图中下半部分的 Host --&gt; &lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt; &lt;Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log\" suffix=\".txt\" pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://zhengw-tech.com/tags/tomcat/"}]},{"title":"Java字节码结构","slug":"java-class","date":"2019-12-21T02:09:47.000Z","updated":"2022-02-07T05:08:05.703Z","comments":true,"path":"2019/12/21/java-class/","link":"","permalink":"https://zhengw-tech.com/2019/12/21/java-class/","excerpt":"我们都知道java实现跨平台靠的是虚拟机技术，将源文件编译成与操作系统无关的，只有虚拟机能识别并执行的字节码文件，由各个操作系统上的jvm来负责执行，屏蔽了底层具体的操作系统。这里我们就来认识一下这个只有jvm才认识的字节码文件的真实样子。 为了节省空间，类文件中没有任何分隔符，各个数据项都是一个挨着一个紧凑排列的，所以其中无论是顺序还是数量等都是严格规定的，哪个字节代表什么含义，长度是多少，先后顺序如何，都不允许改变。下面我们先看一下类文件的整体结构：","text":"我们都知道java实现跨平台靠的是虚拟机技术，将源文件编译成与操作系统无关的，只有虚拟机能识别并执行的字节码文件，由各个操作系统上的jvm来负责执行，屏蔽了底层具体的操作系统。这里我们就来认识一下这个只有jvm才认识的字节码文件的真实样子。 为了节省空间，类文件中没有任何分隔符，各个数据项都是一个挨着一个紧凑排列的，所以其中无论是顺序还是数量等都是严格规定的，哪个字节代表什么含义，长度是多少，先后顺序如何，都不允许改变。下面我们先看一下类文件的整体结构： Class文件结构 其中常量、接口、字段、方法和属性在其中按各自的结构紧密排列，个数由其前面的数量字段决定。同时类文件中最小单位为1个字节，超过一个字节的数据以大端方式存储。 下面依次介绍其中的每个部分： 魔数魔数是用来确定文件的类型是否是class文件，因为只靠文件扩展名来确定文件类型并不可靠。 这个魔数占文件的开始4个字节，为CA FE BA BE。（注意：这里的字面代表的是十六进制数，而不是ASCII码） 版本号接下来的4个字节为class文件版本号，其中前两个字节表示的是次版本号，后两个字节表示的是主版本号（从45开始）。 虚拟机可以向下兼容运行class文件，但不能运行高于其版本的class文件。 常量池由于常量池中的常量数量是不确定的，所以在常量池的入口需要有两个字节用来代表常量池容量计数值（常量池索引从1开始）。 一共有14种常量类型，有着各自对应的结构，但开始的一个字节同样都是表示标志位，用来区分不同的类型。 下面为14种常量的具体类型和对应的标志位： 每种类型的结构如下（其中u1表示1个字节，u2表示2个字节，其他同理）： 读取常量池的时候首先读取标志位，判断常量类型，就可以知道对应的结构，获取对应的信息了。 访问标志 常量池之后的两个字节代表访问标志，即这个class是类还是接口，是否为public等的信息。不同的含义有不同的标志值（没有用到的标志位一律为0。），具体信息如下： 类索引类索引占两个字节，分别指向常量池中的CONSTANT_Class_info类型的常量，这个类型的常量结构见常量池中的图表，其中包含一个指向全限定名常量项的索引。 父类索引因为java只允许单继承，所以只有一个父类，具体内容同上-类索引。 接口索引接口索引开始两个字节用来表示接口的数量，之后的每两个字节表示一个接口索引，用法同类索引与父类索引。 字段字段用于描述接口或者类中声明的变量，包括类级变量以及实例变量，但不包括局部变量。 字段域的开始两个字节表示字段数量，之后为紧密排列的字段结构体数据，其结构如下： 其中的字段和方法的描述符，对于字段来说用来描述字段的数据类型；而对于方法来说，描述的就是方法的参数列表（包括数量、类型以及顺序）和返回值，这个描述顺序也是固定的，必须是参数列表在前，返回值在后，参数列表必须放在一组小括号内。同时为了节省空间，各种数据类型都使用规定的一个字母来表示，具体如下： 对象使用L加上对象的全限定名来表示，而数组则是在每一个维度前添加一个”[“来描述。 属性表在之后进行介绍。 方法class文件中对方法的描述与以前对字段的描述几乎采用了完全一致的方式，唯一的区别就是访问类型不完全一致。 属性java7中预定义了21项属性，具体内容限于篇幅不再列出。 对于每个属性的结构，没有特别严格的要求，并且可以自定义属性信息，jvm运行时会忽略不认识的属性。 符合规范的属性表基本结构如下： 其中前两个字节为指向常量池中的CONSTANT_Utf8_info类型的属性名称，之后4个字节表示属性值所占用的位数，最后就是具体属性了。 其中有一个比较重要的名称为「Code」的属性为方法的代码，即字节码指令。 Code属性表结构如下： 以上只列出了一些Class文件最基本的结构，如有错误欢迎指正。 另：目前准备写一个基于字节码，分析方法（类、包）间的调用关系工具，项目地址：https://github.com/zavier/jclass-relation ，欢迎有兴趣的同学PR","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"Spring 事件及异步方法使用","slug":"practical-spring-function","date":"2019-11-30T04:06:10.000Z","updated":"2023-06-21T00:22:52.300Z","comments":true,"path":"2019/11/30/practical-spring-function/","link":"","permalink":"https://zhengw-tech.com/2019/11/30/practical-spring-function/","excerpt":"Spring 不仅为我们提供了IOC , AOP功能外，还在这个基础上提供了许多的功能，我们用的最多的可能就是Spring MVC了吧，但是让我们来看下spring-context包，其中包含了缓存、调度、校验功能等等 这里主要想介绍一下Spring提供的观察者模式实现(事件发布监听)及异步方法执行，这些功能也都是基于AOP实现的","text":"Spring 不仅为我们提供了IOC , AOP功能外，还在这个基础上提供了许多的功能，我们用的最多的可能就是Spring MVC了吧，但是让我们来看下spring-context包，其中包含了缓存、调度、校验功能等等 这里主要想介绍一下Spring提供的观察者模式实现(事件发布监听)及异步方法执行，这些功能也都是基于AOP实现的 Spring 事件观察者模式大家都了解，它可以解耦各个功能，但是自己实现的话比较麻烦，Spring为我们提供了一种事件发布机制，可以按需要发布事件，之后由监听此事件的类或方法来执行各自对应的功能，代码互相不影响，以后修改订单后续的逻辑时不会影响到订单创建，有点类似于使用MQ的感觉～ 比如在配置中心apollo项目中，在portal创建了app后会发送app创建事件，监听此事件的逻辑处将此消息同步到各个环境的adminsevice中，大家有兴趣可以看下相关代码 现在我们来看看具体如何使用：假设一个下单场景，订单创建成功后可能有一些后续逻辑要处理，但是和创建订单本身没有关系，此时就可以在创建订单完成后，发送一个消息，又相应部分的代码进行监听处理，避免代码耦合到一起 首先创建对应的事件 1234567891011121314151617// 订单创建事件，需要继承 ApplicationEvent（不是必须，也支持不继承此类）public class OrderCreatedEvent extends ApplicationEvent &#123; private String orderSn; public OrderCreatedEvent(Object source) &#123; super(source); &#125; public OrderCreatedEvent(Object source, String orderSn) &#123; super(source); this.orderSn = orderSn; &#125; public String getOrderSn() &#123; return this.orderSn; &#125;&#125; 现在还需要一个事件发布者和监听者，创建一下 12345678910111213141516@Servicepublic class OrderService &#123; private final ApplicationEventPublisher applicationEventPublisher; public OrderService(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; public void createOrder(String orderSn) &#123; //todo 创建订单的逻辑 // 发送创建订单成功的消息 applicationEventPublisher.publishEvent(new OrderCreatedEvent(this, orderSn)); &#125;&#125; 123456789@Componentpublic class OrderEventListener &#123; @EventListener public void orderCreatedListener(OrderCreatedEvent orderCreatedEvent) &#123; System.out.println(\"listen orderSn:\" + orderCreatedEvent.getOrderSn() + \" created\"); //todo 其他订单后处理，如通知其他系统等 &#125;&#125; 因为这里只是一个简单的例子，所以就用配置文件+main方法来执行了 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:component-scan base-package=\"com.zavier.spring\" /&gt;&lt;/beans&gt; 12345678910public class Main &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"spring.xml\"); OrderService orderService = applicationContext.getBean(OrderService.class); orderService.createOrder(\"20191130123\"); applicationContext.close(); &#125;&#125; 这时我们看下控制台，会打印出如下内容，证明监听者确实收到了消息 1listen orderSn:20191130123 created 简单的事件发布就完成了，其中的其他复杂逻辑由Spring替我们处理了 这里我们要注意一点：发布和监听后处理的逻辑是在一个线程中执行的，不是异步执行 异步方法有时候我们为了提高响应速度，有些方法可以异步去执行，一般情况下我们可能是手动将方法调用提交到线程池中去执行，但是Spring 为我们提供了简化的写法，在开启了异步情况下，不用修改代码，只使用注解即可完成此功能 下面来看下具体实现（例子中提供了全局统一的线程池），我们接着上面的例子 添加如下配置(此处@slf4j使用了lombok的注解) 1234567891011121314151617181920212223@Slf4j@Configuration@EnableAsyncpublic class AsyncConfig implements AsyncConfigurer &#123; @Override public Executor getAsyncExecutor() &#123; // 这里的线程池可以使用业务中已经定义好的，此处只是例子 ExecutorService executorService = Executors.newFixedThreadPool(5); return executorService; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; // 执行过程中的异常捕获处理 return new AsyncUncaughtExceptionHandler() &#123; @Override public void handleUncaughtException(Throwable throwable, Method method, Object... objects) &#123; log.error(\"async execute error, method:&#123;&#125;, param:&#123;&#125;\", method.getName(), JSON.toJSONString(objects), throwable); &#125; &#125;; &#125;&#125; 这时只需要在要异步执行的方法上添加@Async注解即可异步执行, 如 1234567891011@Slf4j@Componentpublic class OrderEventListener &#123; @Async // 此注解 @EventListener public void orderCreatedListener(OrderCreatedEvent orderCreatedEvent) &#123; log.info(\"orderCreatedListener threadId:&#123;&#125;\", Thread.currentThread().getId()); log.info(\"listen orderSn:\" + orderCreatedEvent.getOrderSn() + \" created\"); //todo 其他订单后处理，如通知其他系统等 &#125;&#125; 为了验证结果，可以在orderService发送处和事件监听代码中添加日志，打印当前所在的线程，会发现它们并不是同一个线程，大家可以自行打印看下 注意：如果方法需要返回值的时候，需要让方法返回Future 注解实现可参考AsyncExecutionInterceptor类， 同时异步方法也可使用CompletableFuture异步编排实现","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"},{"name":"eventbus","slug":"eventbus","permalink":"https://zhengw-tech.com/tags/eventbus/"}]},{"title":"Spring AOP 使用及浅析","slug":"spring-aop","date":"2019-11-28T04:28:10.000Z","updated":"2022-09-17T06:52:02.818Z","comments":true,"path":"2019/11/28/spring-aop/","link":"","permalink":"https://zhengw-tech.com/2019/11/28/spring-aop/","excerpt":"看过了前面的Spring Beans相关的 IOC 功能, 接下来我们来看看 AOP 是如何实现的 我们都知道 AOP 是通过动态代理来实现的, 但是代理这一步是如何实现的呢? 其实就是之前提到过的, 在Spring Bean的创建过程中, 实现BeanPostProcessor的接口可以对创建好的Bean进行修改替换等操作 123456789protected Object initializeBean(String beanName, Object bean, RootBeanDefinition mbd) &#123; invokeAwareMethods(beanName, bean); Object wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); invokeInitMethods(beanName, wrappedBean, mbd); // 依次执行beanFactory中所有实现BeanPostProcessor的后置方法,对Bean进行修改(*AOP创建返回代理处*) wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); return wrappedBean;&#125;","text":"看过了前面的Spring Beans相关的 IOC 功能, 接下来我们来看看 AOP 是如何实现的 我们都知道 AOP 是通过动态代理来实现的, 但是代理这一步是如何实现的呢? 其实就是之前提到过的, 在Spring Bean的创建过程中, 实现BeanPostProcessor的接口可以对创建好的Bean进行修改替换等操作 123456789protected Object initializeBean(String beanName, Object bean, RootBeanDefinition mbd) &#123; invokeAwareMethods(beanName, bean); Object wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); invokeInitMethods(beanName, wrappedBean, mbd); // 依次执行beanFactory中所有实现BeanPostProcessor的后置方法,对Bean进行修改(*AOP创建返回代理处*) wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); return wrappedBean;&#125; 下面来具体看一下实现方式 Spring AOP的基本接口是 Advisor, 它持有一个 AOP Advice「在joinpoint处要执行的增强行为」, 同时还持有一个决定 Advice是否适用的过滤器, 如pointcut; 也就是说 Advisor决定是否要对某个方法进行增强以及增强的具体逻辑实现是什么 还有一个我们需要注意的接口就是Interceptor, 这个接口继承了Advice, 也就是说它是用来对方法进行修改增强的, 它还有一些子类, 如MethodBeforeAdviceInterceptor用来在方法执行前进行处理, MethodInterceptor用来在方法执行前后进行自定义逻辑处理 当定义好了 Advisor后, 需要一个类来负责在创建bean的时候用所有的Advisor进行匹配并生成对应的代理类返回, 这个类就是AbstractAutoProxyCreator的实现类, 它继承了BeanPostProcessor接口,在创建bean的过程中进行拦截处理 1234567891011121314151617181920212223242526272829303132333435363738// ******** AbstractAutoProxyCreator *********@Overridepublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; // 对类进行代理包装 return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125;protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 如果有匹配的advice,则创建代理 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 现在写一个例子代码来感受一下, 验证一下前面的结论 首先创建一个正常的服务 12345public class DemoService &#123; public void service() &#123; System.out.println(\"this is demoService\"); &#125;&#125; 创建Advice类 123456789public class LogAdvice implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; long st = System.nanoTime(); Object result = invocation.proceed(); System.out.println(\"cost time: \" + (System.nanoTime() - st)); return result; &#125;&#125; 定义配置文件 12345678910111213&lt;bean id=\"logAdvice\" class=\"com.demo.spring.advice.LogAdvice\"/&gt;&lt;bean id=\"demoService\" class=\"com.demo.spring.service.DemoService\"/&gt;&lt;!-- 定义Advisor --&gt;&lt;bean id=\"advisor\" class=\"org.springframework.aop.support.RegexpMethodPointcutAdvisor\"&gt; &lt;!-- 定义使用的advice --&gt; &lt;property name=\"advice\" ref=\"logAdvice\"/&gt; &lt;!-- 定义匹配方式 --&gt; &lt;property name=\"pattern\" value=\"com.demo.spring.service.*\" /&gt;&lt;/bean&gt;&lt;!-- 定义AspectJAwareAdvisorAutoProxyCreator Bean, 用来在创建bean实例时匹配生成代理类 --&gt;&lt;bean class=\"org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator\"/&gt; 测试方法如下: 1234567891011public class Main &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"spring.xml\"); DemoService demoService = applicationContext.getBean(DemoService.class); demoService.service(); &#125;&#125;// 结果// this is demoService// cost time: 17346041 当然我们也可以使用aop标签来简化配置文件 123456&lt;aop:config proxy-target-class=\"false\"&gt; &lt;aop:pointcut id=\"service\" expression=\"execution(* com.demo.spring.service..*(..)))\"/&gt; &lt;aop:advisor advice-ref=\"logAdvice\" pointcut-ref=\"service\"/&gt;&lt;/aop:config&gt; 执行结果是一样的, 只是这种配置会自动注册AspectJAwareAdvisorAutoProxyCreator Bean, Advisor等, 具体可以参数 AopNamespaceHandler类 参考资料: Spring AOP 源码解析","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"}]},{"title":"流计算-Flink笔记","slug":"streaming-flink","date":"2019-11-19T07:30:32.000Z","updated":"2021-04-17T14:50:06.969Z","comments":true,"path":"2019/11/19/streaming-flink/","link":"","permalink":"https://zhengw-tech.com/2019/11/19/streaming-flink/","excerpt":"一种被设计来处理无穷数据集的数据处理系统引擎 对实时产生的数据进行实时统计分析 电商大促时，统计当前下单量、金额 实时统计 App 中的埋点数据等 流计算相比批处理需要切分为窗口才能进行分组聚合处理 同时需要解决如下两个问题 正确性/完整性 exactly-once 处理无序、延迟数据的能力","text":"一种被设计来处理无穷数据集的数据处理系统引擎 对实时产生的数据进行实时统计分析 电商大促时，统计当前下单量、金额 实时统计 App 中的埋点数据等 流计算相比批处理需要切分为窗口才能进行分组聚合处理 同时需要解决如下两个问题 正确性/完整性 exactly-once 处理无序、延迟数据的能力 Flink对流计算提供的支持 同时支持高吞吐、低延迟、高性能(spark支持高吞吐和高性能，strom支持低延迟高性能) 支持事件时间概念 支持有状态的计算 支持高度灵活的窗口 基于轻量级分布式快照实现容错 基于JVM实现独立的内存管理 save point（保存点） 流计算的流程 窗口在处理无限流数据时, 如果需要对数据进行分组聚合操作,实时获取结果时, 则需要将数据分段到不同的窗口中,分别进行计算输出 窗口可分为 滚动窗口(时间驱动、数量驱动) 有固定间隔相等的连续窗口,每个窗口不会重复, 如每5分钟统计一次或每5个数据计算一次 滑动窗口(时间驱动、数量驱动) 有固定间隔相等的连续窗口,每个窗口之间可能有重叠,如每5分钟,统计前20分钟数据 会话窗口 通过数据的间隔时间(session gap)来区分窗口, 如数据间隔5分钟则开一个新的会话窗口 全局窗口 所有的数据都在一个窗口中, 此窗口需要自己出发trigger来进行计算 窗口数据计算处理在窗口结束,触发trigger来进行计算时可以使用如下函数 ReduceFunction 合并 AggregateFunction 高级合并 FoldFunction 与外部元素合并(@Deprecated,使用AggregateFunction) ProcessWindowFunction 对窗口中的所有元素一起进行计算（耗性能） 数据清理(可选)对进入windowFunction前后的数据进行剔除处理 窗口使用API123456789101112131415161718192021Keyed Windowsstream .keyBy(...) &lt;- keyed versus non-keyed windows .window(...) &lt;- required: \"assigner\" [.trigger(...)] &lt;- optional: \"trigger\" (else default trigger) [.evictor(...)] &lt;- optional: \"evictor\" (else no evictor) [.allowedLateness(...)] &lt;- optional: \"lateness\" (else zero) [.sideOutputLateData(...)] &lt;- optional: \"output tag\" (else no side output for late data) .reduce/aggregate/fold/apply() &lt;- required: \"function\" [.getSideOutput(...)] &lt;- optional: \"output tag\"Non-Keyed Windowsstream .windowAll(...) &lt;- required: \"assigner\" [.trigger(...)] &lt;- optional: \"trigger\" (else default trigger) [.evictor(...)] &lt;- optional: \"evictor\" (else no evictor) [.allowedLateness(...)] &lt;- optional: \"lateness\" (else zero) [.sideOutputLateData(...)] &lt;- optional: \"output tag\" (else no side output for late data) .reduce/aggregate/fold/apply() &lt;- required: \"function\" [.getSideOutput(...)] &lt;- optional: \"output tag\" 时间为了应对无序、延迟数据, 保证数据的顺序,就需要有一个用于表示数据的时间,平时用的比较多的是处理的时间 但是由于流数据可能的延迟等原因, 如果数据有前后相关性,那么使用处理时间可能就会有问题, flink把时间分类为如下三种: EventTime 事件发生事件 Ingestion Time 事件进入flink的时间 Processing Time 事件处理时间 如果使用EventTime即时间发生时间时, 除了要提供对应的方法来从数据中取出发生时间外, 还需要提供一个获取WaterMark水印的功能, 水印也是一个时间戳, 用于表示在此时间之前的数据已经全部到齐 同时, 时间窗口的计算触发也是通过判断水印时间是否大于窗口结束时间, 所以这时我们就可以使用 watermark 来让窗口延迟计算时间, 容忍迟到的数据 如果我们不想延迟窗口的计算, 又想容忍延迟的数据, 则可以使用如下方法 123456OutputTag&lt;String&gt; outputTag = new OutputTag&lt;String&gt;(\"late-date\");SingleOutputStreamOperator&lt;String&gt; max = source.timeWindowAll(Time.seconds(10)) .allowedLateness(Time.hours(1)) // 容忍延迟的时间 .sideOutputLateData(outputTag) // 延迟数据的容器 .max(1);DataStream&lt;String&gt; sideOutput = max.getSideOutput(outputTag); // 处理延迟的数据 状态对于处理过程中的状态数据, 分为了 Keyed State(和key有关) 与 Operator State(和key无关) flink还提供了managed state来帮助用户简化使用, 在发生异常时会进行持久化, 之后可通过保存的数据进行任务恢复, 同时用户也可以使用row state, 自己实现序列化等操作 Managed State有如下几种 ValueState[T] ListState[T] ReducingState[T] AggregatingState[IN, OUT] MapState[UK,UV]","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"flink","slug":"flink","permalink":"https://zhengw-tech.com/tags/flink/"}]},{"title":"Dubbo扩展点加载使用简述","slug":"dubbo-spi","date":"2019-11-09T13:45:19.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/11/09/dubbo-spi/","link":"","permalink":"https://zhengw-tech.com/2019/11/09/dubbo-spi/","excerpt":"扩展点加载机制主要是为了实现接口和实现的解耦，接口的具体实现并不在代码中指定，而是通过通过外部配置实现，Dubbo的扩展点加载是对JDK的SPI扩展点加强而来，大家如果不了解JDK的SPI也没有关系，这里我们主要来看一下Dubbo的实现 在Dubbo的实现中，主要有三个注解，@SPI、@Adaptive和@Activate，下面我们来结合例子分别看一下它们的使用","text":"扩展点加载机制主要是为了实现接口和实现的解耦，接口的具体实现并不在代码中指定，而是通过通过外部配置实现，Dubbo的扩展点加载是对JDK的SPI扩展点加强而来，大家如果不了解JDK的SPI也没有关系，这里我们主要来看一下Dubbo的实现 在Dubbo的实现中，主要有三个注解，@SPI、@Adaptive和@Activate，下面我们来结合例子分别看一下它们的使用 首先我们来定义一个接口和几个对应的实现 123456// @SPI注解表示这是一个扩展点，可以有不同的实现// 指定实现时，其中的名字需要与配置文件中的key相同@SPI(\"simple\")public interface DemoService &#123; String echo(URL url, String s);&#125; 123456public class SimpleServiceImpl implements DemoService &#123; @Override public String echo(URL url, String s) &#123; return \"SimpleService\"; &#125;&#125; 123456public class ComplexServiceImpl implements DemoService &#123; @Override public String echo(URL url, String s) &#123; return \"ComplexService\"; &#125;&#125; 使用时，我们需要在类路径下的META-INF/dubbo/或META-INF/dubbo/internal/路径下(也可以在java spi的/META-INF/services/下)创建与接口全路径相同的文件名，在其中以key-value形式指定各个实现类的全路径及对应名称（名称可以自己随意起），对于上面的例子我们可以这样写 123## 文件名：com.test.spi.DemoServicesimple=com.test.spi.SimpleServiceImplcomplex=com.test.spi.ComplexServiceImpl 由于上面我们在接口的SPI注解上指定了simple的实现，即SimpleServiceImpl实现类，写了测试类来验证一下 12345678@Testpublic void testDefaultExtension() &#123; final DemoService defaultExtension = ExtensionLoader.getExtensionLoader(DemoService.class) .getDefaultExtension(); assertTrue(defaultExtension instanceof SimpleServiceImpl); final String echo = defaultExtension.echo(null, null); assertSame(\"SimpleService\", echo);&#125; 测试通过～， 简单的使用就是这样，如果要切换不同的实现，修改@SPI注解中的值为对应实现即可 但这时有一个问题，就是这样我们还是在代码里写死了具体的实现，如果我们想在运行时再决定使用哪一个实现该怎么半？这时就要靠@Adaptive注解了，我们来看一下 其实我们要动态选择的其实不是实现类，而是实现类的方法，所以现在我们将接口修改如下 123456@SPI(\"simple\")public interface DemoService &#123; @Adaptive(\"service\") // 和上面的区别在这里 String echo(URL url, String s);&#125; 到这里，不得不提一下dubbo中的URL类，它是dubbo中的配置关键类，几乎所有的配置想都是在其中以参数键值对的形式存在，SPI的配置当然也不例外 我们在@Adaptive的注解中指定了一个值（可以任意指定，也可不指定，不过不指定则是对应类名的转换，如DemoService则转为 demo.service）这个值有什么用呢，它会从URL中找到和它一样的key对应的value值，这个value值就是要使用的实现类的key(配置文件中设置的key) 上面我们指定了@Adaptive值为”service”, 如果url中有”?service=complex”,那么执行时则是使用complex=com.test.spi.ComplexServiceImpl对应的类来执行 如果没有找到怎么办呢？那就使用SPI注解中的实现–”simple”做为默认实现 Dubbo处理有@Adaptive注解的类时，会默认使用javassist生成一个类，对应上面的类，生成的类内容大致简化如下DemoService$Adaptive 123456789public class DemoService$Adaptive implements com.test.spi.DemoService &#123; public String echo(URL arg0, String arg1) &#123; URL url = arg0; // 调用方法时，会通过URL中的参数值，获取对应类来执行 String extName = url.getParameter(\"service\", \"simple\"); DemoService extension = (DemoService)ExtensionLoader.getExtensionLoader(DemoService.class).getExtension(extName); return extension.echo(arg0, arg1); &#125;&#125; 看了这段代码，相信大家也明白了这个动态功能的实现，下面我们写一个测试类来验证一下 12345678910@Testpublic void testAdaptive() &#123; final DemoService adaptiveExtension = ExtensionLoader.getExtensionLoader(DemoService.class) .getAdaptiveExtension(); // 注意这处的不同 // service = complex // URL构造器 String protocol, String host, int port, String path, String... pairs final URL url = new URL(\"\", \"\", 100, \"\", \"service\", \"complex\"); final String echo = adaptiveExtension.echo(url, null); assertSame(\"ComplexService\", echo);&#125; 到这里其实已经差不多够用了，但是还有一种情况，就是即使我们使用了@Adaptive注解，但是它只能选择一个类来执行，如果我们想匹配多个，并让它们都能得到执行怎么办呢？（如Dubbo中的过滤器）这时就需要@Activate出马了, 我们来修改一下代码 先新创建两个实现类，并添加@Activate注解 1234567@Activate(group = \"act\", value = \"actone\", order = 1)public class ActivateOneServiceImpl implements DemoService &#123; @Override public String echo(URL url, String s) &#123; return \"ActivateOneService\"; &#125;&#125; 1234567@Activate(group = \"act\", value = \"actTwo\", order = 2)public class ActivateTwoServiceImpl implements DemoService &#123; @Override public String echo(URL url, String s) &#123; return \"ActivateTwoService\"; &#125;&#125; 将它们添加到配置文件中去，这时的配置文件如下 1234simple=com.test.spi.SimpleServiceImplcomplex=com.test.spi.ComplexServiceImplactone=com.test.spi.ActivateOneServiceImplacttwo=com.test.spi.ActivateTwoServiceImpl 同样的，我们写个测试类来测试一下 12345678910111213@Testpublic void testActivateTwo() &#123; // select = actone,acttwo(resources中的配置key) final URL url = new URL(\"\", \"\", 100, \"\", \"select\", \"actone,acttwo\"); final List&lt;DemoService&gt; activateExtension = ExtensionLoader.getExtensionLoader(DemoService.class) // 第二个参数执行获取url中的配置key是什么，第三个参数为执行的group .getActivateExtension(url, \"select\", \"act\"); assertEquals(2, activateExtension.size()); final DemoService demoService1 = activateExtension.get(0); assertTrue(demoService1 instanceof ActivateOneServiceImpl); final DemoService demoService2 = activateExtension.get(1); assertTrue(demoService2 instanceof ActivateTwoServiceImpl);&#125; 好了，基本的内容就介绍到这里，这里只是简单介绍了一下使用，还有许多内容没有说到，比如 自动注入: 只支持setter方式注入 自动包装：在定义接口实现时，构造器仍然为一个此接口的参数，这时dubbo会认为它是一个wrapper（可以理解设计模式中的装饰器模式），对于此接口所有类的实现，都会通过这个包装类包装后返回 @Adaptive中的注解值可以指定多个，执行时会依次进行匹配 @Activate的匹配方式还有许多，不止是上面提到的那种，比如URL值的参数键和@Activate中的value匹配上的话也会激活 等等等等，大家有兴趣的话可以继续研究下去","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"dubbo","slug":"dubbo","permalink":"https://zhengw-tech.com/tags/dubbo/"}]},{"title":"自定义扩展线程池","slug":"customize-thread-pool-executor","date":"2019-10-26T17:14:42.000Z","updated":"2023-04-09T13:44:37.072Z","comments":true,"path":"2019/10/27/customize-thread-pool-executor/","link":"","permalink":"https://zhengw-tech.com/2019/10/27/customize-thread-pool-executor/","excerpt":"线程池的基本使用Executors框架提供的创建线程池的方法 123456// 固定线程数量的线程池Executors.newFixedThreadPool(5);// 对于添加的任务，如果有线程可用则使用其执行，否则就创建新线程Executors.newCachedThreadPool();// 创建只有一个线程的线程池Executors.newSingleThreadExecutor(); 它们内部实现都是使用了ThreadPoolExecutor，平时使用时我们最好是直接使用ThreadPoolExecutor，根据实际情况提供如下7个参数对线程池进行定义使用 配置参数 1234567int corePoolSize, // 核心线程数int maximumPoolSize, // 最大线程数long keepAliveTime, // 超出核心数线程的最大空闲存活时间TimeUnit unit, // 空闲存活时间的时间单位BlockingQueue&lt;Runnable&gt; workQueue, // 任务队列ThreadFactory threadFactory, // 线程工厂，可以在此设置线程是否为守护线程等RejectedExecutionHandler handler // 饱和策略，任务队列满且线程数达到最大线程数时触发","text":"线程池的基本使用Executors框架提供的创建线程池的方法 123456// 固定线程数量的线程池Executors.newFixedThreadPool(5);// 对于添加的任务，如果有线程可用则使用其执行，否则就创建新线程Executors.newCachedThreadPool();// 创建只有一个线程的线程池Executors.newSingleThreadExecutor(); 它们内部实现都是使用了ThreadPoolExecutor，平时使用时我们最好是直接使用ThreadPoolExecutor，根据实际情况提供如下7个参数对线程池进行定义使用 配置参数 1234567int corePoolSize, // 核心线程数int maximumPoolSize, // 最大线程数long keepAliveTime, // 超出核心数线程的最大空闲存活时间TimeUnit unit, // 空闲存活时间的时间单位BlockingQueue&lt;Runnable&gt; workQueue, // 任务队列ThreadFactory threadFactory, // 线程工厂，可以在此设置线程是否为守护线程等RejectedExecutionHandler handler // 饱和策略，任务队列满且线程数达到最大线程数时触发 使用 12345678910final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 10, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(100), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; final Thread thread = new Thread(r); thread.setDaemon(true); return thread; &#125;&#125;);threadPoolExecutor.executor(() -&gt; System.out.println(\"execute\")); 线程池监控对于当前线程池中的线程数量，执行总任务数等信息也可以通过ThreadPoolExecutor提供的对应方法来获取 1234567891011getCorePoolSize() // 获取设置的核心线程数getKeepAliveTime(TimeUnit unit) // 获取设置的非核心线程存活时间getMaximumPoolSize() // 获取设置的最大线程数getPoolSize() // 获取当前任务队列中的任务数量getLargestPoolSize() // 获取曾经达到的最大线程数getActiveCount() // 获取当前正在执行任务的线程数getTaskCount() // 获取当前的任务数（包括正在执行的和队列中等待的）getCompletedTaskCount() // 获取执行完成的任务数getQueue() // 获取任务队列getQueue().size() // 获取任务队列中的任务数量getQueue().remainingCapacity() // 获取任务队列的当前剩余空间 可以通过这些方法来对线程池的运行状态进行监控 线程池参数动态调整线程池参数的设置比较复杂，在初始时很难准确的配置，所以可以在初始配置后根据具体的运行情况进行动态更新 ThreadPoolExecutor 也提供了相关的方法可以对初始化设置的参数进行变更 12345678910// 设置核心线程数量setCorePoolSize(int corePoolSize);// 设置最大线程数量setMaximumPoolSize(int maximumPoolSize);// 设置线程存活时间setKeepAliveTime(long time, TimeUnit unit);// 设置拒绝策略setRejectedExecutionHandler(RejectedExecutionHandler handler);// 设置线程池工厂setThreadFactory(ThreadFactory threadFactory); 扩展ThreadPoolExecutor上面的信息正常使用已经足够，但是如果我们想要线程中任务的执行时间(如果要获取执行时间也可以在每个任务类中自己实现)等统计信息时则需要我们来扩展线程池，ThreadPoolExecutor 提供了 beforeExecute, afterExecute和 terminated方法供子类实现 如果我们想要统计每次任务执行的时间，则可以继承 ThreadPoolExecutor 12345678910111213141516171819202122232425262728293031323334353637383940// 来自《Java并发编程实战》public class TimingThreadPool extends ThreadPoolExecutor &#123; // 省略构造函数 private final ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;&gt;(); private final LongAdder numTasks = new LongAdder(); private final LongAdder totalTime = new LongAdder(); @Override protected void beforeExecute(Thread t, Runnable r) &#123; super.beforeExecute(t, r); startTime.set(System.nanoTime()); &#125; @Override protected void afterExecute(Runnable r, Throwable t) &#123; try &#123; final long endTime = System.nanoTime(); final long taskTime = endTime - startTime.get(); numTasks.add(9223372036854775807L); totalTime.add(taskTime); // 打印任务执行时间 System.out.println(String.format(\"Thread %s: end %s, time=%dns\", Thread.currentThread().getName(), r, taskTime)); &#125; finally &#123; super.afterExecute(r, t); &#125; &#125; @Override protected void terminated() &#123; try &#123; // 打印所有任务的平均执行时间 System.out.println(String.format(\"Terminated: avg time=%dns\", totalTime.longValue() / numTasks.longValue())); &#125; finally &#123; super.terminated(); &#125; &#125;&#125; 如果使用Spring 提供的 ThreadPoolTaskExecutor，其也提供了 TaskDecorator 可以对任务进行装饰修改 思考虽然使用线程池可以避免每次创建线程的开销，并且可以控制线程的使用总数量，但是线程池配置不当也会造成一些问题，如队列堆积过多造成内存使用过大，如果是外部的请求可能还会导致大量的接口超时，线程池设置太小则会导致外部请求拒绝等等 所以一般公司内部会提供线程池监控、动态调整线程池参数等组件，但是是否可以有类似自动动态调整的工具，可以根据预先配置的如队列最大等待时间等，结合统计的信息，来自动调整线程池的参数，而不需要人工的参与呢？比如 JVM 中 G1 可以根据设置的预期垃圾回收时间来动态调整新生代空间的大小","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"线程池","slug":"线程池","permalink":"https://zhengw-tech.com/tags/线程池/"}]},{"title":"状态模式笔记","slug":"state-pattern","date":"2019-10-19T05:35:32.000Z","updated":"2021-04-17T14:50:06.969Z","comments":true,"path":"2019/10/19/state-pattern/","link":"","permalink":"https://zhengw-tech.com/2019/10/19/state-pattern/","excerpt":"在介绍状态模式之前，我们先看个简单的例子 比如我们正常的网上购物的订单，对于订单它有许多个不同的状态，在不同状态下会有不同的行为能力，如状态有待支付、已支付待发货、待收货、订单完成等等，在整个订单流转过程中，由不同的事件行为导致它状态的变更，可以看下它简单的状态图 这些状态虽然不同，但是都是属于订单的状态，对应的行为也是订单的行为，在编码的过程中，一种写法是将这些行为(方法)都写到订单这个类或者类似OrderService这种类中，如 1234567891011121314151617public class OrderService &#123; private OrderDao orderDao; public void pay(Long orderId) &#123; Order order = orderDao.findById(orderId); // 下面逻辑也可以改成使用switch if (order.getStatus() == OrderStatus.WAIT_PAY) &#123; // 待支付，则进行支付 &#125; else if (order.getStatus() == OrderStatus.PAYING) &#123; // 支付中，则进行相应提示 &#125; else if (order.getStatus() == OrderStauts.PART_PAID) &#123; // 部分支付，则进行相应处理 &#125; else &#123; // 其他状态进行对应处理 &#125; &#125;&#125; 这样每次进行操作时，我们要先进行一下当前状态的判断，如用户支付时，我们要判断一下当前订单的状态，如果是待支付，则进行支付操作后，将状态改为已支付；如果当前状态是已支付时，就要提示用户当前订单已支付，不能再次支付等等，如果订单状态比较复杂时就会导致这个类中充斥大量的if、switch等判断逻辑，维护不便 而状态模式则提供了另一种解决方案，它将与特定状态相关的行为局部化，也使得状态转换现实化，下面我我们来具体看一下","text":"在介绍状态模式之前，我们先看个简单的例子 比如我们正常的网上购物的订单，对于订单它有许多个不同的状态，在不同状态下会有不同的行为能力，如状态有待支付、已支付待发货、待收货、订单完成等等，在整个订单流转过程中，由不同的事件行为导致它状态的变更，可以看下它简单的状态图 这些状态虽然不同，但是都是属于订单的状态，对应的行为也是订单的行为，在编码的过程中，一种写法是将这些行为(方法)都写到订单这个类或者类似OrderService这种类中，如 1234567891011121314151617public class OrderService &#123; private OrderDao orderDao; public void pay(Long orderId) &#123; Order order = orderDao.findById(orderId); // 下面逻辑也可以改成使用switch if (order.getStatus() == OrderStatus.WAIT_PAY) &#123; // 待支付，则进行支付 &#125; else if (order.getStatus() == OrderStatus.PAYING) &#123; // 支付中，则进行相应提示 &#125; else if (order.getStatus() == OrderStauts.PART_PAID) &#123; // 部分支付，则进行相应处理 &#125; else &#123; // 其他状态进行对应处理 &#125; &#125;&#125; 这样每次进行操作时，我们要先进行一下当前状态的判断，如用户支付时，我们要判断一下当前订单的状态，如果是待支付，则进行支付操作后，将状态改为已支付；如果当前状态是已支付时，就要提示用户当前订单已支付，不能再次支付等等，如果订单状态比较复杂时就会导致这个类中充斥大量的if、switch等判断逻辑，维护不便 而状态模式则提供了另一种解决方案，它将与特定状态相关的行为局部化，也使得状态转换现实化，下面我我们来具体看一下 状态模式状态模式的目的：允许一个对象在其内部状态改变时改变它的行为，使得对象看起来似乎修改了它的类 我们先看一下状态模式的类图 Context为客户感兴趣的接口，State为状态，ConcreteState为具体状态子类，每一个子类实现一个与Context的一个状态相关的行为 Context将与状态相关的请求委托给对应的ConcreteState对象处理，同时可将自身作为一个参数传递给该请求对应的状态对象 下面我们使用《敏捷软件开发：原则、模式与实践（C#版）》中的闸机例子来分析一下 地铁闸机： 状态 行为（事件） 响应 关闭 投币 开门 关闭 （强行）通过 报警 开启 通过 关门 开启 投币 致谢 具体代码 状态接口 12345public interface TurnstileState &#123; // 行为 void coin(Turnstile t); void pass(Turnstile t);&#125; 闸机控制器 1234567891011121314151617public class TurnstileController &#123; public void unlock() &#123; // todo 开门 &#125; public void alarm() &#123; // todo 报警 &#125; public void thankyou() &#123; // todo 致谢 &#125; public void lock() &#123; // todo 关门 &#125;&#125; 门关闭状态类 12345678910111213public class LockedTurnstileState implements TurnstileState &#123; //投币后门打开 @Override public void coin(Turnstile t) &#123; t.setUnlock(); t.unlock(); &#125; // 关闭时通过则报警 @Override public void pass(Turnstile t) &#123; t.alarm(); &#125;&#125; 门开启时状态类 12345678910111213public class UnLockedTurnstileState implements TurnstileState &#123; // 投币时致谢 @Override public void coin(Turnstile t) &#123; t.thankyou(); &#125; // 通过后将门关闭 @Override public void pass(Turnstile t) &#123; t.setLocked(); t.lock(); &#125;&#125; 闸机功能实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class Turnstile &#123; // 维护两个具体状态类 private static TurnstileState lockedState = new LockedTurnstileState(); private static TurnstileState unlockedState = new UnLockedTurnstileState(); // 闸机控制器 private TurnstileController turnstileController; // 当前状态（初始状态为关闭） private TurnstileState state = lockedState; public Turnstile(TurnstileController turnstileController) &#123; this.turnstileController = turnstileController; &#125; // 投币后调用当前状态类处理 public void coin() &#123; state.coin(this); &#125; // 人通过后调用当前状态类处理 public void pass() &#123; state.pass(this); &#125; // 设置状态为关闭状态 public void setLocked() &#123; state = lockedState; &#125; // 设置状态为开启状态 public void setUnlock() &#123; state = unlockedState; &#125; // 判断是否时关闭状态 public boolean isLocked() &#123; return state == lockedState; &#125; // 判断是否时开启状态 public boolean isUnlocked() &#123; return state == unlockedState; &#125; // 调用控制器致谢 void thankyou() &#123; turnstileController.thankyou(); &#125; // 调用控制器报警 void alarm() &#123; turnstileController.alarm(); &#125; // 调用控制器关门 void lock() &#123; turnstileController.lock(); &#125; // 调用控制器开门 void unlock() &#123; turnstileController.unlock(); &#125;&#125; 以上基本就是状态模式的主要使用方式，相比起聚在一起的判断代码，它将不同状态的行为分割开来，让每一个状态相关的代码都集中在对应的State状态类中，如果有新的状态子类，可以很容易的增加扩展，而不需要改动之前的代码（符合开闭原则） 当然，这样带来的一个副作用就是增加了子类的数目，但是如果状态复杂时，这个成本还是值得的 最后我们总结一个状态模式的适用场景 一个对象的行为取决于它的状态，并且它必须在运行时刻根据状态改变它的行为 一个操作中含有庞大的多分支的条件语句，且这些分支依赖于该对象的状态。这个状态通常用一个或多个枚举常量表示。通常，有多个操作包含这一相同的条件结构。State模式将每一个条件分支放入一个独立的类中。这使得你可以根据自身的情况将对象的状态作为一个对象，这一对象可以不依赖于其他对象而独立变化 参考资料 《设计模式-可复用面向对象软件的基础》 《敏捷软件开发：原则、模式与实践（C#版）》","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zhengw-tech.com/tags/设计模式/"}]},{"title":"Drools入门使用","slug":"Drools入门使用","date":"2019-10-01T11:36:06.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/10/01/Drools入门使用/","link":"","permalink":"https://zhengw-tech.com/2019/10/01/Drools入门使用/","excerpt":"Drools是一款基于Java语言的开源规则引擎，通过drools特定的语法，将复杂多变的业务规则统一管理。 环境配置一、使用maven创建项目添加相关依赖，pom.xml如下 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project ...&gt; &lt;packaging&gt;kjar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-compiler&lt;/artifactId&gt; &lt;version&gt;7.27.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.kie&lt;/groupId&gt; &lt;artifactId&gt;kie-maven-plugin&lt;/artifactId&gt; &lt;version&gt;7.27.0.Final&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;","text":"Drools是一款基于Java语言的开源规则引擎，通过drools特定的语法，将复杂多变的业务规则统一管理。 环境配置一、使用maven创建项目添加相关依赖，pom.xml如下 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project ...&gt; &lt;packaging&gt;kjar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-compiler&lt;/artifactId&gt; &lt;version&gt;7.27.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.kie&lt;/groupId&gt; &lt;artifactId&gt;kie-maven-plugin&lt;/artifactId&gt; &lt;version&gt;7.27.0.Final&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 二、创建kmodule.xml文件在src/main/resources/META-INF下创建kmodule.xml文件 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;kmodule xmlns=\"http://www.drools.org/xsd/kmodule\"&gt; &lt;!-- packages指定的路径为规则所在的包（规则文件需要在src/main/resources下） 读取包下的所有规则文件到kbase中 --&gt; &lt;kbase name=\"rules\" packages=\"rules\"&gt; &lt;!-- session中的name需要唯一，可以通过此名称获取会话，type分为有状态无状态 --&gt; &lt;ksession name=\"testhellowrold\" type=\"stateful\" /&gt; &lt;ksession name=\"testhellowrold_1\" type=\"stateless\" /&gt; &lt;/kbase&gt;&lt;/kmodule&gt; 三、创建会话执行规则12345678910111213141516171819202122public class SessionTest &#123; public void testRun() &#123; KieServices kieServices = KieServices.Factory.get(); // 读取 META-INF/kmodule.xml文件，生成KieContainer KieContainer kieClasspathContainer = kieServices.getKieClasspathContainer(); // 根据kmodule.xml中ksession中的name属性获取创建会话 KieSession ks = kieClasspathContainer.newKieSession(\"testhellowrold\"); // 执行规则(可以在此之前执行insert等方法插入Fact数据执行规则) int count = ks.fireAllRules(); System.out.println(\"总共执行了\" + count + \"条规则\"); // 释放会话的资源 ks.dispose(); &#125;&#125;// 或者也可以不使用xml, 手动获取规则文件生成KieSession:KieHelper helper = new KieHelper();for (KieRuleInfo ruleInfo : rules) &#123; helper.addContent(ruleStr, ResourceType.DRL);&#125;KieBase kieBase = helper.build();KieSession kieSession = kieBase.newKieSession(); 规则使用规则文件的后缀名为drl 1234567rule &quot;规则名称&quot; &quot;规则属性&quot; when 规则校验 then when中的条件都为true时，执行的逻辑end 下面依次介绍上面的部分 when中条件匹配字符串匹配1、str1 matches “正则表达式”2、str1 str[startwWith|endsWith|length] 使用 12345678910111213rule &quot;matchesTest001&quot; when $p : Person(name matches &quot;张.*&quot;); then System.out.println(&quot;matchesTest001 success&quot;);endrule &quot;strTest001&quot; when $p : Person(name str[startsWith] &quot;张&quot;) then System.out.println(&quot;strTest001 success&quot;);end 集合匹配 - in/ not in判断元素是否（在/不在）集合中 使用 1234567rule &quot;in使用&quot; when $s: School($cn: className) $p: Person(className in (&quot;五班&quot;, &quot;六班&quot;, $cn)) then System.out.println(&quot;check in的使用: &quot; + $s + &quot;,&quot; + $p);end 或者可以反过来使用contains关键字 实体匹配 - not/ exists判断实体是否存在 使用 12345678910111213rule &quot;测试not&quot; when not Person() then System.out.println(&quot;Person不存在&quot;);endrule &quot;测试exists&quot; when exists Person() then System.out.println(&quot;Person存在&quot;);end 将表达式转换为bool值 - eval使用 123456rule &quot;测试eval&quot; when eval(1 == 1) then System.out.println(&quot;eval true&quot;);end 全匹配- forall当其中的条件都为true时，为true 使用 1234567rule &quot;测试forall&quot; when forall($p : Person(name == &quot;张三&quot;) Person(this == $p, age == 30)) then System.out.println(&quot;forall true&quot;);end 引用资源 - from引用指定的资源，用于数据匹配或对集合进行遍历 使用 123456789101112131415rule &quot;测试from&quot; when $p: Person($ps: school) $s: School(className == &quot;一班&quot;) from $ps; then System.out.println(&quot;测试from: &quot; + $p + &quot;,&quot; + $s);endrule &quot;测试from1&quot; when $s: School() $p: Person(className == &quot;一班&quot;) from $s.classNameList then System.out.println(&quot;测试from1: &quot; + $p + &quot;,&quot; + $s);end 收集集合及过滤 - collect使用 1234567891011121314rule &quot;测试from collect&quot; when $al: ArrayList() from collect($p: Person(className == &quot;一班&quot;)) then System.out.println(&quot;res size: &quot; + $al.size());endrule &quot;测试from collect pattern&quot; when $al: ArrayList(size &gt;= 3) from collect($p: Person(className == &quot;一班&quot;)) then System.out.println(&quot;res size: &quot; + $al.size());end 集合的复杂处理 - accumulate使用 123456789101112131415161718rule &quot;测试accumulate 取最大值、最小值&quot; when accumulate(Person($age: age), $min:min($age), $max:max($age), $sum:sum($age)) then System.out.println(&quot;max:&quot; + $max + &quot;, min: &quot; + $min + &quot;,sum:&quot; + $sum);endrule &quot;测试accumulate 第二种用法&quot; when $total: Integer() from accumulate(Person($value: age), init(Integer total = 0;), action(total += $value;), result(total) ) then System.out.println(&quot;total:&quot; + $total);end then中的后续处理在when中的条件满足后，进行then的后续逻辑处理，此时可对传进来的数据进行修改等操作 update(对象)单纯的调用对象的方法修改其中的属性，不会触发其他规则的校验 但修改后调用update则会告诉引擎对象已经改变，如果满足条件则会触发规则 也可以简写为： modify() {}，如： 123456789rule &quot;测试更新&quot; when $p : Person(name matches &quot;张.*&quot;); then modify($p)&#123; setName(&quot;李四&quot;) &#125; System.out.println(&quot;matchesTest001 success&quot;);end insert(对象)将新的对象放入工作空间 delete(对象)将工作空间的对象删除 drools.halt()终止规则的执行 规则属性no-loop当update修改对象后，可能会再次触发自身规则，形成死循环 当其值为true时，可以避免自己被自己触发 lock-on-active当其值为true时，则只会被触发一次 salience规则的执行顺序，默认值为0，也可以设置为负数，数值越大，优先级越高 activation-group激活分组，具有相同组名称的规则体只有一个规则被激活，属性受salience影响 样例代码：https://github.com/zavier/drools-demo","categories":[],"tags":[{"name":"drools","slug":"drools","permalink":"https://zhengw-tech.com/tags/drools/"}]},{"title":"Redis内存优化小技巧","slug":"redis-optimization-1","date":"2019-06-20T17:07:59.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2019/06/21/redis-optimization-1/","link":"","permalink":"https://zhengw-tech.com/2019/06/21/redis-optimization-1/","excerpt":"在Redis中，相同的数据，如果我们使用不同的数据结构来存储，它们使用的内存大小差异可能是非常大的，要想更多的节省空间，我们不仅仅需要了解Redis的几种常用数据类型，还需要了解他们内部在不同情况下使用的具体数据结构 之前曾整理过一篇Redis每种数据类型及对应的内部结构，如果对此不太了解的同学可以先大致看一下 压缩数据结构Redis为hash、set、zset都提供了对应的节约空间的数据结构存储方式，合理使用它们可以大大节约内存空间 下面以hash结构举例，其他的结构也是类似的","text":"在Redis中，相同的数据，如果我们使用不同的数据结构来存储，它们使用的内存大小差异可能是非常大的，要想更多的节省空间，我们不仅仅需要了解Redis的几种常用数据类型，还需要了解他们内部在不同情况下使用的具体数据结构 之前曾整理过一篇Redis每种数据类型及对应的内部结构，如果对此不太了解的同学可以先大致看一下 压缩数据结构Redis为hash、set、zset都提供了对应的节约空间的数据结构存储方式，合理使用它们可以大大节约内存空间 下面以hash结构举例，其他的结构也是类似的 hash内部有两种结构 hashtable -哈希表这是我们比较熟悉的一种结构，内部使用数组与链表结合，正常使用数组，如果遇到冲突则使用链表 查找迅速但是比较占用空间 ziplist - 压缩列表使用条件： 键和值的长度都不能超过64字节（可通过 hash-max-ziplist-value配置） 键值对数量小于512个（可通过 hash-max-ziplist-entries配置） ziplist的使用条件虽然苛刻了一些，但是如果满足条件后，则可以节省很多的空间 它内部使用的是一段连续内存空间，将键值对紧挨着排列在其中，这样虽然查询的时候需要顺序遍历，但是如果数据量不大其实并没有什么影响，这也是空间和时间的平衡 我们来看一个具体的例子： 假设我们目前由10万个键值对要保存到Redis中，形式如：key=object:123 value=val，一种比较简单且容易想到的做法就是使用string结构，都以key-value的形式存储到Redis中，这种做法有什么问题呢？ 首先，db中的key其实也都是以字典表的形式存储的，如果db中的key数量不断增多，会需要不断重新rehash分配空间，效果和都放到一个hash结构中差不多，而且应该也能想象的到，字典表为了快速查找且降低key冲突，它需要一些额外的空间，所以它并不节省内存。其实我们可以尝试将这些键值对分组，打散到多个小的hash结构中去 我们可以先来测试一下，分别以string和hash来存储相同数据，看一下效果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 存储 object:[1-100000] val 的键值对func main() &#123; client := redis.NewClient(&amp;redis.Options&#123; Addr: \"127.0.0.1:6379\", &#125;) fmt.Println(\"start kvUsedMemory test\") kvUsedMemory(client) fmt.Println(\"=========================\") fmt.Println(\"start hashUserMemory test\") hashUserMemory(client)&#125;// 使用hash结构，field中字符串长度最大为2func hashUserMemory(client *redis.Client) &#123; // 先清空数据 client.FlushAll() info := client.Info(\"memory\") fmt.Print(\"before add used memory: \") printUsedMemory(info.Val()) client.Pipelined(func(pipeliner redis.Pipeliner) error &#123; for i := 0; i &lt; 100000; i++ &#123; if i &lt; 100 &#123; pipeliner.HSet(\"object:\", string(i), \"val\") &#125; else &#123; v := strconv.Itoa(i) pipeliner.HSet(\"object:\" + v[:len(v)-2], v[len(v)-2:], \"val\") &#125; &#125; return nil &#125;) fmt.Print(\"after add 100_000 hash used memory:\") info = client.Info(\"memory\") printUsedMemory(info.Val())&#125;// 使用string存储func kvUsedMemory(client *redis.Client) &#123; // 先清空数据 client.FlushAll() info := client.Info(\"memory\") fmt.Print(\"before add used memory: \") printUsedMemory(info.Val()) client.Pipelined(func(pipeliner redis.Pipeliner) error &#123; for i := 0; i &lt; 100000; i++ &#123; pipeliner.Set(\"object:\" + strconv.Itoa(i), \"val\", -1); &#125; return nil &#125;) fmt.Print(\"after add 100_000 kv used memory:\") info = client.Info(\"memory\") printUsedMemory(info.Val())&#125;// 获取打印 memoryinfo中的使用内存信息func printUsedMemory(memoryinfo string) &#123; fmt.Println(strings.Split(strings.Split(memoryinfo, \"\\r\\n\")[2], \":\")[1])&#125; 结果如下 1234567start kvUsedMemory test // 大约使用6M空间before add used memory: 2.00Mafter add 100_000 kv used memory:7.89M=========================start hashUserMemory test // 使用了不到1M空间before add used memory: 2.00Mafter add 100_000 hash used memory:2.84M 具体结果可能略有差异，但是仍然可以很明显的看出，使用 hash结构比string节省了很多的空间 分片结构分片简单来说，就是将数据按照一定规则分为许多小部分 上面我们说到的压缩结构，可以节省内存空间，但它往往存在一些限制：只有在数据满足特定情况（一般是数据长度比较小，数量比较少时）才会使用压缩的数据结构，如果数据量大了就不会使用了。这时我们就可以使用分片，将大的数据拆成一个一个小的数据结构，这样就可能会触发使用压缩结构的条件，同时还避免了大key的问题 在分片时，可以尽量让分片后的结构向压缩结构的条件上面靠，甚至可以略微调整触发它的条件 对于hash结构，我们需要写一个根据key计算出分片键的函数 123456public String shardKey(String base, String key, int shardNumber) &#123; CRC32 crc32 = new CRC32(); crc32.update(key.getBytes()); int shardId = (int)(crc32.getValue() % shardNumber); return String.format(\"%s:%s\", base, shardId);&#125; 这样查询和获取的时候，先通过key计算出分片键，使用其作为存储的key 1234public Long shardHash(String base, String key, String value, int shardNumber) &#123; String shardKey = shardKey(base, key, shardNumber); return jedis.hset(shardKey, key, value);&#125;","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://zhengw-tech.com/tags/redis/"}]},{"title":"Redis服务端-客户端通信协议","slug":"redis-resp","date":"2019-06-08T13:32:08.000Z","updated":"2021-04-17T14:50:06.969Z","comments":true,"path":"2019/06/08/redis-resp/","link":"","permalink":"https://zhengw-tech.com/2019/06/08/redis-resp/","excerpt":"了解Redis通信内容Redis我们都比较熟悉，可以用来做缓存、分布式锁等，但是，其中的客户端与服务端是如何进行通信的呢？ 我们可以分别模拟一个服务端或者客户端，打印查看来自实际连接的请求来获取它们的通信方式 首先，让我们先使用先模拟一个服务端，使用Jedis进行连接查看 1234567891011121314// 一个简单的demopublic class MockRedisServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serverSocket = new ServerSocket(6379); Socket socket = serverSocket.accept(); try (InputStream inputStream = socket.getInputStream(); final OutputStream outputStream = socket.getOutputStream()) &#123; byte[] data = new byte[1024]; final int read = inputStream.read(data); final byte[] bytes = Arrays.copyOf(data, read); System.out.println(new String(bytes)); &#125; &#125;&#125;","text":"了解Redis通信内容Redis我们都比较熟悉，可以用来做缓存、分布式锁等，但是，其中的客户端与服务端是如何进行通信的呢？ 我们可以分别模拟一个服务端或者客户端，打印查看来自实际连接的请求来获取它们的通信方式 首先，让我们先使用先模拟一个服务端，使用Jedis进行连接查看 1234567891011121314// 一个简单的demopublic class MockRedisServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serverSocket = new ServerSocket(6379); Socket socket = serverSocket.accept(); try (InputStream inputStream = socket.getInputStream(); final OutputStream outputStream = socket.getOutputStream()) &#123; byte[] data = new byte[1024]; final int read = inputStream.read(data); final byte[] bytes = Arrays.copyOf(data, read); System.out.println(new String(bytes)); &#125; &#125;&#125; 这时用Jedis进行连接 123456789101112// 这时客户端会报错，因为我们模拟的非常简单，没有实现真正的功能返回数据Jedis jedis = new Jedis(\"127.0.0.1\", 6379);jedis.set(\"k1\", \"v1\");// 在服务端将会看到如下输出*3$3SET$2k1$2v1 具体这些内容是什么意思呢？其实这就是RESP(REdis Serialization Protocol)协议的格式 Redis通信协议-RESPRedis客户端与服务端通信使用 RESP(REdis Serialization Protocol)协议 它是一个序列化协议，支持如下几种数据类型，具体类型判断通过第一个字节判断，之间通过”\\r\\n”来分隔 简单字符串 以”+”开头 错误类型 以”-“开头 整数 以”:”开头 块字符串 以”$”开头 数组 以”*”开头 客户端每次发送一个块字符串数组到服务端，服务端根据命令执行后返回结果 简单字符串以”+”字符开头，后面接实际字符串，最后以”\\r\\n”结尾 因为字符是通过’\\r\\n’来判断结尾的，所以此种类型中的字符串内容就不能包含这特殊字符，如果有需要可以使用块字符串类型 例子：+OK\\r\\n 错误类型以”-“字符开头，后面接着错误错误信息，最后以”\\r\\n”结尾 例子：-Error message\\r\\n 整数以”:”字符开头，数值，，最后以”\\r\\n”结尾 例子：:1000\\r\\n 块字符串以”$”字符开头，后面是字符串的实际长度，之后以”\\r\\n”分隔，接着是字符串内容，最后以’\\r\\n’结尾 例子： 1234foobar : $6\\r\\nfoobar\\r\\n// 为了方便阅读，可以简化为$6foobar 空字符串：$0\\r\\n\\r\\n Null(不存在的值)：$-1\\r\\n 数组以”*”开头，后面是数组长度，之后以”\\r\\n”分隔，后面是具体的其他的数据值(数据类型不要求一致) 空数组：*0\\r\\n 1234567[&quot;1&quot;, &quot;foo&quot;]：*2\\r\\n$1\\r\\n1\\r\\n$3\\r\\nfoo\\r\\n方便阅读，简化为：*2 // 数组长度为2$1 // 此元素为长度为1的简单字符1 // 字符内容为&quot;1&quot;$3 // 此元素为长度为3的简单字符foo // 字符内容为&quot;foo&quot; 如果是队列阻塞超时，则返回值为：*-1\\r\\n 现在再让我们看一下之前demo中的返回值就会很明了了，这里简单解释一下 12345678// 原始命令 set k1 v1*3 -长度为3的数组$3 -一个长度为3的字符串SET -字符内容为 \"SET\"$2 -一个长度为2的字符串k1 -字符内容为 \"k1\"$2 -一个长度为2的字符串v1 -字符内容为 \"v1\" 这里有一个简单的实现几个功能的demo：https://github.com/zavier/lite-redis 参考资料：https://github.com/antirez/redis-doc/blob/master/topics/protocol.md","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://zhengw-tech.com/tags/redis/"}]},{"title":"浅谈Java Lambda表达式及其使用","slug":"java-lambda","date":"2019-06-07T05:50:06.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2019/06/07/java-lambda/","link":"","permalink":"https://zhengw-tech.com/2019/06/07/java-lambda/","excerpt":"什么是 Lambda表达式？对于 Java 中的 lambda 表达式，我们可以把它简单的理解为一个函数。 比如，我们需要这样一个函数，它需要把两个数字相加，将结果返回 则可以这样定义 1int add(int a, int b); 但是我们知道，Java中函数是没有办法单独定义存在的，所以我们需要一个接口才能声明这个函数功能 123interface Function &#123; int add(int a, int b);&#125; 当我们需要实现这个方法的时候，一种方法就是定义一个新的类来实现这个接口 123456class Calc implements Function &#123; @Override public int add(int a, int b) &#123; return a + b; &#125;&#125;","text":"什么是 Lambda表达式？对于 Java 中的 lambda 表达式，我们可以把它简单的理解为一个函数。 比如，我们需要这样一个函数，它需要把两个数字相加，将结果返回 则可以这样定义 1int add(int a, int b); 但是我们知道，Java中函数是没有办法单独定义存在的，所以我们需要一个接口才能声明这个函数功能 123interface Function &#123; int add(int a, int b);&#125; 当我们需要实现这个方法的时候，一种方法就是定义一个新的类来实现这个接口 123456class Calc implements Function &#123; @Override public int add(int a, int b) &#123; return a + b; &#125;&#125; 除此之外，还有一种方法就是使用匿名类 123456Function addFunc = new Function() &#123; @Override public int add(int a, int b) &#123; return a + b; &#125;&#125;; 而在 Java8 中，我们又有了一种更简单的写法，这也就是lambda表达式 1Function addFunc1 = (a, b) -&gt; a + b; 当然，既然是为了表达一个函数所创建的接口，所以定义的接口中就必须只能有一个方法。对于这类接口，它还有一个特殊的名字: 函数式接口，我们可以在对应的接口上面添加@FunctionalInterface注解来表明它的身份。 如何使用?上一节我们可以知道，lambda就是函数式接口的实现，所以要想使用lambda表示式，我们必须先定义一个函数式接口，这样任何需要函数式接口的地方，我们都可以传递lambda表达式进去。我们也可以自己定义方法，接受lambda表达式参数 JDK中已经定义了很多常用的函数式接口，比如Comparator接口 1234@FunctionalInterfacepublic interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2);&#125; 这样我们在排序的时候，接受 Comparator接口的地方就可以传递lambda表达式了，非常方便 12List&lt;String&gt; list = ...;list.sort((s1, s2) -&gt; s1.compareTo(s2)); 基本常用的函数式接口，JDK已经都帮我们内置好了，不需要自己定义，大致有以下几类 常用函数式接口Predicate谓词 - 用来对数据进行判断，返回true或false 1234@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t);&#125; Function用于转换数据，将前一个参数的类型转为后面的类型 1234@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t);&#125; Supplier生产者，用来生产数据，无参数，返回一个对象 1234@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; Consumer消费者，就是用来消费数据，接受一个数据，无返回值 1234@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; void accept(T t);&#125; Lambda表达式复合使用函数式接口的功能都比较单一，有时候无法满足我们的需求，这时候就需要将多个lambda表达式组合到一起使用来完成功能 比较器复合12345678// 对于用户类，有两个比较器Comparator&lt;User&gt; ageComparator = (u1, u2) -&gt; u1.getAge().compareTo(u2.getAge());Comparator&lt;User&gt; nameComparator = (u1, u2) -&gt; u1.getAge().compareTo(u2.getAge());// 如果我们需要按照年龄倒序排序Comparator&lt;User&gt; comparator = ageComparator.reversed();// 年龄相等时，我们需要再根据姓名进行比较comparator = ageComparator.thenComparing(nameComparator); 上面只是为了方便理解，实际比较时，可以使用 Comparator.comparing()方法 如按照年龄排序: Comparator&lt;User&gt; newAgeComparator = Comparator.comparing(User::getAge); 谓词复合谓词接口有三个方法，negate, and ,or来分别表示 非、与、或 123456789// 获取年龄大于18岁的用户Predicate&lt;User&gt; userPred1 = u -&gt; u.getAge() &gt; 18;// 获取体重大于80的人Predicate&lt;User&gt; userPred2 = u -&gt; u.getWeight() &gt; 80;// 同时获取年龄大于18 且 体重大于80的人Predicate&lt;User&gt; newPred = userPred1.and(userPred2);// 获取年龄大于18 或者 体重大于80的人Predicate&lt;User&gt; newPred2 = userPred1.or(userPred2); 注意：如果and和or在一起使用，则会按照书写顺序来定优先级 函数复合Function接口提供了两个方法andThen和compose用来组合函数 andThen用在执行完当然函数，将结果用户参数中的下一个函数 而 compose顺序则相反，是执行完参数中的函数，将结果用于当前调用函数 123456789101112Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;// 先执行 f 再执行 gFunction&lt;Integer, Integer&gt; h = f.andThen(g);// == (10 + 1) * 2 = 22System.out.println(h.apply(10));// 先执行 g 再执行 fFunction&lt;Integer, Integer&gt; compose = f.compose(g);// == (10 * 2) + 1 = 21System.out.println(compose.apply(10)); 附：Java8其他流的扁平化-flatMapflatMap方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流12345678910// 获取所有的各不相同的字符List&lt;String&gt; words = Arrays.asList(\"hello\", \"world\");List&lt;String&gt; result = words.stream() // 转换为字符串数组流 .map(word -&gt; word.split(\"\")) // Arrays.stream会将数组转换成一个流，之后将其合并为一个流 .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList());System.out.println(result); 1234567891011// 生成所有数对，如：[(1,3), (1,3), (1,4), (2,3), (2,4), (3,3), (3,4)]List&lt;Integer&gt; num1 = Arrays.asList(1, 2, 3);List&lt;Integer&gt; num2 = Arrays.asList(3, 4);List&lt;int[]&gt; collect = num1.stream() // 将每个num1中的数值转换为对应的流，并合成一个 .flatMap(n1 -&gt; num2.stream().map(n2 -&gt; new int[]&#123;n1, n2&#125;)) .collect(Collectors.toList());collect.stream() .map(Arrays::toString) .forEach(System.out::println); 查找和匹配至少一个匹配boolean b = words.stream().anyMatch(&quot;hello&quot;::equals); 匹配全部元素12boolean b1 = words.stream().allMatch(&quot;hello&quot;::equals);boolean b2 = words.stream().noneMatch(&quot;hello&quot;::equals); 查找元素12Optional&lt;String&gt; h1 = words.stream().filter(&quot;hello&quot;::equals).findAny();Optional&lt;String&gt; h2 = words.stream().filter(&quot;hello&quot;::equals).findFirst(); 收集器接口123456789101112131415161718192021222324252627282930313233/** * * @param &lt;T&gt; 要收集的项目的范型 * @param &lt;A&gt; 累加器的类型，累加器在收集过程中累积部分结果的对象 * @param &lt;R&gt; 收集操作得到的对象的类型 */interface Collector&lt;T, A, R&gt; &#123; /** * 建立新的结果容器 */ Supplier&lt;A&gt; supplier(); /** * 将元素添加到结果容器 */ BiConsumer&lt;A, T&gt; accumulator(); /** * 对结果容器应用最终转换 */ Function&lt;A, R&gt; finisher(); /** * 合并两个结果容器（并行处理使用） */ BinaryOperator&lt;A&gt; combiner(); /** * 定义收集器的行为（是否可以并行归约等） * @return */ Set&lt;Characteristics&gt; characteristics();&#125; 具体例子可参考 Collectors.toList实现 参考资料：《Java8 实战》","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"Redis Rehash源码分析","slug":"redis-rehash","date":"2019-06-01T18:35:01.000Z","updated":"2021-04-17T14:50:06.969Z","comments":true,"path":"2019/06/02/redis-rehash/","link":"","permalink":"https://zhengw-tech.com/2019/06/02/redis-rehash/","excerpt":"接着之前说过的 Java HashMap的Rehash，这次我们来看看 Redis中的 hash结构(对应Java中的Map)是如何实现rehash的。 这次先说下结论，它的结构与HashMap基本一致，只是它有两个哈希表，平时只使用其中的第一个，在发生rehash时，会逐渐的将元素转移到另一个表中，全部转移完成后，再将引用赋值给第一个哈希表 下面我们来开始看代码","text":"接着之前说过的 Java HashMap的Rehash，这次我们来看看 Redis中的 hash结构(对应Java中的Map)是如何实现rehash的。 这次先说下结论，它的结构与HashMap基本一致，只是它有两个哈希表，平时只使用其中的第一个，在发生rehash时，会逐渐的将元素转移到另一个表中，全部转移完成后，再将引用赋值给第一个哈希表 下面我们来开始看代码 注：为了简化代码，只保留了源码中的主要字段，不是完整源码，需要的可以参看Redis源码 12345678910111213141516171819202122// 字典typedef struct dict &#123; // 哈希表（一共有两个，这是rehash的关键） dictht ht[2]; long rehashidx; /* 没有在进行rehash时，rehashidx == -1 */&#125; dict;// 哈希表// 每个字典都使用两个哈希表，从而实现渐进式 rehash（从一个哈希表渐进转到另一个哈希表）typedef struct dictht &#123; dictEntry **table; unsigned long size; // 哈希表的数组长度 unsigned long sizemask; // 哈希表大小掩码，用于计算索引值，总是等于 size -1 unsigned long used; // 共有元素节点数量&#125; dictht;// 字典中的节点typedef struct dictEntry &#123; void *key; // 键 union &#123;... &#125; v; // 值 struct dictEntry *next; // 链表指针(指向下一节点)&#125; dictEntry; 之前分析Java的HashMap时，我们知道rehash是比较消耗机器性能的，而Redis是单线程的，这个影响只会更大，甚至影响Redis的使用，所以它不是一次完成，而是有严格控制的分次，一点点的将ht[0]中的数据转移到ht[1]中来完成这个过程。当然，在这个过程中，如果要查询元素，则需要在ht[0]和ht[1]中都进行检索 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// n 表示一次最多转移的数组中索引数量(索引表示对应的整个链表)int dictRehash(dict *d, int n) &#123; int empty_visits = n*10; /* 查找不为空的索引的最大查找数量 */ if (!dictIsRehashing(d)) return 0; // 如果已经在进行rehash则直接返回 // 用于控制转移索引的数量 while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; // 用于查找到第一个不为空的索引，如果查找到最大上限仍没找到非空索引则结束返回 while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125; // 获取ht[0]中的第一个非空索引中的元素 de = d-&gt;ht[0].table[d-&gt;rehashidx]; // 将索引对应的元素及后面的链表(如果存在)全部转移 while(de) &#123; uint64_t h; // 拿到要转移的元素后面的一个元素 nextde = de-&gt;next; // 获取元素在ht[1]中的索引位置 h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; // // 使用头插法将元素插入到新位置中 de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; // 用于判断被转移的元素之前是否有后续链表，有则继续转移 de = nextde; &#125; // 转移完成后，将ht[0]对应索引清空 d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; // rehashindex维护ht[0]中要进行转移的索引位置 d-&gt;rehashidx++; &#125; // 检查，如果全部完成后，则将h[1]中的数据赋值给h[0]，清空h[1]并重置rehashidx if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; return 1;&#125; Rehash的过程基本就是上面所说的了，看完后是不是很好奇，既然是分次转移，那么这个操作是如何触发的呢？ 如果对此比较好奇的话，接着往下看 Redis虽然说是单线程的，但是它仍然有一些后台任务在悄悄的运行着 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* This function handles 'background' operations we are required to do * incrementally in Redis databases, such as active key expiring, resizing, * rehashing. */// 大意就是：这个函数用来处理后台操作，比如过期key, resizing， rehashing// 这里删掉一部分暂时不关注的代码void databasesCron(void) &#123; if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1) &#123; /* Resize */ // 如果插入数据量达到阈值，会触发resize // 初始化ht[1]为rehash后的大小，并将rehash标志位 rehashidx 置为0，表示开始进行了rehash for (j = 0; j &lt; dbs_per_call; j++) &#123; tryResizeHashTables(resize_db % server.dbnum); resize_db++; &#125; /* Rehash */ // 上一步只是分配了空间，打开标志为，真正转移数据的部分在下面代码中进行 if (server.activerehashing) &#123; for (j = 0; j &lt; dbs_per_call; j++) &#123; // 开始rehash转移数据！！！ int work_done = incrementallyRehash(rehash_db); if (work_done) &#123; /* If the function did some work, stop here, we'll do * more at the next cron loop. */ break; &#125; else &#123; /* If this db didn't need rehash, we'll try the next one. */ rehash_db++; rehash_db %= server.dbnum; &#125; &#125; &#125; &#125;&#125;int incrementallyRehash(int dbid) &#123; /* Keys dictionary */ // 由于之前resize时已经将标志位打开，所以执行if中的函数 if (dictIsRehashing(server.db[dbid].dict)) &#123; // 使用 1ms 进行rehash dictRehashMilliseconds(server.db[dbid].dict,1); return 1; /* already used our millisecond for this loop... */ &#125; // 省略过期key的代码处理 return 0;&#125;int dictRehashMilliseconds(dict *d, int ms) &#123; long long start = timeInMilliseconds(); int rehashes = 0; // 每次移动 100个数组中的索引，如果用时不到之前指定的1ms则进行进行，否则不再执行 while(dictRehash(d,100)) &#123; rehashes += 100; if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125; 再就是每次插入、删除或者查询时，也会进行rehash，主要代码如下： 123456789101112131415161718192021222324252627282930// 单步rehash，一次只转移一个索引对应的所有元素static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125;// 插入dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; if (dictIsRehashing(d)) _dictRehashStep(d); // ... 省略插入逻辑&#125;// 查找dictEntry *dictFind(dict *d, const void *key)&#123; // 如果dict在rehash过程中，则进行单步的数据转移(一个索引对应的所有元素) if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) return NULL; &#125; return NULL;&#125; 本篇的主要内容已经讲完了，代码部分有些多，需要大家耐下心来看，都比较简单 内容如有错误之处，欢迎指正～","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://zhengw-tech.com/tags/redis/"}]},{"title":"漫谈 Java HashMap的Rehash","slug":"java-rehash","date":"2019-06-01T02:34:08.000Z","updated":"2021-04-17T14:50:06.968Z","comments":true,"path":"2019/06/01/java-rehash/","link":"","permalink":"https://zhengw-tech.com/2019/06/01/java-rehash/","excerpt":"我们都知道Java中的HashMap是使用数组，结合链表来实现的，其结构如下： 如果加入的元素数量达到了设定的阈值，那么必然会涉及到扩容重新分配空间，将元素重新插入到新的空间中，也就是发生了rehash。这个过程其实是很耗时的，这也是为什么我们写代码时，最好指定的HashMap的初始空间大小的原因，就是为了避免或者减少发生rehash的次数。下面我们来看看这个过程的具体实现。 JDK是一直在升级的，其中的代码也在不断优化调整，我们这次主要就看下JDK1.7和 JDK1.8中的实现","text":"我们都知道Java中的HashMap是使用数组，结合链表来实现的，其结构如下： 如果加入的元素数量达到了设定的阈值，那么必然会涉及到扩容重新分配空间，将元素重新插入到新的空间中，也就是发生了rehash。这个过程其实是很耗时的，这也是为什么我们写代码时，最好指定的HashMap的初始空间大小的原因，就是为了避免或者减少发生rehash的次数。下面我们来看看这个过程的具体实现。 JDK是一直在升级的，其中的代码也在不断优化调整，我们这次主要就看下JDK1.7和 JDK1.8中的实现 JDK1.7了解实现就免不了看源码，我们先来看下put方法的主要源码（为了方便阅读，省略了部分代码） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public V put(K key, V value) &#123; int hash = hash(key.hashCode()); // 计算数组索引，插入 int i = indexFor(hash, table.length); addEntry(hash, key, value, i); return null;&#125;void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) // 插入后总数量达到了阈值，发生rehash，扩容一倍 resize(2 * table.length);&#125;void resize(int newCapacity) &#123; Entry[] newTable = new Entry[newCapacity]; // 创建新的数组，并将老的数据转换过去 transfer(newTable); // 查新指定引用空间 table = newTable;&#125;/** * 具体转换数据的实现 * 依次遍历数组元素，重新计算索引插入 * 如果数组对应元素有链表，那么处理完这个链表后进行下一个索引数据的处理 */void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; // 遍历主数组 for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; // 如果数组索引对应的元素是个链表，那么将这个链表处理完成再处理下一个索引 if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); // 使用头插法插入到新的空间(可能是链表)中 e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; 如果大家对上面的大段代码比较头疼，我就用文字来简单概括一下： 当map中的元素数量达到阈值时，会重新创建一个新的数组，长度为旧数组的两倍(如果长度没有达到上限的话)，这时会依次对旧数组(包括其中的链表)按顺序重新计算索引插入，之后重新赋值引用即可 而我们通常说的HashMap线程不安全，其实主要原因就在上面transfer方法中的链表处理逻辑里 简单描述一下，就是当一个线程1持有链表中的一个元素e和下一个元素的引用next时，如果此时当前线程时间片用完 这时另一个线程2启动，它将整个链表重新rehash完毕，碰巧这几个链表元素还在同一个索引位置，因为链表插入使用头插入，这时的链表顺序和之前就是相反的 此时如果线程1启动，很明显的它持有的e和next位置被调换了，next竟然会持有e的引用，这时继续处理的结果就是在这两个元素之前成环状，一旦调用get方法处理到这个地方，就会发生死循环 主要的思路就这些，大家如果有兴趣可以继续查看一下其它的资料 下面我们接着来看JDK1.8的rehash JDK1.8JDK1.8的HashMap相比1.7进行了比较多的改动，当然，代码量也是增加了很多～ 我们还是尽量只看主逻辑 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 初始化空间 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 数组空闲，可以直接插入 tab[i] = newNode(hash, key, value, null); else &#123; // 插入链表，这部分逻辑比较复杂 // 相比1.7多了一步：如果链表元素过长（达到8个），就会将链表转为红黑树 &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125;final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order(这里是关键) Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // (1) 确定新索引位置 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 我们具体看下其中的链表处理部分，把这部分代码拿出来分析一下 在这之前，我们需要先证明一个结论： HashMap rehash重新计算索引后，新索引要么等于原索引位置，要么等于原索引值+原数组大小 说一下HashMap的几个相关知识点 HashMap的数组大小一定是2的N次幂（这是由HashMap自己保证） HashMap的索引计算方式为 hash(key) &amp; (size - 1)，由1可知，size-1的二进制低位都为1 HashMap扩容时一般为增大一倍，即size = size * 2，相当于 size = size &lt;&lt; 1 其实hash(key) &amp; (size -1)，由于size-1在范围内的值二进制都是1，所以结果就是hash值在数组范围内的值，size值影响的只是取hash值的低位二进制的位数而已，它本身相当于不参与计算。如果不太好理解，再举个例子 如果size=16，size-1的二进制就是1111，与hash结果进行按位与运算，就是取hash结果自己的低4位值 而如果扩容后size=32，size-1的二进制就是11111，与hash结果进行按位与运算，就是取hash结果自己的低5位值 这样其实我们就可以得到之前的结论了，对于上面的例子，如果hash结果的倒数第5位是0，那么重新hash后他还在原位置，否则就会在原基础上增加的二进制值是10000（oldSize），即 oldIndex + oldSize 准备工作已经结束，下面我们来分析这部分代码 123456789101112131415161718192021222324252627282930313233// loHead对应的是rehash后还在原位置的，hiHead对应的是newIndex = oldIndex + oldSizeNode&lt;K,V&gt; loHead = null, loTail = null;Node&lt;K,V&gt; hiHead = null, hiTail = null;Node&lt;K,V&gt; next;do &#123; next = e.next; // 确定新索引位置,对应之前例子就是判断第5位的值是不是0，如果是0就是rehash后还在原位置的 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else // 尾插法，保证顺序和之前在前面的元素现在还在前面 loTail.next = e; loTail = e; &#125; // 这个else表明hash结果对应的位是1，即newIndex = oldIndex + oldSize else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125;&#125; while ((e = next) != null);// 将两个链表插入到对应的新数组位置中if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead;&#125;if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead;&#125; 总结一下1.8的链表处理部分，因为rehash后新索引只有两种情况 newIndex = oldIndex newIndex = oldIndex + oldSize 这个可以通过(e.hash &amp; oldCap) == 0判断，在遍历链表的过程中，使用尾插法(保证前后顺序)将链表分组插入到临时链表中，最后再将链表引用赋值到对应的数组空间中 这种方法其实就解决了1.7中的链表rehash成环的问题 好了，基本内容就是这些，如有错误之处，欢迎指正～","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"Spring Bean 中 Bean解析创建过程（下）","slug":"spring-beans-2","date":"2019-05-04T15:22:43.000Z","updated":"2022-02-07T05:08:05.703Z","comments":true,"path":"2019/05/04/spring-beans-2/","link":"","permalink":"https://zhengw-tech.com/2019/05/04/spring-beans-2/","excerpt":"这篇来跟踪一下AbstractBeanFactory#getBean(java.lang.String, java.lang.Class&lt;T&gt;)这个方法获取bean实例的流程，由于过程比较复杂，我们这里以一个简单的例子来跟进一下主要的流程 Spring 配置使用下面我们看下具体的例子代码 spring配置文件 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"com.zavier.spring.beans.TestBean\" id=\"testBean\" init-method=\"myinit\" destroy-method=\"mydestroy\"&gt; &lt;/bean&gt;&lt;/beans&gt;","text":"这篇来跟踪一下AbstractBeanFactory#getBean(java.lang.String, java.lang.Class&lt;T&gt;)这个方法获取bean实例的流程，由于过程比较复杂，我们这里以一个简单的例子来跟进一下主要的流程 Spring 配置使用下面我们看下具体的例子代码 spring配置文件 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"com.zavier.spring.beans.TestBean\" id=\"testBean\" init-method=\"myinit\" destroy-method=\"mydestroy\"&gt; &lt;/bean&gt;&lt;/beans&gt; 对应要创建的bean的定义 12345678910111213141516171819202122232425262728293031323334public class TestBean implements BeanNameAware, BeanFactoryAware, InitializingBean, DisposableBean &#123; public TestBean() &#123; System.out.println(\"执行无参构造器\"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println(\"执行 InitializingBean 接口的 afterPropertiesSet 方法进行初始化\"); &#125; @Override public void destroy() throws Exception &#123; System.out.println(\"执行 DisposableBean 接口的 destroy 方法\"); &#125; @Override public void setBeanName(String name) &#123; System.out.println(\"执行 BeanNameAware 接口的 setBeanName 方法，获取设置 Bean 名称\"); &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println(\"执行 BeanFactoryAware 接口的 setBeanFactory 方法，获取设置 BeanFactory\"); &#125; public void myinit() &#123; System.out.println(\"执行自己在配置文件中定义的初始化方法\"); &#125; public void mydestroy() &#123; System.out.println(\"执行自己在配置文件中定义的结束方法\"); &#125;&#125; main方法 12345678public static void main(String[] args) &#123; ClassPathResource resource = new ClassPathResource(\"spring-bean.xml\"); DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); beanDefinitionReader.loadBeanDefinitions(resource); TestBean bean = beanFactory.getBean(\"testBean\", TestBean.class);&#125; 执行结果如下, 从中可以看出Bean的部分生命周期 12345执行无参构造器执行 BeanNameAware 接口的 setBeanName 方法，获取设置 Bean 名称执行 BeanFactoryAware 接口的 setBeanFactory 方法，获取设置 BeanFactory执行 InitializingBean 接口的 afterPropertiesSet 方法进行初始化执行自己在配置文件中定义的初始化方法 Spring 创建流程现在来跟踪一下获取单例Bean实例的主要过程: 1.根据Bean名称, 创建RootBeanDefinition这一步可以简单理解为执行了以下三个操作 1.1 从registry中根据beanName获取到对应的BeanDefinition1.2 创建一个RootBeanDefinition，并将BeanDefinition的属性复制到其中1.3 如果其未设置scope, 则设置其默认的scope为 singleton(单例)2.开始单例模式Bean的创建1234567891011121314151617181920212223242526272829303132333435363738// 创建Beanprotected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) &#123; // 主要执行了如下两个步骤 // 可以在这步骤中创建代理取代原来的Bean返回 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; // 此时执行真正的创建Bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); &#125;protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) &#123; // 反射调用(如默认构造方法等)进行实例化 BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args); Object exposedObject = bean; try &#123; // 为bean的属性赋值(配置文件中bean标签下配置的property, constructor-arg等) populateBean(beanName, mbd, instanceWrapper); // 调用初始化方法等,详情见下面 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; return exposedObject;&#125;protected Object initializeBean(String beanName, Object bean, RootBeanDefinition mbd) &#123; // 如果实现了BeanNameAware、BeanFactoryAware等方法,则调用进行赋值 invokeAwareMethods(beanName, bean); // 依次执行beanFactory中所有实现BeanPostProcessor的前置方法,对Bean进行修改 Object wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); // 执行初始化方法,先执行afterPropertiesSet,后执行配置文件中的init-method方法 invokeInitMethods(beanName, wrappedBean, mbd); // 依次执行beanFactory中所有实现BeanPostProcessor的后置方法,对Bean进行修改 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); return wrappedBean;&#125; 3.返回最终创建的bean实例，创建结束其他在Bean的整个声明周期中, 有部分环节我们可以插入自己的代码来对bean进行修改等操作,完成一些特定的功能 比如在上面的initializeBean方法中, 可以在调用初始化方法前后执行我们实现的BeanPostProcessor对bean进行修改、甚至替换等操作 12345678910111213public class MyBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 执行bean的初始化方法前，可以对其进行修改 return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; // 执行bean的初始化方法后，可以对其进行修改，甚至替换（比如代理等）并返回替换后的类 return bean; &#125;&#125; 举个简单的例子, 比如要实现一个自定义注解, 就可以结合spring的注解使用, 让spring帮我们扫描后, 我们在postprocessor中再过滤出有对应注解的类,收集或进行修改等其他处理 或者实现代理的一些功能等","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"}]},{"title":"Spring Bean 中 Bean解析创建过程（上）","slug":"spring-beans-1","date":"2019-05-01T09:59:43.000Z","updated":"2022-02-07T05:08:05.703Z","comments":true,"path":"2019/05/01/spring-beans-1/","link":"","permalink":"https://zhengw-tech.com/2019/05/01/spring-beans-1/","excerpt":"spring-beans虽然是一个很基础的包，但是它已经包括了很多的功能，我们先看下如何在只使用spring-beans包的情况下，解析并拿到xml中配置的bean实例 spring-bean.xml 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"com.zavier.spring.beans.SimpleBean\" id=\"simpleBean\" /&gt;&lt;/beans&gt; 解析代码 123456789// 1.创建一个BeanFactoryDefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();// 2.创建读取Bean定义的ReaderXmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);// 3.使用Reader来读取指定的资源信息ClassPathResource resource = new ClassPathResource(\"spring-bean.xml\");beanDefinitionReader.loadBeanDefinitions(resource);// 4.之后就可以从工厂中正常获取对应的bean实例SimpleBean bean = beanFactory.getBean(SimpleBean.class);","text":"spring-beans虽然是一个很基础的包，但是它已经包括了很多的功能，我们先看下如何在只使用spring-beans包的情况下，解析并拿到xml中配置的bean实例 spring-bean.xml 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"com.zavier.spring.beans.SimpleBean\" id=\"simpleBean\" /&gt;&lt;/beans&gt; 解析代码 123456789// 1.创建一个BeanFactoryDefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();// 2.创建读取Bean定义的ReaderXmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);// 3.使用Reader来读取指定的资源信息ClassPathResource resource = new ClassPathResource(\"spring-bean.xml\");beanDefinitionReader.loadBeanDefinitions(resource);// 4.之后就可以从工厂中正常获取对应的bean实例SimpleBean bean = beanFactory.getBean(SimpleBean.class); 让我们来一步一步分析一下上面几行代码的底层的实际执行逻辑 先看一下最重要的BeanFactory实现类 DefaultListableBeanFactory的继承关系 在这个图中，我们能看出其主要是实现了两个接口 BeanFactory - Bean的工厂类，负责创建Bean实例等 BeanDefinitionRegistry - Bean定义的注册器，可以将Bean的定义信息注册到其中 DefaultListableBeanFactory实现后，就可以通过beanDefinitionReader读取解析xml等配置文件中的信息，将Bean的信息BeanDefinition通过registry注册，之后可以通过 beanFactory创建bean 这篇文章中我们先看一下Bean信息的读取注册过程，也就是BeanDefinitionRegistry 接口的功能实现 先看一下 XmlBeanDefinitionReader具体是如何解析xml文件，并将配置的bean信息注册给registry呢 XmlBeanDefinitionReader.loadBeanDefinition ​ 委托给 DefaultBeanDefinitionDocumentReader.registerBeanDefinition ​ 委托给 BeanDefinitionParserDelegate 负责最终的处理 而BeanDefinitionParseDelegate对于默认的标签（bean、import、alias等）和自定义的标签有不同的处理逻辑 一、自定义标签123// 对应的方法如下，用来处理如 &lt;mvc:annotation-driven /&gt; 之类的其他命名空间的标签// 这次我们先不进入细看，感兴趣的可以进入看下delegate.parseCustomElement(root) 二、 beans默认标签（bean、import、alias等）BeanDefinitionParserDelegate的parseBeanDefinitionElement方法，它的执行流程大体如下 1.解析bean标签中的ID和name属性，将beanName=id，并校验次beanName是否已经存在 2.解析bean标签中的class等属性，创建 AbstractBeanDefinition (Bean的定义包装类) 12GenericBeanDefinition bd = new GenericBeanDefinition();bd.setBeanClass(ClassUtils.forName(className, classLoader)); 3.解析bean标签属性(scope, lazy-init, init-method, destroy-method等)，并赋值给AbstractBeanDefinition中对应的属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445// BeanDefinitionParserDelegate.parseBeanDefinitionAttributes方法AbstractBeanDefinition bd = ...;bd.setScope(..);bd.setAbstract(..);bd.setLazyInit(..);bd.setAutowireMode(..);bd.setDependencyCheck(..);bd.setDependsOn(..);bd.setAutowireCandidate(..);bd.setPrimary(..);bd.setInitMethodName(..);bd.setDestroyMethodName(..);bd.setFactoryMethodName(..);bd.setFactoryBeanName(..);// 同时，我们可以简单看下AbstractBeanDefinition中包含的主要属性class AbstractBeanDefinition extends BeanMetadataAttributeAccessor implements BeanDefinition, Cloneable &#123; private volatile Object beanClass; // bean的实际class private String scope = SCOPE_DEFAULT; private boolean abstractFlag = false; private boolean lazyInit = false; private int autowireMode = AUTOWIRE_NO; private int dependencyCheck = DEPENDENCY_CHECK_NONE; private String[] dependsOn; private boolean autowireCandidate = true; private boolean primary = false; private final Map&lt;String, AutowireCandidateQualifier&gt; qualifiers = new LinkedHashMap&lt;String, AutowireCandidateQualifier&gt;(0); private boolean nonPublicAccessAllowed = true; private boolean lenientConstructorResolution = true; private String factoryBeanName; private String factoryMethodName; private ConstructorArgumentValues constructorArgumentValues; private MutablePropertyValues propertyValues; private MethodOverrides methodOverrides = new MethodOverrides(); private String initMethodName; private String destroyMethodName; private boolean enforceInitMethod = true; private boolean enforceDestroyMethod = true; private boolean synthetic = false; private int role = BeanDefinition.ROLE_APPLICATION; private String description; private Resource resource; &#125; 4.处理bean标签中的子标签，如constructor-args, property等，并赋值给AbstractBeanDefinition中对应的属性 123AbstractBeanDefinition bd = ...;bd.setConstructorArgumentValues(..); // constructor-argsbd.setPropertyValues(..); // property 5.创建BeanDefinitionHolder(对BeanDefinition的包装类，主要是包含了 alias属性) 12345678new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray);// BeanDefinitionHolder 的定义public class BeanDefinitionHolder implements BeanMetadataElement &#123; private final BeanDefinition beanDefinition; private final String beanName; private final String[] aliases;&#125; 6.最后调用BeanDefinitionReaderUtils.registerBeanDefinition注册到DefaultListableBeanFactory 12345678910111213141516171819public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125;&#125;// DefaultListableBeanFactory 对应的存储结构private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); 至此，我们就完成了一个xml文件的读取，解析并赋值给DefaultListableBeanFactory（BeanDefinitionRegistry接口的实现）的过程 之前我们说过 DefaultListableBeanFactory 主要实现的是两个接口，BeanDefinitionRegistry与 BeanFactory，现在我们只说了BeanDefinitionRegistry 读取注册Bean相关的功能，下一篇我们来接续讲解一下BeanFactory也是bean实例创建的部分，谢谢～","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"}]},{"title":"MyBatis-Spring配置及使用","slug":"mybatis-spring","date":"2019-03-31T10:22:50.000Z","updated":"2022-01-16T08:00:37.968Z","comments":true,"path":"2019/03/31/mybatis-spring/","link":"","permalink":"https://zhengw-tech.com/2019/03/31/mybatis-spring/","excerpt":"MyBatis 基本用法MyBatis是我们常用的ORM框架，先看一下它的基本用法(省略了Mapper相关的配置项): 123456789101112// 读取MyBatis配置文件InputStream inputStream = Resources.getResourceAsStream(\"mybatis-config.xml\");// 从配置文件中构建 SqlSessionFactory (全局只有一个，用于构建 SqlSession)SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 使用 SqlSessionFactory 创建 SqlSession(请求作用域，用后销毁)SqlSession session = sessionFactory.openSession(true);// 获取对应 MapperUserMapper mapper = session.getMapper(UserMapper.class);// 执行查询User user = mapper.findById(1);// 关闭 sessionsession.close(); MyBatis-Spring工作中最常用的还是与Spring结合，使用mybatis-spring 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt;&lt;/dependency&gt;","text":"MyBatis 基本用法MyBatis是我们常用的ORM框架，先看一下它的基本用法(省略了Mapper相关的配置项): 123456789101112// 读取MyBatis配置文件InputStream inputStream = Resources.getResourceAsStream(\"mybatis-config.xml\");// 从配置文件中构建 SqlSessionFactory (全局只有一个，用于构建 SqlSession)SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 使用 SqlSessionFactory 创建 SqlSession(请求作用域，用后销毁)SqlSession session = sessionFactory.openSession(true);// 获取对应 MapperUserMapper mapper = session.getMapper(UserMapper.class);// 执行查询User user = mapper.findById(1);// 关闭 sessionsession.close(); MyBatis-Spring工作中最常用的还是与Spring结合，使用mybatis-spring 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt;&lt;/dependency&gt; 看一下mybatis-spring的主要配置及使用 spring-mybatis.xml1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 使用Spring提供的简单的DataSource --&gt; &lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/demo\" /&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"root\" /&gt; &lt;/bean&gt; &lt;!-- 声明 SqlSessionFactoryBean --&gt; &lt;bean id=\"sqlSessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 指定数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;!-- 指定Mapper文件所在的路径 --&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\" /&gt; &lt;!-- 加载配置文件 --&gt; &lt;property name=\"configLocation\" value=\"mybatis-config.xml\" /&gt; &lt;/bean&gt; &lt;!-- 声明扫描的包，创建对应的 MapperFactoryBean --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.zavier.demo.dao\" /&gt; &lt;/bean&gt;&lt;/beans&gt; main方法 12345678910ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"spring-mybatis.xml\");UserMapper userMapper = applicationContext.getBean(\"userMapper\", UserMapper.class);UserDO userDO = new UserDO();userDO.setUserName(\"testname\");userDO.setUserAge(1);userMapper.save(userDO);userDO = userMapper.findById(1);System.out.println(userDO); 下面分析一下上面的配置 MyBatis-Spring对于mybatis中关键的 SqlSessionFactoryBuilder、SqlSession、Mapper接口等提供了替代的Bean，避免了手动创建管理的麻烦，只需要配置对应的类即可注入使用，很方便 一、 对于SqlSessionFactoryBuilder，使用sqlSessionFactoryBean （实现了Spring的FactoryBean）替代，用来创建 SqlSessionFactory 12345678&lt;!-- 使用SqlSessionFactoryBean 替代 SqlSessionFactoryBuilder --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 指定数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;!-- 使用 mapper 对应的xml文件路径 --&gt; &lt;property name=\"mapperLocations\" value=\"classpath*:sample/config/mappers/**/*.xml\" /&gt; &lt;!-- 还可注入其他属性，如configLocation等 --&gt;&lt;/bean&gt; 二、 对于SqlSession，提供SqlSessionTemplate，它线程安全（可以简单理解为每次创建新的SqlSession），提供了执行SQL方法，翻译异常功能 1234567891011121314151617181920212223242526272829303132333435363738// =============================主要源码===========================================public class SqlSessionTemplate implements SqlSession, DisposableBean &#123; private final SqlSessionFactory sqlSessionFactory; private final ExecutorType executorType; private final SqlSession sqlSessionProxy; public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; // SqlSessionInterceptor代理SqlSession的方法 this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor()); &#125; // 实现了sqlSession的执行操作方法 @Override public &lt;T&gt; T selectOne(String statement) &#123; return this.sqlSessionProxy.selectOne(statement); &#125; // ...&#125;private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 获取sqlSession，反射调用，获取的时候会从TransactionSynchronizationManager中获取线程相关的类 SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; Object result = method.invoke(sqlSession, args); return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); // 包装处理异常 throw unwrapped; &#125; &#125;&#125; 使用（只需注入 SqlSessionFactory） 123&lt;bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSessionFactory\" /&gt;&lt;/bean&gt; 之后可以注入此 sqlSession正常使用，但是我们一般也不需要使用此配置项创建session，通过session来获取mapper进行执行查询等操作，而是直接创建mapper的bean，让容器注入到对应位置，直接执行。我们接着往下看 三、对于Mapper接口，提供了 MapperFactoryBean（可以为每个mapper声明一个MapperFactoryBean） SqlSessionDaoSupport 12345678910111213// 主要方法如下，可以实现此类，通过 getSqlSession 方法获取 sqlSessionTemplate 执行// 通常的实现类是 MapperFactoryBean public abstract class SqlSessionDaoSupport extends DaoSupport &#123; private SqlSessionTemplate sqlSessionTemplate; protected SqlSessionTemplate createSqlSessionTemplate(SqlSessionFactory sqlSessionFactory) &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; public SqlSession getSqlSession() &#123; return this.sqlSessionTemplate; &#125;&#125; MapperFactoryBean 12345678public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; &#123; private Class&lt;T&gt; mapperInterface; @Override public T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface); &#125;&#125; 使用（提供SqlSessionFactory 与要实现的接口） 12345&lt;bean id=\"userMapper\" class=\"org.mybatis.spring.mapper.MapperFactoryBean\"&gt; &lt;!-- 指定接口，接口对应的mapper文件需要在sqlSessionFactory中指定 --&gt; &lt;property name=\"mapperInterface\" value=\"org.mybatis.spring.sample.mapper.UserMapper\" /&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\" /&gt;&lt;/bean&gt; MapperFactoryBean 是一个 FactoryBean, 它会返回传入的 UserMapper 接口的实例，之后可以使用此方法 1234567891011public class FooServiceImpl implements FooService &#123; private UserMapper userMapper; public void setUserMapper(UserMapper userMapper) &#123; this.userMapper = userMapper; &#125; public User doSomeBusinessStuff(String userId) &#123; return this.userMapper.getUser(userId); &#125;&#125; 但是这样还是很麻烦，我们需要为每一个Mapper添加对应配置，有没有办法可以自动完成这个操作，而不用手动创建Mapper Bean呢，答案当然是肯定的，继续来看 四、使用 MapperScannerConfigurer 来简化多个 MapperFactoryBean 声明，配置扫描的包，其下的接口会被自动创建成对应的 MapperFactoryBean 1234&lt;!-- 扫描路径下的所有接口，自动将它们创建成 MapperFactoryBean --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"org.mybatis.spring.sample.mapper\" /&gt;&lt;/bean&gt; 使用时可以直接注入对应的Mapper接口使用，具体可以回头看看之前的配置信息和使用例子 五、mybatis-spring配置总结 使用mybatis-spring，我们需要配置的项有三个 Datasource SqlSessionFactoryBean MapperScannerConfigurer 附一个简单的配置例子供参数： mybatis-spring-demo 另： 如果需要使用Spring的事务处理功能，需要添加如下配置 123&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;constructor-arg ref=\"dataSource\" /&gt;&lt;/bean&gt; 同时，如果要使用Spring的注解式事务，别忘了添加1&lt;tx:annotation-driven transaction-manager=\"transactionManager\" proxy-target-class=\"false\"/&gt; 这样就可以在需要事务的方法上添加@Transactional注解来实现事务了","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://zhengw-tech.com/tags/spring/"},{"name":"mybatis","slug":"mybatis","permalink":"https://zhengw-tech.com/tags/mybatis/"}]},{"title":"CountDownLatch应用及原理","slug":"CountDownLatch应用及原理","date":"2019-02-26T14:39:35.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/02/26/CountDownLatch应用及原理/","link":"","permalink":"https://zhengw-tech.com/2019/02/26/CountDownLatch应用及原理/","excerpt":"CountDownLatch功能很简单，它主要有两个方法，await()与countDown()，初始创建的时候需要给它提供一个数值，调用countDown()方法会将数值减1，调用await()方法的时候会判断值是不是等于0，如果等于0就继续执行，否则就阻塞等待 123456// 初始化创建，值为1CountDownLatch countDownLatch = new CountDownLatch(1);// 如果countDownLatch中的值不是0则阻塞等待countDownLatch.await();// 将countDownLatch中的值进行减1countDownLatch.countDown(); 利用这两个方法，我们能用来做什么呢？","text":"CountDownLatch功能很简单，它主要有两个方法，await()与countDown()，初始创建的时候需要给它提供一个数值，调用countDown()方法会将数值减1，调用await()方法的时候会判断值是不是等于0，如果等于0就继续执行，否则就阻塞等待 123456// 初始化创建，值为1CountDownLatch countDownLatch = new CountDownLatch(1);// 如果countDownLatch中的值不是0则阻塞等待countDownLatch.await();// 将countDownLatch中的值进行减1countDownLatch.countDown(); 利用这两个方法，我们能用来做什么呢？ 让一组线程等待同时开始这种用法，我们只需要将CountDownLatch的初始值设为1，在需要线程阻塞的地方调用countDownLatch.await()方法，当满足开始条件后，调用countDownLatch.countDown()方法将类中的值减为0，让其他所有阻塞的线程可以几乎同时得到执行 1234567891011121314151617181920ExecutorService executorService = Executors.newCachedThreadPool();CountDownLatch countDownLatch = new CountDownLatch(1);for (int i = 0; i &lt; 5; i++) &#123; executorService.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \" waiting...\"); try &#123; // 阻塞等待countdownlatch中的值被减为0 countDownLatch.await(); System.out.println(Thread.currentThread().getName() + \" working...\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;);&#125;TimeUnit.SECONDS.sleep(4);System.out.println(\"\\nstart!\");countDownLatch.countDown(); executorService.shutdown(); 执行结果： 123456789101112pool-1-thread-1 waiting...pool-1-thread-3 waiting...pool-1-thread-2 waiting...pool-1-thread-4 waiting...pool-1-thread-5 waiting...start!pool-1-thread-2 working...pool-1-thread-3 working...pool-1-thread-5 working...pool-1-thread-1 working...pool-1-thread-4 working... 等待一组线程执行完毕这时候，我们需要将CountDownLatch的初始值设置为线程的数量，每次执行完毕后调用countDownLatch.countDown()方法对值进行减1，等待线程可以调用countDownLatch.await()阻塞等待，待所有线程执行完毕后，类中的值减为0，这时阻塞线程就可以继续向下执行了 1234567891011121314151617181920ExecutorService executorService = Executors.newCachedThreadPool();int num = 5;CountDownLatch countDownLatch = new CountDownLatch(num);System.out.println(\"start\");for (int i = 0; i &lt; num; i++) &#123; executorService.execute(() -&gt; &#123; // 加上延时，让效果明显些 try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" working...\"); countDownLatch.countDown(); &#125;);&#125;// 阻塞等待线程执行完成countDownLatch.await();System.out.println(\"task end!\");executorService.shutdown(); 执行结果： 1234567startpool-1-thread-4 working...pool-1-thread-3 working...pool-1-thread-5 working...pool-1-thread-2 working...pool-1-thread-1 working...task end! CountDownLatch内部实现CountDownLath内部使用AbstractQueuedSynchronizer来实现 将AQS中的staus用作CountDownLatch的初始值 在获取资源时会判断status是否等于0，等于0则通过，否则加入AQS中的CLH队列阻塞等待 在释放资源时会对status进行减一操作，如果结果等于0则进行真正的释放操作，将等待队列中的任务唤醒执行 CountDownLatch核心源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// await 和 countDown时，调用对应内部Sync类方法public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));&#125;public void countDown() &#123; sync.releaseShared(1);&#125;// CountDownLatch 内部类，继承AQS，为了方便查看，将AQS中对应代码也粘贴到此处private static final class Sync extends AbstractQueuedSynchronizer &#123; // 实现AQS中的获取共享资源操作 protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; // 实现AQS中的释放共享资源操作 protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c - 1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; // ******* AQS中对应部分代码 ************ public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; // 如果释放成功，status == 0, 那面唤醒线程 doReleaseShared(); return true; &#125; return false; &#125; private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125;&#125; 关于AbstractQueuedSynchronizer有不明白的，可以参考之前的AbstractQueuedSynchronizer简述","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"AbstractQueuedSynchronizer简述","slug":"AQS概述","date":"2019-02-20T12:48:15.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/02/20/AQS概述/","link":"","permalink":"https://zhengw-tech.com/2019/02/20/AQS概述/","excerpt":"工作流程AbstractQueuedSynchronizer 是一个用于在竞争资源（如多线程）时使用的同步器，它内部使用了一个int类型的字段status表示需要同步的资源状态， 并基于一个先进先出（FIFO）的等待队列，队列中的每个节点表示要获取资源的线程 同步器主要是用于控制资源的获取以及释放，它可以用于独占模式和共享模式，这里我们以独占模式为例 在获取和释放资源时，我们需要实现自己的尝试获取和尝试释放的方法，利用status字段来控制成功与否","text":"工作流程AbstractQueuedSynchronizer 是一个用于在竞争资源（如多线程）时使用的同步器，它内部使用了一个int类型的字段status表示需要同步的资源状态， 并基于一个先进先出（FIFO）的等待队列，队列中的每个节点表示要获取资源的线程 同步器主要是用于控制资源的获取以及释放，它可以用于独占模式和共享模式，这里我们以独占模式为例 在获取和释放资源时，我们需要实现自己的尝试获取和尝试释放的方法，利用status字段来控制成功与否 获取资源(独占模式)1234567891011public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 在独占模式下尝试获取资源(需要自己实现),成功返回true, 失败返回falseprotected boolean tryAcquire(int arg) &#123; // 尝试获取资源与释放资源都是依靠 status 来实现具体的逻辑 // 可以基于 status 与 arg 字段来实现此方法 （我们可以赋予status任何意义来实现逻辑）&#125; 获取资源的流程如下（独占模式） 首先尝试获取资源，如果成功直接返回，进行后续流程 失败则创建一个新节点，将其添加到链表尾部（如果链表为空，则先创建一个空的表头再添加） 之后判断当前节点前一个节点是不是头结点(头节点HEAD无实际作用,可以不把它当作等待队列的一部分)，如果是则再次尝试获取资源，成功则将当前节点置为头节点，进行获取资源后的流程 如果当前节点前一个节点不是头结点，那么将当前节点中的线程挂起-&gt;LockSupport.park(this),然后等待被唤醒（挂起前务必将其前一节点状态改为SIGNAL, SIGNAL表示当前node的后继节点对应的线程需要被唤醒） 被唤醒后则跳转到第3步继续执行 释放资源(独占模式)123456789101112131415public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;// 在独占模式下尝试释放资源(需要自己实现)protected boolean tryRelease(int arg) &#123; // 尝试获取资源与释放资源都是依靠 status 来实现具体的逻辑 // 可以基于 status 与 arg 字段来实现此方法 （我们可以赋予status任何意义来实现逻辑）&#125; 释放资源的流程如下（独占模式）1.首先尝试释放资源2.成功后判断，如果头结点不为null，同时其状态不是初始0值（需要有后继节点更改其状态），那么将当前节点状态置为0，同时唤醒下一节点中线程 共享模式共享模式与独占模式基本相同 区别主要在于此方法，当线程被唤醒后获取资源，如果成功且返回值&gt;0，则会继续唤醒后续线程返回负数：失败返回0：成功，但是其他线程无法再获取资源返回正数：成功，其他线程可能继续获取资源（需要尝试后知道） 123protected int tryAcquireShared(int arg) &#123; // todo&#125; 下面举一个《Java并发编程实战》中的二元闭锁例子来说明AQS的使用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 使用 AQS 实现的二元闭锁（所有线程都会阻塞，直到状态改变被唤醒，此时所有线程都得到执行） * status表是开关状态，=0时关闭，=1时开启 */public class OneShotLatch &#123; private final Sync sync = new Sync(); public void signal() &#123; sync.releaseShared(0); &#125; public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(0); &#125; private class Sync extends AbstractQueuedSynchronizer &#123; /** * 如果闭锁是开的 （state==1），那么这个操作成功，否则失败阻塞 * @param ignored * @return */ @Override protected int tryAcquireShared(int ignored) &#123; return (getState() == 1) ? 1: -1; &#125; /** * 打开status状态开关，放开所有线程 * @param ignored * @return */ @Override protected boolean tryReleaseShared(int ignored) &#123; setState(1); return true; &#125; &#125; // 测试方法 public static void main(String[] args) throws Exception &#123; OneShotLatch oneShotLatch = new OneShotLatch(); for (int i = 0; i &lt; 3; i++) &#123; new Thread(() -&gt; &#123; try &#123; oneShotLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"completed\"); &#125;).start(); &#125; // 2S后唤醒 TimeUnit.SECONDS.sleep(2); oneShotLatch.signal(); TimeUnit.SECONDS.sleep(5); System.out.println(\"end\"); &#125;&#125; 小结 使用AQS后，我们要做的就是通过status来控制请求和释放资源操作及是否成功，而AQS会负责在获取失败后将其放入队列，等待有释放资源操作后被唤醒，进而再次请求资源等操作","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"}]},{"title":"Redis数据结构概览","slug":"Redis数据结构概览","date":"2019-02-07T08:54:28.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/02/07/Redis数据结构概览/","link":"","permalink":"https://zhengw-tech.com/2019/02/07/Redis数据结构概览/","excerpt":"Redis支持的主要有5种数据类型，string, list, set, zset , hash，但是对于每种数据类型，Redis都不是简单的使用一种数据结构来实现，而是根据数据量等因素使用多种数据结构（SDS、双向链表、hashtable等），来达到提高效率、节省空间的目的，可以使用object encoding &lt;key&gt; 来查看数据的内部结构","text":"Redis支持的主要有5种数据类型，string, list, set, zset , hash，但是对于每种数据类型，Redis都不是简单的使用一种数据结构来实现，而是根据数据量等因素使用多种数据结构（SDS、双向链表、hashtable等），来达到提高效率、节省空间的目的，可以使用object encoding &lt;key&gt; 来查看数据的内部结构 （注：对于Redis的早期版本，list 结构内部是使用双向链表实现的）","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://zhengw-tech.com/tags/redis/"}]},{"title":"Maven聚合与继承","slug":"maven聚合与继承","date":"2019-02-06T08:18:26.000Z","updated":"2022-02-07T05:08:05.703Z","comments":true,"path":"2019/02/06/maven聚合与继承/","link":"","permalink":"https://zhengw-tech.com/2019/02/06/maven聚合与继承/","excerpt":"maven聚合聚合的目的是为了快速构建项目，当我们有几个maven模块，想要一次性构建，而不是到每个模块下面去执行maven命令，这时候就需要使用maven聚合（或者称为多模块）。 使用聚合的时候，我们需要新建一个maven项目，由它来控制构建其他的项目，其pom.xml配置与其他普通maven项目的区别主要在以下两个地方： 打包类型（packaging）必须为pom 需要在其中添加modules标签，在其中使用module标签包括需要同时构建的maven模块的名称路径，路径为相对于此pom.xml文件的路径（如果与pom.xml文件同级则直接写项目名，如果在上一级则写../项目名）。 这样当我们在此项目下执行构建的时候，就会同时构建其中配置的项目。","text":"maven聚合聚合的目的是为了快速构建项目，当我们有几个maven模块，想要一次性构建，而不是到每个模块下面去执行maven命令，这时候就需要使用maven聚合（或者称为多模块）。 使用聚合的时候，我们需要新建一个maven项目，由它来控制构建其他的项目，其pom.xml配置与其他普通maven项目的区别主要在以下两个地方： 打包类型（packaging）必须为pom 需要在其中添加modules标签，在其中使用module标签包括需要同时构建的maven模块的名称路径，路径为相对于此pom.xml文件的路径（如果与pom.xml文件同级则直接写项目名，如果在上一级则写../项目名）。 这样当我们在此项目下执行构建的时候，就会同时构建其中配置的项目。 下面举一个配置文件的例子： 12345678910&lt;project ......&gt; &lt;groupId&gt;XXX.XXX&lt;/groupId&gt; &lt;artifactId&gt;XXX&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;XX1&lt;/module&gt; &lt;module&gt;XX2&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; maven继承继承的目的是为了消除重复配置，在项目中可以通过继承父模块的一些配置来简化配置文件，避免配置的重复。 父模块 使用继承的时候，父模块的配置文件（pom.xml）中打包类型必须同聚合一样，为pom。 依赖管理：为了避免子模块继承没有不必要的依赖，所以在父模块中并不引入实际的依赖，而是使用dependencyManagement元素，在其中声明的的dependencies不会在其本身（父模块）中引入依赖，也不会给它的子模块引入依赖。如果在子模块需要使用其中配置的依赖，则可以在子模块中声明，但是不需要声明版本号和依赖范围（已在父模块中声明），这样可以统一不同模块中的依赖版本。 插件管理：同依赖管理，Maven提供了类似的pluginManagement元素来帮助管理插件，使用方式也基本相同。 子模块子模块如果要继承父模块，则需在其pom.xml中需添加如下配置，同时其groupId和version会省略，直接继承父模块的配置。 123456&lt;parent&gt; &lt;groupId&gt;XXX.XXX&lt;/groupId&gt; &lt;artifactId&gt;XX&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;relativePath&gt;XX/XX/pom.xml&lt;/relativePath&gt;&lt;/parent&gt; 其中relativePath为父项目的pom.xml路径（如果没有配置此项，则默认为../pom.xml，即上级目录下的pom.xml），构建时会先根据relativePath查找，如果找不到，则会再从本地仓库查找。 注：maven聚合和继承可以同时使用。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://zhengw-tech.com/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://zhengw-tech.com/tags/maven/"}]},{"title":"JavaScript数组常用方法","slug":"JavaScript数组常用方法","date":"2019-02-04T03:51:54.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/02/04/JavaScript数组常用方法/","link":"","permalink":"https://zhengw-tech.com/2019/02/04/JavaScript数组常用方法/","excerpt":"push 方法 将元素添加到数组尾部 12var values = [1,2,3,4,5]values.push(6,7) // values = [1,2,3,4,5,6,7] pop 方法 将数组尾部元素弹出 12var values = [1,2,3,4,5]values.pop() // values = [1,2,3,4] shift 方法 弹出数组头元素 12var values = [1,2,3]values.shift() // values = [2,3]","text":"push 方法 将元素添加到数组尾部 12var values = [1,2,3,4,5]values.push(6,7) // values = [1,2,3,4,5,6,7] pop 方法 将数组尾部元素弹出 12var values = [1,2,3,4,5]values.pop() // values = [1,2,3,4] shift 方法 弹出数组头元素 12var values = [1,2,3]values.shift() // values = [2,3] unshift 方法 将元素添加到数组头部 12var values = [1,2,3]values.unshift(-1, -2) // values = [-1, -2, 1, 2, 3] reverse 方法 反转数组 12var values = [1, 4, 5, 2]values.reverse() // values = [2, 5, 4, 1] sort 方法 对数组进行排序 12345var values = [1, 4, 5, 2]values.sort() // values = [1, 2, 4, 5]values.sort(function(a, b) &#123; return a - b;&#125;) // values = [5, 4, 3, 2, 1] concat 方法 连接两个数组，生成一个新数组 123var values1 = [1, 2, 3]var values2 = [\"A\", \"B\"]var res = values1.concat(values2) // res = [1, 2, 3, \"A\", \"B\"] slice 方法 剪切数组，索引可为负数 1234var values = [\"aa\", \"bb\", \"cc\", \"dd\"]var res1 = values.slice(1) // res1 = [\"bb\", \"cc\", \"dd\"]var res2 = values.slice(1, 3) // res2 = [\"bb\", \"cc\"]var res3 = values.slice(-1) // res3 = [\"dd\"] splice 方法 删除、插入、替换数组元素 1234567891011// 删除 splice(开始删除的索引，删除的数量)var colors = [\"red\", \"green\", \"blue\"]var removed = colors.splice(0, 2)// colors = [\"blue\"]// removed = [\"red\", \"green\"]// 插入/替换 splice(开始位置，删除的数量[可为0，此时为插入]，插入的元素)var colors = [\"red\", \"green\", \"blue\"]var removed = colors.splice(1, 1, \"yellow\", \"orange\")// colors = [\"red\", \"yellow\", \"orange\", \"blue\"]// removed = [\"green\"] 删除的元素 indexOf / lastIndexOf 查找元素索引位置 12345// indexOf(要查找的元素, [其实查找位置])var colors = [1, 2, 3, 4, 1]colors.indexOf(1) // = 0colors.indexOf(1, 1) // = 4colors.indexOf(10) // = -1 迭代方法 every() : 对数组中的每一项运行给定的函数，如果都返回true, 则返回true filter() : 对数组中的每一项运行给定函数，返回该函数会返回true的项组成的数组 forEach() : 对数组中的每一项运行给定函数，这个方法无返回值 map() : 对数组中的每一项运行给定的函数，返回每次函数调用的结果组成的函数 some() : 对数组中的每一项运行给定的函数，如果该函数对任一项返回true，则返回true 传入这些方法的函数会接收三个参数：数组项的值，该项在数组中的位置，数组对象本身 1234567891011121314151617181920var numbers = [1, 2, 3, 4, 5, 4, 3, 2 ,1];var everyResult = numbers.every(function(item, index, array) &#123; return item &gt; 2;&#125;); // everyResult = falsevar someResult = numbers.some(function(item, index, array) &#123; return item &gt; 2;&#125;); // someResult = truevar filterResult = numbers.filter(function(item, index, array) &#123; return item &gt; 2;&#125;); // filterResult = [3, 4, 5, 4, 3]var mapResult = numbers.map(function(item, index, array) &#123; return item * 2;&#125;); // mapResult = [2, 4, 6, 8, 10, 8, 6, 4, 2]numbers.forEach(function(item, index, array) &#123; // 执行一些操作&#125;) reduce/ reduceRight 方法 传入此方法的函数接收4个参数：前一个值，当前值，项的索引，数组对象 1234var values = [1, 2, 3, 4, 5]var sum = values.reduce(function(prev, cur, index, array) &#123; return prev + cur;&#125;); // sum = 15","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://zhengw-tech.com/tags/javascript/"}]},{"title":"JavaScript类型转换","slug":"JavaScript类型转换","date":"2019-02-03T00:57:33.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/02/03/JavaScript类型转换/","link":"","permalink":"https://zhengw-tech.com/2019/02/03/JavaScript类型转换/","excerpt":"ECMAScript中有五种基本数据类型：Undefined, Null, Boolean, Number, String，一种复杂数据类型：Object 数据类型检测方法typeof 函数，例： 12var s = xx;var res = typeof(s); 返回结果=typeof(res) 意义 typeof(res) === “undefined” 值未定义 typeof(res) === “boolean” 值为布尔类型 typeof(res) === “string” 值是字符串 typeof(res) === “number” 值为数值 typeof(res) === “object” 值是对象或null typeof(res) === “function” 值是函数","text":"ECMAScript中有五种基本数据类型：Undefined, Null, Boolean, Number, String，一种复杂数据类型：Object 数据类型检测方法typeof 函数，例： 12var s = xx;var res = typeof(s); 返回结果=typeof(res) 意义 typeof(res) === “undefined” 值未定义 typeof(res) === “boolean” 值为布尔类型 typeof(res) === “string” 值是字符串 typeof(res) === “number” 值为数值 typeof(res) === “object” 值是对象或null typeof(res) === “function” 值是函数 Boolean类型转换12345678910111213141516171819# BooleanBoolean(true) == trueBoolean(false) == false# StringBoolean(\"\") == falseBoolean(\"ad\") == true# NumberBoolean(0) == falseBoolean(NaN) == falseBoolean(10) == true# ObjectBoolean(&#123;&#125;) == tureBoolean(null) = false# UndefinedBoolean(undefined) == false 数值类型转换Number(), parseInt() 和 parseFloat()，第一个函数可以用于任何数量类型，而另外两个函数则专门用于把字符串转换成数值 参数 Number() parseInt(); parseInt(“xx”, [8 10 16]) true Number(ture) === 1 parseInt(true) === NaN(isNaN) false Number(false) === 0 parseInt(false) === NaN(isNaN) 13 Number(13) === 13 parseInt(13) === 13 null Number(null) === 0 parseInt(null) === NaN(isNaN) undefined Number(undefined) === NaN(isNaN) parseInt(undefined) === NaN(isNaN) “234” Number(“234”) === 234 parseInt(“234”) === 234 “1.1” Number(“1.1”) === 1.1 parseInt(“1.1”) === 1 “070” Number(“070”) === 70 parseInt(“070”) = 70; parseInt(“070”, 8) = 56 “0xf” Number(“0xf”) === 15 parseInt(“0xf”) === 15 “” Number(“”) === 0 parseInt(“”) === NaN(isNaN) “123abc” Number(“123abc”) === NaN(isNaN) parseInt(“123abc”) === 123 Number()函数，如果参数是对象，则调用对象的valueOf()方法，然后依照前面的规则进行转换，如果结果是NaN，则调用对象的 toString()方法，然后依照前面的规则进行转换 字符串类型转换1234String(10) === \"10\"String(true) === \"true\"String(null) === \"null\"String(undefined) === \"undefined\"","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://zhengw-tech.com/tags/javascript/"}]},{"title":"Redis数据结构-SDS","slug":"Redis数据结构SDS","date":"2019-01-26T04:27:31.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/01/26/Redis数据结构SDS/","link":"","permalink":"https://zhengw-tech.com/2019/01/26/Redis数据结构SDS/","excerpt":"基本结构Redis中没有使用C语言原生的字符串，而是在其基础上包装了一个新的数据结构-SDS，其结构如下 1234567891011// 指向下面结构中的buf指针typedef char *sds;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; // 使用到的空间 uint8_t alloc; // 分配的C语言字符串空间，不包括头部和C字符串的中止符号null unsigned char flags; // 使用后三位表示是sdshdr8/sdshdr16的类型 char buf[]; // 实际字符数组的空间&#125;// 类似的还有 sdshdr16, sdshdr32等，用于节省空间// 其中的所有方法都在此结构基础上实现","text":"基本结构Redis中没有使用C语言原生的字符串，而是在其基础上包装了一个新的数据结构-SDS，其结构如下 1234567891011// 指向下面结构中的buf指针typedef char *sds;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; // 使用到的空间 uint8_t alloc; // 分配的C语言字符串空间，不包括头部和C字符串的中止符号null unsigned char flags; // 使用后三位表示是sdshdr8/sdshdr16的类型 char buf[]; // 实际字符数组的空间&#125;// 类似的还有 sdshdr16, sdshdr32等，用于节省空间// 其中的所有方法都在此结构基础上实现 主要方法及实现sdslen(sds s) - 获取sds中已经使用的数组空间大小 根据flags判断类型，将指向buf的指针前移到结构开始，转换为结构类型，获取len属性返回 源码如下 12345678910111213141516171819// 由于s是指向sdshdr结构中buf数组，所有需要减去len,alloc,flags所占用的空间，到达结构在内存中的开始位置，进行类型转换#define SDS_HDR(T,s) ((struct sdshdr##T *)((s)-(sizeof(struct sdshdr##T))))static inline size_t sdslen(const sds s) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return SDS_TYPE_5_LEN(flags); case SDS_TYPE_8: return SDS_HDR(8,s)-&gt;len; case SDS_TYPE_16: return SDS_HDR(16,s)-&gt;len; case SDS_TYPE_32: return SDS_HDR(32,s)-&gt;len; case SDS_TYPE_64: return SDS_HDR(64,s)-&gt;len; &#125; return 0;&#125; size_t sdsavail(sds s) - 获取可用空间大小 = alloc - len void sdssetlen(sds s, size_t newlen) - 设置len属性值=newlen void sdsinclen(sds s, size_t inc) - 修改len属性值=len+inc size_t sdsalloc(sds s) - 返回alloc属性值 void sdssetalloc(sds s, size_t newlen) - 设置alloc属性值=newlen sds sdsnewlen(void *init, size_t initlen) - 通过传递指针和长度创建sds 根据长度initlen判断选择的sdshdr类型，分配空间，初始化 len, alloc, type属性，返回指向buf的指针 sds sdsempty(void) - 创建一个空的sds字符串 sds sdsnew(const char *init) - 创建一个包含init字符的sds sds sdsup(const sds s) - 复制一个sds字符串 void sdsfree(sds s) - 释放sds字符串内存空间 void sdsupdatelen(sds s) - 更新sds长度（用于去除字符中的中间\\0字符） void sdsclear(sds s) - 长度设为0，清空字符串（s[0]=&#39;\\0&#39;） sds sdsMakeRoomFor(sds s, size_t addlen) - 重新为sds中数组分配长度，确保能再添加addlen个长度数组 sds sdsRemoveFreeSpace(sds s) - 释放未使用的空间 等等……","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://zhengw-tech.com/tags/redis/"}]},{"title":"Python参数使用总结","slug":"Python参数使用总结","date":"2019-01-04T05:14:16.000Z","updated":"2021-04-17T14:50:06.967Z","comments":true,"path":"2019/01/04/Python参数使用总结/","link":"","permalink":"https://zhengw-tech.com/2019/01/04/Python参数使用总结/","excerpt":"Python 中参数的传递非常灵活，不太容易记住理解，特整理如下备忘： 普通参数即按照函数所需的参数，对应位置传递对应的值，可以对应 Java 中的普通参数 1234567def max(a, b): if a &gt; b: return a else: return b max(5, 13) # = 13","text":"Python 中参数的传递非常灵活，不太容易记住理解，特整理如下备忘： 普通参数即按照函数所需的参数，对应位置传递对应的值，可以对应 Java 中的普通参数 1234567def max(a, b): if a &gt; b: return a else: return b max(5, 13) # = 13 默认参数可以对位置参数中的某个参数设置默认值，设置了默认值的参数在调用时可以不传递 此时需要注意，默认参数只能在必选参数后面 123456789def max(a, b=0): if a &gt; b: return a else: return b max(5, 13) # = 13max(5) # = 5max(-6) # = 0 当有多个默认参数时，调用参数传递的值会按照顺序赋值，也可以通过指定参数值为特定参数赋值 123456def position(x, y=1, z=0): print('x:', x, 'y:', y, 'z:', z) position(5) # x=5, y=1, z=0position(5, 6) # x=5, y=6, z=0position(5, z=6) # x=5, y=1, z=6 可变参数即传递的参数个数不确定，可以对应为 Java 中的可变参数，类似传递了一个 list 或 tuple 可变参数只能出现在必选参数和默认参数后面 12345678910def max(*numbers): # 此处可以有更简单的写法 sum = 0 for number in numbers: sum += number return sumsum(1,2,3,4,5) # = 15# 对于 list 或 tuple, 如 nums = [1,2,3,4,5], 可以这样使用sum(*nums) # = 15 命名关键字参数命名关键字有些像普通参数和默认参数的结合，在一个 * 后面的参数为命名关键字参数 和普通参数、默认参数的区别就是需要在传递参数时指定赋值给的参数名字 命名关键字参数只能出现在必选参数、默认参数、可变参数后面 12345678def person1(name, *, age, sex): print('name:', name, 'age:', age, 'sex:', sex) def person1=2(name, *, age=15, sex='F'): print('name:', name, 'age:', age, 'sex:', sex) person1('zhang', age=15, sex='F') # 如果命名关键字参数没有设置默认值，则必须显示给每个参数赋值person2('zhang') # 函数中已经对参数设置默认值 如果命名关键字参数前面有可变参数，则可省略 * 号 123# age 和 sex 均是命名关键字参数def person(name, *args, age, sex): pass 关键字参数关键字参数必须出现在必选参数、默认参数、可变参数、命名关键字参数后面 在可变参数的基础上，即不仅仅可以传递任意个参数，同时还可以对传递的各个参数指定参数名，可以理解为传递了一个 dict 123456def person(name, **kw): print('name:', name, 'other:', kw) person('zhang', age=15, sex='M') # name: zhang other: &#123;'sex': 'M', 'age': 15&#125;# 对于 dict, 如 p=&#123;'age': 15, 'sex':'M'&#125;, 可以这样使用person('zhang', **p) 总结一下 普通参数——必选参数 可选参数——参数有默认值，调用函数时可以传递也可以不传递，如果不传递则使用默认值 可变参数——传递数量不确定 (可以为0个) 的参数，类似传递一个 list 命名关键字参数 ——如果设置默认值，则同可选参数，否则必须传递，且传递时指定值对应的参数名 关键字参数——传递数量不确定 (可以为0) 的 键值对，类似传递一个 dict 在函数中出现的顺序必须和上面的保持一致 参考资料 https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://zhengw-tech.com/tags/python/"}]}]}